---
title: ClearML
subtitle: MLOps YA.Camp 2025
author:
    Лев Коваленко
format: revealjs
---

##
![](images/clearml.png){fig-align=center}


:::{.notes}
Для начала давайте рассмотрим, что нам предлагает clearml, как фреймворк для проведения исследований.  ClearML предоставляет как унифицированную платформу с открытым исходным кодом для непрерывного использования искусственного интеллекта, так и набор модулей для совместного взаимодействия. То есть авторы инструмента имеют в виду, что можно как ограничиться использование только clearml и проводить исследования в рамках платформы, так и использовать определенные модули clearml в своих процессах проведения исследований.


Clearml действительно имеет обширные возможности:


- возможности dataops (версионирование и управление данными)
- трекинг экспериментов
- платформа для обучение моделей
- генерация отчетов и реестр для их хранения
- model store, для упрощения поставок моделей и переиспользования предыдущих наработок
- запуск CI-CD
- model servering - автоматическое развертывание моделей


И все это с уже настроенной оркестрацией, планировщиками и распределенными вычислениями. Звучит очень круто, как инструмент позволяющий покрыть практически весь процесс создания и поставки моделей.
:::


## Варианты использования


- ClearML SaaS
- Частное облако (VPC)
- Локальная развертка
- Управляемое VPC


:::{.notes}
ClearML предлагает 4 варианта использования:


- Управляемый ClearML SaaS. Развертывание выделенного облачного сервера Clear ML. Все данные и вычисления остаются в контуре клиентов или VPC.
- Развертывание виртуального частного облака. Все данные остаются в контуре клиента. Самоуправление с полной удаленной поддержкой.
- Локально Запускайте ClearML на собственных локальных серверах и персональных устройствах клиентов. Самоуправление с полной удаленной поддержкой.
- VPC Полностью управляется ClearML в контуре.


Далее мы будем рассматривать локальный запуск.
:::


## Архитектура ClearML
![](images/clearml_architecture.png){fig-align=center}


:::{.notes}
ClearML Server -- решение поставляемое clearml -- это внутренняя инфраструктура из набора сервисов ClearML . Существует бесплатная опенсорс-реализация этого ClearML Server. Ее можно развернуть на свои собственных мощностях и использовать внутри команды для совместной работы.


ClearML Server содержит следующие компоненты:


- Веб-приложение ClearML — одностраничный пользовательский интерфейс для управления экспериментами и просмотра данных.
- RESTful API для:
  - Документирование и регистрация информации, статистики и результатов эксперимента.
  - Запрос истории экспериментов, журналов и результатов
- Локальный файловый сервер для хранения изображений и моделей, обеспечивающий легкий доступ к ним с помощью веб-приложения. При желании его можно заменить на s3-совместимое хранилище.


Его можно быстро развернуть с помощью Docker, AWS EC2 AMI или Kubernetes. Есть две конфигурации сервера с зафиксированными портами или саб-деменами. Дефолтно используются следующие порты


- Веб-приложение на порту 8080
- Служба API на порту 8008
- Служба хранения файлов на порту 8081


Ознакомиться с запуском вы можете в [документации](https://github.com/allegroai/clearml-server?tab=readme-ov-file#launching), он несколько различается для разных систем. Но заключается в запуске docker-compose или kubectl. При запуске у вас будут запущены все компоненты clear ml, а также elatic, mongo db и redis для хранения информации на сервере clear ml.


Важный нюанс, дефолтно clear ml не запускается функции аутентификации, и соответственно на селфхостед версию может зайти кто угодно. Для подключения аутентификации нужно изменить конфиг и прописать список пользователей (логин + пароль) для кого будет доступе сервис, то есть это будет дополнительная работа для админа.
:::


## ClearML agent
![](images/clearml_agent.png){fig-align=center}


:::{.notes}
ClearML Agent — это виртуальная среда и менеджер выполнения решений DL/ML на машинах с графическим процессором. Он интегрируется с пакетом ClearML Python и сервером ClearML, обеспечивая полноценное кластерное решение ИИ.
Основное внимание уделяется:


- Воспроизведению экспериментов, включая их полную среду.
- Масштабированию рабочих процессов на нескольких целевых машинах.


Агент ClearML выполняет эксперимент или другой рабочий процесс, воспроизводя состояние кода с исходного компьютера на удаленный компьютер. Для этого он клонирует состояние репозитория (определенный коммит) указанные в эксперименте и добавляет git diff от коммита, сохраненный в эксперименте.


На предыдущей диаграмме показан типичный процесс, в котором агент выполняет задачу:


- Поставьте задачу для выполнения в очередь.
- Агент извлекает задачу из очереди.
- Агент запускает Docker-контейнер, в котором выполняется код задачи.
- Настраивается среда выполнения задачи:
  - Выполнить любой настроенный сценарий пользовательской установки.
  - Установить все необходимые системные пакеты.
  - Клонируется код из репозитория git.
  - Применяются все записанные незафиксированные изменения.
  - Настраивает среду Python и необходимые пакеты.
- Сценарий/код задачи выполняется.


> Агент ClearML использует версию Python, доступную в среде или докере, в котором он выполняет код. Он не устанавливает Python, поэтому обязательно используйте докер или среду той версии, которая вам нужна.


> Агент ClearML может работать на Google Colab. Это помогает пользователям использовать вычислительные ресурсы, предоставляемые Google Colab, и отправлять на них эксперименты для выполнения.
:::


## ClearML serving
![](images/clearml_serving.png){fig-align=center}

:::{.notes}
ClearML serving -- это сервис для развертывания и оркестровки моделей. Он позволяет развертывать модели, включая обслуживание и предварительную обработку кода в кластере Kubernetes или пользовательском решении на основе контейнера.
Важные качества такого подхода: 
- Простота развертывания и настройки
  - Поддержка моделей машинного обучения (Scikit Learn, XGBoost, LightGBM)
  - Поддержка моделей глубокого обучения (TensorFlow, PyTorch, ONNX)
  - Настраиваемый RestAPI для обслуживания (т.е. позволяет выполнять предварительную и последующую обработку для каждой модели для легкой интеграции)
- Гибкость
  - Развертывание модели в режиме онлайн
  - Развертывание модели/версии конечной точки в режиме онлайн (т.е. нет необходимости останавливать работу сервиса)
  - Отдельная предварительная и постобработка кода Python для каждой модели
- Масштабируемость
  - Несколько моделей на контейнер
  - Несколько моделей на одну услугу обслуживания
  - Поддержка нескольких служб (полностью разделенные многофункциональные службы, работающие независимо)
  - Поддержка нескольких кластеров
  - Автоматическое масштабирование узлов «из коробки» на основе нагрузки/использования
- Эффективность
  - Использование ресурсов нескольких контейнеров
  - Поддержка узлов CPU и GPU
  - Автоматическое пакетирование для моделей DL
  - Автоматическое развертывание
  - Автоматические обновления моделей с поддержкой Canary
  - Программируемый API для развертывания модели
  - Развертывание Canary A/B — онлайн-обновления Canary
- Мониторинг
  - Отчетность по показателям использования
  - Метрическая панель инструментов
  - Метрика производительности модели
  - Панель управления производительностью модели
:::

# Основные команды


## Подключение к ClearML серверу
`~/clearml.conf`
```conf
api {
    web_server: "http://localhost:8008"
    api_server: "http://localhost:8080"
    files_server: "http://localhost:8081"
}
```


:::{.notes}
Предварительно [установите](https://github.com/allegroai/clearml/releases/tag/v1.15.1) ``clearml`` в ваш проект с помощью pip/poetry/pdm и тд.


Для подключения к серверу есть два варианта:


1. Запустить команду ``clearml-init`` для интерактивной настройки
2. Ручками прописать в файле ``~/clearml.conf`` адреса основных компонент clear ml.


После настройки вы легко сможете подключать clearm ml к серверу, загружать или выгружать данные, модели, результаты экспериментов. буквально парой строк кода.


Есть важное примечание, если вы используете саб-доменную конфигурацию, то нужно указывать протокол http/https, а так же порты если они отличаются от 80 и 443
:::


## Трекинг экспериментов

:::: {.columns }
 
::: {.column width="50%" }

```python
from clearml import Task


def main():
    ...
    task = Task.init(project_name='great project', task_name='best experiment')
    ...
    task.set_progress(0)
    ...
    task.set_progress(50)
    print(task.get_progress())
    ...
    task.set_progress(100)
```
:::

::: {.column width="50%" }

![](images/clearml_experiments.png)
:::
::::

:::{.notes}
В ClearML эксперименты организованы в виде задач. ClearML автоматически регистрирует ваш эксперимент и код, включая выходные данные и параметры из [популярных платформ](https://clear.ml/docs/latest/docs/clearml_sdk/task_sdk/#automatic-logging) машинного обучения, как только вы интегрируете ClearML со своим кодом.


Для этого импортируете класс Task в код, инициализируйте Task, указав проект и имя эксперимента. Если проект еще не существует, новый создается автоматически. Действительно этих двух строк хватит что бы логировать практически любые эксперименты


:::




## Что логирует clear ml {.smaller .scrollable}

:::: {.columns }
 
::: {.column width="50%" }

- **Hyperparameters**
    - Command Line Parsing
        - click
        - argparse
        - Python Fire
        - LightningCLI
    - TensorFlow Definitions (absl-py)
    - Hydra
- **Metrics, scalars, plots**
    - Matplotlib
    - Tensorboard
    - TensorboardX
- **Execution details including**
    - Git information
    - Uncommitted code modifications
    - Python environment
    - Execution configuration
:::
::: {.column width="50%" }
- **Models**
    - TensorFlow
    - Keras
    - PyTorch
    - AutoKeras
    - CatBoost
    - Fast.ai
    - LightGBM
    - MegEngine
    - MONAI
    - scikit-learn (only using joblib)
    - XGBoost (only using joblib)
    - YOLOv8
    - YOLOv5

:::
::::

## ClearML Task{.smaller}


:::: {.columns }
 
::: {.column width="50%" }
**Получение эксперимента по ID**


```python
prev_task = Task.get_task(task_id='123456deadbeef')
```


**Получение эксперимента по имени**


```python
prev_task = Task.get_task(
    project_name='great project',
    task_name='best experiment',
)
```
:::
 
::: {.column width="50%"}
**Фильтрация экспериментов по разным параметрам**


```python
task_list = Task.get_tasks(
    task_ids=None,  # type Optional[Sequence[str]]
    project_name=None,  # Optional[str]
    task_name=None,  # Optional[str]
    allow_archived=True, # [bool]
    task_filter=None,  # Optional[Dict]#
    # tasks with tag `included_tag` or without tag `excluded_tag`
    tags=['included_tag', '-excluded_tag']
)
```
 
:::
::::


:::{.notes}
Каждый ранее выполненный эксперимент сохраняется как Задача. То есть атомарной единицей исследования в clearml является разовый запуск какого-то эксперимента. Эксперименту-задаче автоматически присваивается автоматически сгенерированный уникальный идентификатор (строка UUID), который нельзя изменить и который всегда определяет одну и ту же задачу в системе.


Можно получить объект Task программным путем, запросив систему на основе идентификатора задачи или комбинации проекта и имени. Вы также можете запрашивать задачи на основе их свойств, например теговб имени проекта или задачи и тд.


Когда вы получили объект Task, то можете получить его состояние: модель, датасет, метрики, параметры и тд.
:::


## ClearML artifacts{.smaller}


:::: {.columns }
 
::: {.column width="50%" }
**Добавление артефактов**


```python
# конкретный файл
task.upload_artifact(
    name='data',
    artifact_object='/path/to/preprocess_data.csv',
)
# дирректория и все файлы внутри нее
task.upload_artifact(name='folder', artifact_object='/path/to/folder/')
# объект python
numpy_object = np.eye(100, 100)
task.upload_artifact(name='features', artifact_object=numpy_object)
```
 
:::
 
::: {.column width="50%"}
**Использование артефактов**


```python
preprocess_task = Task.get_task(task_id='preprocessing_task_id')
local_csv = preprocess_task.artifacts['data'].get_local_copy()


prev_task = Task.get_task(task_id='the_training_task')
last_snapshot = prev_task.models['output'][-1]
local_weights_path = last_snapshot.get_local_copy()
```
 
:::
::::


:::{.notes}
ClearML позволяет легко хранить выходные продукты эксперимента — снимок модели/файл весов, предварительную обработку данных, функциональное представление данных и многое другое!


По сути, артефакты — это файлы (или объекты Python), загруженные из сценария и хранящиеся вместе с задачей. К этим артефактам можно легко получить доступ через веб-интерфейс или программно.


Артефакты можно хранить где угодно: на сервере ClearML, в любом решении для хранения объектов или в общей папке.


Зарегистрированные артефакты могут использоваться другими задачами, будь то предварительно обученная модель или обработанные данные. Чтобы использовать артефакт, сначала вам необходимо получить экземпляр задачи, которая его изначально создала, затем вы либо загружаете его и получаете путь к нему, либо получаете объект артефакта напрямую.


task.artifacts— это словарь, ключами которого являются имена артефактов, а возвращаемый объект — это объект артефакта.


- Вызов get_local_copy() создает локально копию артефакта и возвращает путь до объекта. Таким образом, при следующем выполнении кода вам не потребуется повторно загружать артефакт.
- Вызов get() возвращает десериализованный python объект, не сохраняя его в локальный кеш.


Еще хотелось бы уделить внимание моделям. Модели — это особый вид артефакта. Модели, созданные с помощью популярных платформ (таких как PyTorch, TensorFlow, Scikit-learn), автоматически регистрируются ClearML. Все снимки автоматически записываются. Чтобы убедиться, что вы также автоматически загружаете снимок модели (вместо сохранения ее локального пути), укажите место хранения файлов модели, в которые будут загружены. для этого надо добавить аргумент ``output_uri`` в инициализацию Task.


- Общая папка:/mnt/share/folder
- S3:s3://bucket/folder
- Сервисы, отличные от AWS S3 (например, MinIO):s3://host_addr:port/bucket
- Облачное хранилище Google:gs://bucket-name/folder
- Хранилище Azure:azure://<account name>.blob.core.windows.net/path/to/file


Что бы получить модель, нужно получить экземпляр задачи, обучающей исходные файлы весов, затем вы можете запросить у задачи ее выходные модели (список снимков) и получить последний снимок.
:::


## ClearML metrics{.smaller}


:::: {.columns }
 
::: {.column width="50%" }
**Автоматическое логирование**


- TensorBoard
- TensorBoardX
- Matplotlib


![](images/clearml_auto_metrics.png){fig-align=center}
:::
 
::: {.column width="50%"}
**Ручное логирование метрик**


```python
logger = task.get_logger()

for i in range(100):
    logger.report_scalar(
        "unified graph", "series A", iteration=i, value=1./(i+1)
    )
    logger.report_scalar(
        "unified graph", "series B", iteration=i, value=10./(i+1)
    )
```
![](images/clearml_handle_logging.png){fig-align=center}
:::
::::


:::{.notes}
ClearML автоматически фиксирует показатели, передаваемые в ведущие библиотеки визуализации, такие как TensorBoard и Matplotlib, без необходимости использования дополнительного кода.


Кроме того, ClearML фиксирует и регистрирует все, что выводится на стандартный вывод, — от сообщений отладки до ошибок и предупреждающих сообщений библиотеки.


Информация о графическом процессоре, процессоре, памяти и сети также фиксируется автоматически.


ClearML также поддерживает составление вручную отчетов по нескольким типам показателей и графиков, таких как линейные графики, гистограммы и даже графические диаграммы.


Объект, используемый для ручного логирования метрик, называется logger и получается путем вызова Task.get_logger(). Например в него можно залогировать набор значений и в дальнейшем clearml построит график по тим значениям.
:::


## ClearML logging {.scrollable .smaller}

:::: {.columns }
 
::: {.column width="50%" }
- Текст [report_text](https://clear.ml/docs/latest/docs/references/sdk/logger#report_text)
- Скаляры [report_scalar](https://clear.ml/docs/latest/docs/references/sdk/logger#report_scalar)
- Одинарное значение метрики [report_single_value](https://clear.ml/docs/latest/docs/references/sdk/logger#report_single_value)
- Отладочные примеры
    - Изображений [report_image](https://clear.ml/docs/latest/docs/references/sdk/logger#report_image)
    - HTML и Медиа (аудио, видео) [report_media](https://clear.ml/docs/latest/docs/references/sdk/logger#report_media)
- Jupyter Notebook как отчет по эксперименту [jupiter logging](https://github.com/allegroai/clearml/blob/master/examples/reporting/jupyter_logging_example.ipynb)
:::
::: {.column width="50%" }
- Графики
    - 2D графики [report_scatter2d](https://clear.ml/docs/latest/docs/references/sdk/logger#report_scatter2d)
        - Гистограммы
        - Матрицы ошибок
        - Диаграммы рассеяния
    - 3D графики [report_scatter3d](https://clear.ml/docs/latest/docs/references/sdk/logger#report_scatter3d)
        - Графики поверхностей(surface)
        - Диаграммы рассеяния
    - Таблицы [report_table](https://clear.ml/docs/latest/docs/references/sdk/logger#report_table)
        - Pandas DataFrame
        - CSV-файл
    - Matplotlib figures [report_matplotlib_figure](https://clear.ml/docs/latest/docs/references/sdk/logger#report_matplotlib_figure)
    - Plotly figures [report_plotly](https://clear.ml/docs/latest/docs/references/sdk/logger#report_plotly)
:::
::::

:::{.notes}
Это весь список того что можно передать в logger, то есть можно сохранить текст, метрики, динамику метрик, какие-то графики из сырых данных, matplolib или plotly figures, различные таблицы данных и все это потом будет доступно в clearml при просмотре эксперимента.
:::

## ClearML data{.smaller}


:::: {.columns }
 
::: {.column width="50%" }
clearml-data — Утилита CLI для управления датасетами.


```sh
clearml-data create [-h] [--parents [PARENTS [PARENTS ...]]] [--project PROJECT]
                    --name NAME [--version VERSION] [--output-uri OUTPUT_URI]
                    [--tags [TAGS [TAGS ...]]
```
:::


::: {.column width="50%" }
clearml.Dataset — Интерфейс Python для управления данными.


```python
from clearml import Dataset

dataset = Dataset.create(
  dataset_name='dataset name',
  dataset_project='dataset project',
  dataset_version="1.0",
)
```
:::


::::


![](images/clearml-data.gif){fig-align=center}


:::{.notes}
ClearML Data Management решает две важные задачи:


- Доступность. Обеспечение легкого доступа к данным с любого компьютера.
- Управление версиями — связывание данных и экспериментов для лучшей прослеживаемости.


Наборы clearml dataset можно настроить для наследования от других наборов данных, что позволяет создавать линии передачи данных, а пользователи могут отслеживать, когда и как изменяются их данные. Изменения набора данных сохраняются с использованием дифференцируемого хранилища, то есть версия будет хранить набор изменений из предыдущего родительского набора данных.


Управлять можно из CLI и из питона, используя соответствующие инструменты clearml-data и clearml.Dataset.


К хорошим практикам управления данными относятся:


- версионирование данных (если нужно как-то изменить набор данных, то создайте новую версию набора данных, а не новый датасет, так будет проще отслеживать изменения)
- документирование данных (`Dataset.get_logger()` и вы получаете те же возможности, что и в эксперименте)
- структура данных, наборы данных можно организовывать в проекты (и подпроекты) . Кроме того, при создании набора данных к набору данных можно применять теги, что упростит поиск набора данных.
:::


## Clear ML pipelines


![](images/clearml_pipelines.png){fig-align=center}


:::{.notes}
Пайплайны — это способ оптимизировать и соединить несколько процессов, используя выходные данные одного шага как входные данные другого.


Пайплайны ClearML реализуются с помощью задачи контроллера, которая содержит логику взаимодействия шагов пайплайна. В зависимости от спецификаций, изложенных в задаче контроллера, параметры шага могут быть переопределены, что позволяет использовать продукты выполнения других шагов, такие как артефакты и параметры.


При запуске контроллер последовательно запускает этапы пайплайна. Логика и шаги пайплайна могут выполняться локально или на любом компьютере с помощью Clearml-агента.


ClearML поддерживает несколько режимов выполнения пайлайна:


- Удаленный режим (по умолчанию). В этом режиме логика pipeline controller выполняется через назначенную очередь, и все шаги пайплайна запускаются удаленно через соответствующие очереди. Поскольку каждая задача выполняется независимо, она может контролировать свой репозиторий git (при необходимости), необходимые пакеты Python и конкретный контейнер, который будет использоваться.
- Локальный режим. В этом режиме Пайплайн выполняется локально, а шаги выполняются как подпроцессы. Каждый подпроцесс использует ту же среду Python, что и логика основного пайплайна.
- Режим отладки (для PipelineDecorator). В этом режиме весь пайплайн выполняется локально, при этом контроллер пайплайна и шаги вызываются синхронно, как обычные функции Python, обеспечивая полную возможность отладки каждого вызова функции.




Пайплайны ClearML создаются из кода с использованием одного из следующих способов:


- Класс PipelineController — Pythonic интерфейс для определения и настройки контроллера пайплайна и его шагов. Контроллер и шаги могут быть функциями в вашем коде Python или существующими задачами ClearML .
- Класс PipelineDecorator — набор декораторов Python, которые преобразуют ваши функции в контроллер пайплайна и шаги.


> Поскольку контроллер пайплайна сам по себе является задачей-экспериментом ClearML , его можно использовать в качестве шага пайплайна. Это позволяет создавать более сложные рабочие процессы, например пайплайны, выполняющие другие пайплайны, или пайплайны, выполняющие несколько задач одновременно.
:::

