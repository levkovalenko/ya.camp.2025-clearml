[
  {
    "objectID": "9. clearml_extend_pipes.html",
    "href": "9. clearml_extend_pipes.html",
    "title": "Расширение ClearML pipelines",
    "section": "",
    "text": "Расширение ClearML pipelines\nЕще немного вернемся к пайплайнам, кроме пайплайнов из кода, как это было показано в 5. clearml_pipeline.md, можно создавать пайплайны из задач. Давайте разберемся, что для этого надо и рассмотрим файл mlops-example/5.full_pipe.py.\n\nТочно также инициализируем пайплайн, как делали ранее и задаем ему все необходимые параметры:\n\nfrom clearml import PipelineController\n\npipe = PipelineController(\n    name=\"FullPipeline\",\n    project=\"Amazon reviews\",\n    version=\"0.0.1\",\n    packages=[\"./mlops-example\"],\n    docker=\"python:3.11.13-slim-bookworm\",\n    enable_local_imports=True,\n    # working_dir=\"./mlops-example\",\n)\n\npipe.add_parameter(\n    name=\"dataset_name\",\n    description=\"ClearML dataset name\",\n    default=\"Amazon reviews dataset\",\n)\npipe.add_parameter(\n    name=\"dataset_project\",\n    description=\"ClearML project\",\n    default=\"Amazon reviews\",\n)\npipe.add_parameter(\n    name=\"dataset_version\",\n    description=\"ClearML dataset version\",\n    default=\"1.2\",\n)\npipe.add_parameter(\n    name=\"test_size\", description=\"Test ratio size\", default=0.2, param_type=\"float\"\n)\npipe.add_parameter(\n    name=\"random_state\", description=\"Random state\", default=42, param_type=\"int\"\n)\npipe.add_parameter(\n    name=\"max_features\",\n    description=\"Tf-idf features limit\",\n    default=1000,\n    param_type=\"int\",\n)\npipe.add_parameter(\n    name=\"analyzer\",\n    description=\"Tf-idf analyzer\",\n    default=\"word\",\n    param_type=\"str\",\n)\n\nЗададим первый шаг и включим в него весь пайплайн подготовки данных из mlops-example/5.full_pipe.py. В нем указываем base_task_id=\"1ecd1cacb1db4f40a362a67d629fe14f\", которая определит задачу которая должна выполняться на этом шаге, переопределим ее параметры и донастроим. По параметрам, их нужно писать так: Section/Param name, что бы корректно переопределить.\n\npipe.add_step(\n    name=\"data_prepare\",\n    base_task_id=\"1ecd1cacb1db4f40a362a67d629fe14f\",\n    parameter_override={\n        \"Args/dataset_name\": \"${pipeline.dataset_name}\",\n        \"Args/dataset_project\": \"${pipeline.dataset_project}\",\n        \"Args/dataset_version\": \"${pipeline.dataset_version}\",\n        \"Args/random_state\": \"${pipeline.random_state}\",\n        \"Args/test_size\": \"${pipeline.test_size}\",\n    },\n    cache_executed_step=True,\n    execution_queue=\"default\",\n)\nВ результате при выполнении у нас будет запускаться дополнительно этот пайплайн \n\nЗададим шаг на основе mlops-example/3.tf_idf.py, работа с ним описана в 6. clearml_research.md. Точно также указываем base_task_id=\"b5217b5ef85e4e4aa630c672f8177973\" из clearml и переопределяем параметры, а также указываем что следует она после выполнения подпайплайна data_prepare.\n\npipe.add_step(\n    name=\"fit_model\",\n    base_task_id=\"b5217b5ef85e4e4aa630c672f8177973\",\n    parameter_override={\n        \"General/dataset_name\": \"${pipeline.dataset_name}\",\n        \"General/dataset_project\": \"${pipeline.dataset_project}\",\n        \"General/train_dataset_version\": \"${pipeline.dataset_version}.2\",\n        \"General/test_dataset_version\": \"${pipeline.dataset_version}.3\",\n        \"General/dataset_version\": \"${pipeline.dataset_version}.4\",\n        \"General/random_state\": \"${pipeline.random_state}\",\n        \"General/max_features\": \"${pipeline.max_features}\",\n        \"General/analyzer\": \"${pipeline.analyzer}\",\n    },\n    parents=[\"data_prepare\"],\n    cache_executed_step=True,\n    execution_queue=\"default\",\n)\nПосле выполнения подпайплайна data_prepare переходит к выполнению этой задачи. И так у нас есть цельный пайплайн по обработке данных и обучению модели, который мы можем запустить на любой версии данных.",
    "crumbs": [
      "Практика",
      "Расширение ClearML pipelines"
    ]
  },
  {
    "objectID": "7. clearml_reports.html",
    "href": "7. clearml_reports.html",
    "title": "ClearML Reports",
    "section": "",
    "text": "ClearML предоставляет мощные инструменты для создания отчетов о результатах экспериментов. Отчеты позволяют документировать и визуализировать результаты исследований, сравнивать разные эксперименты и делиться выводами с командой.\n\n\n\nCodeLess отчеты на основе залогированных метрик и артефактов\nСравнение экспериментов в табличном или графическом виде\nВстраивание визуализаций (графики, таблицы, изображения)\nВерсионирование отчетов вместе с экспериментами\n\n\n\n\n\n\nСоздание:\n\nВ разделе Reports → Create New Report\nИспользуйте визуальный редактор или Markdown\n\nНаписание отчета\n\nОписывайте постановку задачи/эксперимента/исследования\nПрикладывайте результаты различных экспериментов и описывайте их\nФиксируйте свои наблюдения и предположения\n\nРевью отчета\n\nОбсуждайте результаты с коллегами\nФиксируйте вопросы к отчетам и замечаниям\nПравьте отчет и дополняйте его\nПосле его полной финализации – опубликуйте его",
    "crumbs": [
      "Практика",
      "ClearML Reports"
    ]
  },
  {
    "objectID": "7. clearml_reports.html#основные-возможности-отчетов",
    "href": "7. clearml_reports.html#основные-возможности-отчетов",
    "title": "ClearML Reports",
    "section": "",
    "text": "CodeLess отчеты на основе залогированных метрик и артефактов\nСравнение экспериментов в табличном или графическом виде\nВстраивание визуализаций (графики, таблицы, изображения)\nВерсионирование отчетов вместе с экспериментами",
    "crumbs": [
      "Практика",
      "ClearML Reports"
    ]
  },
  {
    "objectID": "7. clearml_reports.html#работа-с-отчетами-через-веб-интерфейс",
    "href": "7. clearml_reports.html#работа-с-отчетами-через-веб-интерфейс",
    "title": "ClearML Reports",
    "section": "",
    "text": "Создание:\n\nВ разделе Reports → Create New Report\nИспользуйте визуальный редактор или Markdown\n\nНаписание отчета\n\nОписывайте постановку задачи/эксперимента/исследования\nПрикладывайте результаты различных экспериментов и описывайте их\nФиксируйте свои наблюдения и предположения\n\nРевью отчета\n\nОбсуждайте результаты с коллегами\nФиксируйте вопросы к отчетам и замечаниям\nПравьте отчет и дополняйте его\nПосле его полной финализации – опубликуйте его",
    "crumbs": [
      "Практика",
      "ClearML Reports"
    ]
  },
  {
    "objectID": "5. clearml_pipeline.html",
    "href": "5. clearml_pipeline.html",
    "title": "ClearML Pipelines",
    "section": "",
    "text": "Теперь разберем работу с ClearML agent и ClearML pipeline.\n\n\nБыстрый его запуск разобран в 2. clearml_yandex_kube.md, сейчас мы уделим внимание его более детальной настройки и чуть-уть разберем его helm chart.\nВесь перечень параметров представлен в репозитории clearml-helm-charts\n\nСтоит уделить внимание версии самого ClearML-agent, на момент подготовки курса доступна версия 1.9.3, но она не корректно работает с задачами в очереди (см. issue). Поэту ставим специально понижаем версию до последней рабочей.\n\nagentk8sglue:\n  ...\n  extraEnvs:\n  - name: CLEARML_AGENT_UPDATE_VERSION\n    value: \"==1.9.2\"\n\nТакже стоит изменить образ который будет использоваться для запуска задач на нужный вам (возможно кастомный). Опять же советую использовать python не выше 3.11, что бы не возникало проблем с использованием более старых версий библиотек на следующих этапах.\n\nagentk8sglue:\n  ...\n  defaultContainerImage: python:3.11.13-slim-bookworm\n\nВнеся такие изменения вы в целом можете разворачивать его на kubernetes и использовать для выполнения пайплайнов и экспериментов.\n\n\n\n\nClearML позволяет составлять пайплайны, формируя их из существующих задач или прописывая специализированный код используя pipeline SDK. Сейчас мы разберем пример pipeline реализованного с помощью PipelineController, для этого надо посмотреть в файл 2.train_test_split.py, давайте его запустим:\npixi run python mlops-example/2.train_test_split.py\nА пока он исполняется, разберем код пайплайна:\n\nСоздается основной объект пайплайна, ему указывается имя, проект, версия, специальные зависимости, докер образ для исполнения и возможность локального импорта модулей. Далее мы будем работать с этим объектом и его донастраивать.\n\npipe = PipelineController(\n    name=\"DataPrepare\",\n    project=\"Amazon reviews\",\n    version=\"0.0.1\",\n    packages=[\"./mlops-example\", \"numpy==1.26.4\"],\n    docker=\"python:3.11.13-slim-bookworm\",\n    enable_local_imports=True,\n)\n\nПайплайну задаются основные параметры, которые в дальнейшем мы сможем задавать в интерфейсе clearml.\n\npipe.add_parameter(\n    name=\"dataset_name\",\n    description=\"ClearML dataset name\",\n    default=\"Amazon reviews dataset\",\n)\npipe.add_parameter(\n    name=\"dataset_project\",\n    description=\"ClearML project\",\n    default=\"Amazon reviews\",\n)\npipe.add_parameter(\n    name=\"dataset_version\",\n    description=\"ClearML dataset version\",\n    default=\"1.2\",\n)\npipe.add_parameter(\n    name=\"test_size\", description=\"Test ratio size\", default=0.2, param_type=\"float\"\n)\npipe.add_parameter(\n    name=\"random_state\", description=\"Random state\", default=42, param_type=\"int\"\n)\n\n\nДалее описываются функции, которые будут исполняться. Обратит внимание Что основные импорты находятся внутри функции, это позволяет clearml автоматически считать зависимости которые необходимы для работы этого кода, но на практике лучше вручную задавать зависимости для каждого шага, что бы установить корректные версии библиотек. Здесь пример функции которая занимается разделение данные на train и test, и складывает их в новую версию датасета: X.X.1.\n\ndef dataset_train_test_split(\n    dataset_name,\n    dataset_project,\n    dataset_version,\n    test_size,\n    random_state,\n    version_postfix,\n):\n    from pathlib import Path\n\n    import pandas as pd\n    import polars as pl\n    import pyarrow\n    from clearml import Dataset, Logger\n    from sklearn.model_selection import train_test_split\n\n    print(pyarrow.__version__)\n\n    dataset = Dataset.get(\n        dataset_name=dataset_name,\n        dataset_project=dataset_project,\n        dataset_version=dataset_version,\n    )\n    datset_path = Path(dataset.get_local_copy())\n\n    data: pd.DataFrame = pl.concat(\n        [pl.read_csv(data_file) for data_file in datset_path.iterdir()]\n    )\n    train, test = train_test_split(\n        data.to_pandas(), test_size=float(test_size), random_state=int(random_state)\n    )\n    train_distrib = class_distribution(train, \"Polarity\")\n    test_distrib = class_distribution(test, \"Polarity\")\n    result_path = Path(\"data/prepared/split\")\n    result_path.mkdir(exist_ok=True, parents=True)\n    train.to_csv(result_path / \"raw_train.csv\", index=False)\n    test.to_csv(result_path / \"raw_test.csv\", index=False)\n    prepared_dataset = Dataset.create(\n        dataset_name=dataset_name,\n        dataset_project=dataset_project,\n        dataset_version=f\"{dataset_version}.{version_postfix}\",\n        parent_datasets=[dataset],\n    )\n    prepared_dataset.add_files(result_path)\n    prepared_dataset.upload()\n    prepared_dataset.get_logger().report_plotly(\n        \"Class distribution\", \"Train\", train_distrib\n    )\n    prepared_dataset.get_logger().report_plotly(\n        \"Class distribution\", \"Test\", test_distrib\n    )\n    prepared_dataset.finalize()\n\n    pipe_logger = Logger.current_logger()\n    pipe_logger.report_plotly(\"Class distribution\", \"Train\", train_distrib)\n    pipe_logger.report_plotly(\"Class distribution\", \"Test\", test_distrib)\n    return (\n        pl.from_pandas(train, include_index=False),\n        pl.from_pandas(test, include_index=False),\n        prepared_dataset.id,\n    )\n\nДобавляем первый функциональный шаг, указываем его имя, функцию которая его исполняет, ее аргументы, используя параметры pipeline, так же указываем какие артефакты сохранить на этом шаге в качестве возвращаемых значений функции, указываем что этот шаг может быть закеширован, указываем очередь для передачи ее ClearML agent, если вы ее не настраивали, то это default, Так же у нас идут helper fucntions, они нужны что бы код шага корректно сгенерировался, и наконец специфичные зависимости для шага.\n\npipe.add_function_step(\n    name=\"train_test_split\",\n    function=dataset_train_test_split,\n    function_kwargs=dict(\n        dataset_name=\"${pipeline.dataset_name}\",\n        dataset_project=\"${pipeline.dataset_project}\",\n        dataset_version=\"${pipeline.dataset_version}\",\n        test_size=\"${pipeline.test_size}\",\n        random_state=\"${pipeline.random_state}\",\n        version_postfix=\"1\",\n    ),\n    function_return=[\"raw_train_dataframe\", \"raw_test_dataframe\", \"splited_dataset_id\"],\n    cache_executed_step=True,\n    execution_queue=\"default\",\n    helper_functions=[class_distribution],\n    packages=[\n        \"plotly&gt;=6.2.0,&lt;7\",\n        \"plotly-express&gt;=0.4.1,&lt;0.5\",\n        \"clearml-serving&gt;=1.3.5,&lt;2\",\n        \"scikit-learn==1.2.2\",\n        \"numpy==1.26.4\",\n        \"pandas&gt;=2.3.0,&lt;3\",\n        \"polars&gt;=1.31.0,&lt;2\",\n        \"nltk&gt;=3.9.1,&lt;4\",\n        \"pyarrow&gt;=20.0.0,&lt;21\",\n    ],\n)\nЕще стоит сказать про особенность function_step, в нем ваш код будет преобразован в отдельный скрипт который будет исполняться, поэтому есть такие проблемы с import разных библиотек и тд. Вот пример кода для этого шага, который переработал ClearML:\nfrom clearml import Task\nfrom clearml import TaskTypes\nfrom clearml.automation.controller import PipelineDecorator\nimport inspect\n\nfrom clearml.utilities.proxy_object import get_basic_type\n\n\n\n\n\ntry:\n    import pandas as pd\nexcept Exception as e:\n    print('Import error: ' + str(e))\n\ntry:\n    import plotly.express as px\nexcept Exception as e:\n    print('Import error: ' + str(e))\n\ntry:\n    import plotly.graph_objects as go\nexcept Exception as e:\n    print('Import error: ' + str(e))\n\ndef class_distribution(data, target_col):\n    polarity_distribution = data.groupby(target_col, as_index=False).agg(count=pd.NamedAgg(target_col, 'count'))\n    return px.histogram(polarity_distribution, x=target_col, y='count')\n\ntry:\n    from clearml import PipelineController\nexcept Exception as e:\n    print('Import error: ' + str(e))\n\ntry:\n    from mlops_example.preprocessing import dataframe_preprocessing\nexcept Exception as e:\n    print('Import error: ' + str(e))\n\ntry:\n    from mlops_example.preprocessing import lemmatize\nexcept Exception as e:\n    print('Import error: ' + str(e))\n\ntry:\n    from mlops_example.preprocessing import text_preprocessing\nexcept Exception as e:\n    print('Import error: ' + str(e))\n\ntry:\n    from mlops_example.visualisation import class_distribution\nexcept Exception as e:\n    print('Import error: ' + str(e))\n\ndef dataset_train_test_split(dataset_name, dataset_project, dataset_version, test_size, random_state, version_postfix):\n    from pathlib import Path\n    import pandas as pd\n    import polars as pl\n    import pyarrow\n    from clearml import Dataset, Logger\n    from sklearn.model_selection import train_test_split\n    print(pyarrow.__version__)\n    dataset = Dataset.get(dataset_name=dataset_name, dataset_project=dataset_project, dataset_version=dataset_version)\n    datset_path = Path(dataset.get_local_copy())\n    data: pd.DataFrame = pl.concat([pl.read_csv(data_file) for data_file in datset_path.iterdir()])\n    train, test = train_test_split(data.to_pandas(), test_size=float(test_size), random_state=int(random_state))\n    train_distrib = class_distribution(train, 'Polarity')\n    test_distrib = class_distribution(test, 'Polarity')\n    result_path = Path('data/prepared/split')\n    result_path.mkdir(exist_ok=True, parents=True)\n    train.to_csv(result_path / 'raw_train.csv', index=False)\n    test.to_csv(result_path / 'raw_test.csv', index=False)\n    prepared_dataset = Dataset.create(dataset_name=dataset_name, dataset_project=dataset_project, dataset_version=f'{dataset_version}.{version_postfix}', parent_datasets=[dataset])\n    prepared_dataset.add_files(result_path)\n    prepared_dataset.upload()\n    prepared_dataset.get_logger().report_plotly('Class distribution', 'Train', train_distrib)\n    prepared_dataset.get_logger().report_plotly('Class distribution', 'Test', test_distrib)\n    prepared_dataset.finalize()\n    pipe_logger = Logger.current_logger()\n    pipe_logger.report_plotly('Class distribution', 'Train', train_distrib)\n    pipe_logger.report_plotly('Class distribution', 'Test', test_distrib)\n    return (pl.from_pandas(train, include_index=False), pl.from_pandas(test, include_index=False), prepared_dataset.id)\n\nif __name__ == '__main__':\n    task = Task.init(\n        auto_connect_frameworks=True,\n        auto_connect_arg_parser=True,\n    )\n    kwargs = {'dataset_name': '${pipeline.dataset_name}', 'dataset_project': '${pipeline.dataset_project}', 'dataset_version': '${pipeline.dataset_version}', 'test_size': '${pipeline.test_size}', 'random_state': '${pipeline.random_state}', 'version_postfix': '1'}\n    task.connect(kwargs, name='kwargs')\n    function_input_artifacts = {}\n    params = task.get_parameters(cast=True) or dict()\n    argspec = inspect.getfullargspec(dataset_train_test_split)\n    if argspec.varkw is not None or argspec.varargs is not None:\n        for k, v in params.items():\n            if k.startswith('kwargs/'):\n                kwargs[k.replace('kwargs/', '', 1)] = v\n    return_section = 'return'\n    for k, v in params.items():\n        if not v or not k.startswith('kwargs_artifacts/'):\n            continue\n        k = k.replace('kwargs_artifacts/', '', 1)\n        task_id, artifact_name = v.split('.', 1)\n        parent_task = Task.get_task(task_id=task_id)\n        if artifact_name in parent_task.artifacts:\n            kwargs[k] = parent_task.artifacts[artifact_name].get(deserialization_function=None)\n        else:\n            kwargs[k] = parent_task.get_parameters(cast=True).get(return_section + '/' + artifact_name)\n    if '0' in kwargs:  # *args arguments are present\n        pos_args = [kwargs.pop(arg, None) for arg in (argspec.args or [])]\n        other_pos_args_index = 0\n        while str(other_pos_args_index) in kwargs:\n            pos_args.append(kwargs.pop(str(other_pos_args_index)))\n            other_pos_args_index += 1\n        results = dataset_train_test_split(*pos_args, **kwargs)\n    else:\n        results = dataset_train_test_split(**kwargs)\n    result_names = ['raw_train_dataframe', 'raw_test_dataframe', 'splited_dataset_id']\n    if result_names:\n        if not isinstance(results, (tuple, list)) or len(result_names) == 1:\n            results = [results]\n        parameters = dict()\n        parameters_types = dict()\n        for name, artifact in zip(result_names, results):\n            if type(artifact) in (float, int, bool, str):\n                parameters[return_section + '/' + name] = artifact\n                parameters_types[return_section + '/' + name] = get_basic_type(artifact)\n            else:\n                task.upload_artifact(\n                    name=name,\n                    artifact_object=artifact,\n                    extension_name='.pkl' if isinstance(artifact, dict) else None,\n                    serialization_function=None\n                )\n        if parameters:\n            task._set_parameters(parameters, __parameters_types=parameters_types, __update=True)\n\nПрописываем все функцию для препроцессинга данных с помощью nltk.\n\ndef dataset_preprocessing(\n    dataframe,\n    parent_dataset,\n    dataset_name,\n    dataset_project,\n    dataset_version,\n    version_postfix,\n    frame_name,\n):\n    from pathlib import Path\n\n    import nltk\n    import polars as pl\n    import pyarrow\n    from clearml import Dataset\n\n    print(pyarrow.__version__)\n\n    nltk.download(\"stopwords\")\n    nltk.download(\"wordnet\")\n\n    prepared_dataset = Dataset.create(\n        dataset_name=dataset_name,\n        dataset_project=dataset_project,\n        dataset_version=f\"{dataset_version}.{version_postfix}\",\n        parent_datasets=[parent_dataset],\n    )\n    dataframe: pl.DataFrame\n    processed_dataframe = dataframe_preprocessing(dataframe, \"Review\")\n\n    result_path = Path(\"data/prepared/processed\")\n    result_path.mkdir(exist_ok=True, parents=True)\n    processed_dataframe.write_parquet(result_path / f\"processed_{frame_name}.parquet\")\n\n    prepared_dataset.add_files(result_path)\n    prepared_dataset.upload()\n    prepared_dataset.finalize()\n    return processed_dataframe, prepared_dataset.id\n\nИ задаем для нее два шага, для обработки обучающей и тестовой выборок. Можно заметить что в параметризации функции у нас также используются и сохраненные артефакты шагаtrain_test_split, а также появился параметр parents, позволяющий строить пайплайн. Кстати, эти шаги будут выполняться паралельно.\n\npipe.add_function_step(\n    name=\"train_processing\",\n    function=dataset_preprocessing,\n    function_kwargs=dict(\n        dataframe=\"${train_test_split.raw_train_dataframe}\",\n        parent_dataset=\"${train_test_split.splited_dataset_id}\",\n        dataset_name=\"${pipeline.dataset_name}\",\n        dataset_project=\"${pipeline.dataset_project}\",\n        dataset_version=\"${pipeline.dataset_version}\",\n        version_postfix=\"2\",\n        frame_name=\"train\",\n    ),\n    function_return=[\"processed_train_dataframe\", \"dataset_id\"],\n    cache_executed_step=True,\n    execution_queue=\"default\",\n    helper_functions=[lemmatize, dataframe_preprocessing, text_preprocessing],\n    parents=[\"train_test_split\"],\n    packages=[\n        \"plotly&gt;=6.2.0,&lt;7\",\n        \"plotly-express&gt;=0.4.1,&lt;0.5\",\n        \"clearml-serving&gt;=1.3.5,&lt;2\",\n        \"scikit-learn==1.2.2\",\n        \"numpy==1.26.4\",\n        \"pandas&gt;=2.3.0,&lt;3\",\n        \"polars&gt;=1.31.0,&lt;2\",\n        \"nltk&gt;=3.9.1,&lt;4\",\n        \"pyarrow&gt;=20.0.0,&lt;21\",\n    ],\n)\n\npipe.add_function_step(\n    name=\"test_processing\",\n    function=dataset_preprocessing,\n    function_kwargs=dict(\n        dataframe=\"${train_test_split.raw_test_dataframe}\",\n        parent_dataset=\"${train_test_split.splited_dataset_id}\",\n        dataset_name=\"${pipeline.dataset_name}\",\n        dataset_project=\"${pipeline.dataset_project}\",\n        dataset_version=\"${pipeline.dataset_version}\",\n        version_postfix=\"3\",\n        frame_name=\"test\",\n    ),\n    function_return=[\"processed_test_dataframe\", \"dataset_id\"],\n    cache_executed_step=True,\n    execution_queue=\"default\",\n    helper_functions=[lemmatize, dataframe_preprocessing, text_preprocessing],\n    parents=[\"train_test_split\"],\n    packages=[\n        \"plotly&gt;=6.2.0,&lt;7\",\n        \"plotly-express&gt;=0.4.1,&lt;0.5\",\n        \"clearml-serving&gt;=1.3.5,&lt;2\",\n        \"scikit-learn==1.2.2\",\n        \"numpy==1.26.4\",\n        \"pandas&gt;=2.3.0,&lt;3\",\n        \"polars&gt;=1.31.0,&lt;2\",\n        \"nltk&gt;=3.9.1,&lt;4\",\n        \"pyarrow&gt;=20.0.0,&lt;21\",\n    ],\n)\n\nТеперь непосредственно команда запуска. Есть два варианта запуска start и start_locally.Первая (start) запускает сборку и исполнение pipeline на стороне агента, то есть агент установит окружение пайплайна и начнемт подготовку кода для каждого из шагов, затем непосредсвенно начнет выполнение шагов. По сути это не блокирующая команда которая направляет задачу агенту и он ее выполняет. Второй вариант start_locally позволяет сконфигурировать пайплайн локлаьно и только шаги исполнить удаленно, но если указать start_locally(run_pipeline_steps_locally=True), то и шаги пайплайна будут исполнены локально, что может быть удобно для дебага.\n\npipe.start()\nВы можете перейти в clearml и увидеть что ваш pipeline выполняется:  Посмотреть его логи можно в поде clearml-id-xxxxxxx:  Или в консоле пайплайна.\n\nКогда пайплайн завершился, можно посотреть всю инфомрацию о нем: настройки, изменения, заисимости, артефакты и тд.     \nТеперь мы легко можем запускать этот пайплайн для других верси датасета, для этого надо клинкнуть по нему пкм и надать run, тогда появится окно задания настрое, напрмиер поставим версию 1.3.   В процессе вы увидите что у вас динамически создаются worker для обработки шагов пайплайна",
    "crumbs": [
      "Практика",
      "ClearML Pipelines"
    ]
  },
  {
    "objectID": "5. clearml_pipeline.html#настойка-clearml-agent",
    "href": "5. clearml_pipeline.html#настойка-clearml-agent",
    "title": "ClearML Pipelines",
    "section": "",
    "text": "Быстрый его запуск разобран в 2. clearml_yandex_kube.md, сейчас мы уделим внимание его более детальной настройки и чуть-уть разберем его helm chart.\nВесь перечень параметров представлен в репозитории clearml-helm-charts\n\nСтоит уделить внимание версии самого ClearML-agent, на момент подготовки курса доступна версия 1.9.3, но она не корректно работает с задачами в очереди (см. issue). Поэту ставим специально понижаем версию до последней рабочей.\n\nagentk8sglue:\n  ...\n  extraEnvs:\n  - name: CLEARML_AGENT_UPDATE_VERSION\n    value: \"==1.9.2\"\n\nТакже стоит изменить образ который будет использоваться для запуска задач на нужный вам (возможно кастомный). Опять же советую использовать python не выше 3.11, что бы не возникало проблем с использованием более старых версий библиотек на следующих этапах.\n\nagentk8sglue:\n  ...\n  defaultContainerImage: python:3.11.13-slim-bookworm\n\nВнеся такие изменения вы в целом можете разворачивать его на kubernetes и использовать для выполнения пайплайнов и экспериментов.",
    "crumbs": [
      "Практика",
      "ClearML Pipelines"
    ]
  },
  {
    "objectID": "5. clearml_pipeline.html#clearml-pipeline",
    "href": "5. clearml_pipeline.html#clearml-pipeline",
    "title": "ClearML Pipelines",
    "section": "",
    "text": "ClearML позволяет составлять пайплайны, формируя их из существующих задач или прописывая специализированный код используя pipeline SDK. Сейчас мы разберем пример pipeline реализованного с помощью PipelineController, для этого надо посмотреть в файл 2.train_test_split.py, давайте его запустим:\npixi run python mlops-example/2.train_test_split.py\nА пока он исполняется, разберем код пайплайна:\n\nСоздается основной объект пайплайна, ему указывается имя, проект, версия, специальные зависимости, докер образ для исполнения и возможность локального импорта модулей. Далее мы будем работать с этим объектом и его донастраивать.\n\npipe = PipelineController(\n    name=\"DataPrepare\",\n    project=\"Amazon reviews\",\n    version=\"0.0.1\",\n    packages=[\"./mlops-example\", \"numpy==1.26.4\"],\n    docker=\"python:3.11.13-slim-bookworm\",\n    enable_local_imports=True,\n)\n\nПайплайну задаются основные параметры, которые в дальнейшем мы сможем задавать в интерфейсе clearml.\n\npipe.add_parameter(\n    name=\"dataset_name\",\n    description=\"ClearML dataset name\",\n    default=\"Amazon reviews dataset\",\n)\npipe.add_parameter(\n    name=\"dataset_project\",\n    description=\"ClearML project\",\n    default=\"Amazon reviews\",\n)\npipe.add_parameter(\n    name=\"dataset_version\",\n    description=\"ClearML dataset version\",\n    default=\"1.2\",\n)\npipe.add_parameter(\n    name=\"test_size\", description=\"Test ratio size\", default=0.2, param_type=\"float\"\n)\npipe.add_parameter(\n    name=\"random_state\", description=\"Random state\", default=42, param_type=\"int\"\n)\n\n\nДалее описываются функции, которые будут исполняться. Обратит внимание Что основные импорты находятся внутри функции, это позволяет clearml автоматически считать зависимости которые необходимы для работы этого кода, но на практике лучше вручную задавать зависимости для каждого шага, что бы установить корректные версии библиотек. Здесь пример функции которая занимается разделение данные на train и test, и складывает их в новую версию датасета: X.X.1.\n\ndef dataset_train_test_split(\n    dataset_name,\n    dataset_project,\n    dataset_version,\n    test_size,\n    random_state,\n    version_postfix,\n):\n    from pathlib import Path\n\n    import pandas as pd\n    import polars as pl\n    import pyarrow\n    from clearml import Dataset, Logger\n    from sklearn.model_selection import train_test_split\n\n    print(pyarrow.__version__)\n\n    dataset = Dataset.get(\n        dataset_name=dataset_name,\n        dataset_project=dataset_project,\n        dataset_version=dataset_version,\n    )\n    datset_path = Path(dataset.get_local_copy())\n\n    data: pd.DataFrame = pl.concat(\n        [pl.read_csv(data_file) for data_file in datset_path.iterdir()]\n    )\n    train, test = train_test_split(\n        data.to_pandas(), test_size=float(test_size), random_state=int(random_state)\n    )\n    train_distrib = class_distribution(train, \"Polarity\")\n    test_distrib = class_distribution(test, \"Polarity\")\n    result_path = Path(\"data/prepared/split\")\n    result_path.mkdir(exist_ok=True, parents=True)\n    train.to_csv(result_path / \"raw_train.csv\", index=False)\n    test.to_csv(result_path / \"raw_test.csv\", index=False)\n    prepared_dataset = Dataset.create(\n        dataset_name=dataset_name,\n        dataset_project=dataset_project,\n        dataset_version=f\"{dataset_version}.{version_postfix}\",\n        parent_datasets=[dataset],\n    )\n    prepared_dataset.add_files(result_path)\n    prepared_dataset.upload()\n    prepared_dataset.get_logger().report_plotly(\n        \"Class distribution\", \"Train\", train_distrib\n    )\n    prepared_dataset.get_logger().report_plotly(\n        \"Class distribution\", \"Test\", test_distrib\n    )\n    prepared_dataset.finalize()\n\n    pipe_logger = Logger.current_logger()\n    pipe_logger.report_plotly(\"Class distribution\", \"Train\", train_distrib)\n    pipe_logger.report_plotly(\"Class distribution\", \"Test\", test_distrib)\n    return (\n        pl.from_pandas(train, include_index=False),\n        pl.from_pandas(test, include_index=False),\n        prepared_dataset.id,\n    )\n\nДобавляем первый функциональный шаг, указываем его имя, функцию которая его исполняет, ее аргументы, используя параметры pipeline, так же указываем какие артефакты сохранить на этом шаге в качестве возвращаемых значений функции, указываем что этот шаг может быть закеширован, указываем очередь для передачи ее ClearML agent, если вы ее не настраивали, то это default, Так же у нас идут helper fucntions, они нужны что бы код шага корректно сгенерировался, и наконец специфичные зависимости для шага.\n\npipe.add_function_step(\n    name=\"train_test_split\",\n    function=dataset_train_test_split,\n    function_kwargs=dict(\n        dataset_name=\"${pipeline.dataset_name}\",\n        dataset_project=\"${pipeline.dataset_project}\",\n        dataset_version=\"${pipeline.dataset_version}\",\n        test_size=\"${pipeline.test_size}\",\n        random_state=\"${pipeline.random_state}\",\n        version_postfix=\"1\",\n    ),\n    function_return=[\"raw_train_dataframe\", \"raw_test_dataframe\", \"splited_dataset_id\"],\n    cache_executed_step=True,\n    execution_queue=\"default\",\n    helper_functions=[class_distribution],\n    packages=[\n        \"plotly&gt;=6.2.0,&lt;7\",\n        \"plotly-express&gt;=0.4.1,&lt;0.5\",\n        \"clearml-serving&gt;=1.3.5,&lt;2\",\n        \"scikit-learn==1.2.2\",\n        \"numpy==1.26.4\",\n        \"pandas&gt;=2.3.0,&lt;3\",\n        \"polars&gt;=1.31.0,&lt;2\",\n        \"nltk&gt;=3.9.1,&lt;4\",\n        \"pyarrow&gt;=20.0.0,&lt;21\",\n    ],\n)\nЕще стоит сказать про особенность function_step, в нем ваш код будет преобразован в отдельный скрипт который будет исполняться, поэтому есть такие проблемы с import разных библиотек и тд. Вот пример кода для этого шага, который переработал ClearML:\nfrom clearml import Task\nfrom clearml import TaskTypes\nfrom clearml.automation.controller import PipelineDecorator\nimport inspect\n\nfrom clearml.utilities.proxy_object import get_basic_type\n\n\n\n\n\ntry:\n    import pandas as pd\nexcept Exception as e:\n    print('Import error: ' + str(e))\n\ntry:\n    import plotly.express as px\nexcept Exception as e:\n    print('Import error: ' + str(e))\n\ntry:\n    import plotly.graph_objects as go\nexcept Exception as e:\n    print('Import error: ' + str(e))\n\ndef class_distribution(data, target_col):\n    polarity_distribution = data.groupby(target_col, as_index=False).agg(count=pd.NamedAgg(target_col, 'count'))\n    return px.histogram(polarity_distribution, x=target_col, y='count')\n\ntry:\n    from clearml import PipelineController\nexcept Exception as e:\n    print('Import error: ' + str(e))\n\ntry:\n    from mlops_example.preprocessing import dataframe_preprocessing\nexcept Exception as e:\n    print('Import error: ' + str(e))\n\ntry:\n    from mlops_example.preprocessing import lemmatize\nexcept Exception as e:\n    print('Import error: ' + str(e))\n\ntry:\n    from mlops_example.preprocessing import text_preprocessing\nexcept Exception as e:\n    print('Import error: ' + str(e))\n\ntry:\n    from mlops_example.visualisation import class_distribution\nexcept Exception as e:\n    print('Import error: ' + str(e))\n\ndef dataset_train_test_split(dataset_name, dataset_project, dataset_version, test_size, random_state, version_postfix):\n    from pathlib import Path\n    import pandas as pd\n    import polars as pl\n    import pyarrow\n    from clearml import Dataset, Logger\n    from sklearn.model_selection import train_test_split\n    print(pyarrow.__version__)\n    dataset = Dataset.get(dataset_name=dataset_name, dataset_project=dataset_project, dataset_version=dataset_version)\n    datset_path = Path(dataset.get_local_copy())\n    data: pd.DataFrame = pl.concat([pl.read_csv(data_file) for data_file in datset_path.iterdir()])\n    train, test = train_test_split(data.to_pandas(), test_size=float(test_size), random_state=int(random_state))\n    train_distrib = class_distribution(train, 'Polarity')\n    test_distrib = class_distribution(test, 'Polarity')\n    result_path = Path('data/prepared/split')\n    result_path.mkdir(exist_ok=True, parents=True)\n    train.to_csv(result_path / 'raw_train.csv', index=False)\n    test.to_csv(result_path / 'raw_test.csv', index=False)\n    prepared_dataset = Dataset.create(dataset_name=dataset_name, dataset_project=dataset_project, dataset_version=f'{dataset_version}.{version_postfix}', parent_datasets=[dataset])\n    prepared_dataset.add_files(result_path)\n    prepared_dataset.upload()\n    prepared_dataset.get_logger().report_plotly('Class distribution', 'Train', train_distrib)\n    prepared_dataset.get_logger().report_plotly('Class distribution', 'Test', test_distrib)\n    prepared_dataset.finalize()\n    pipe_logger = Logger.current_logger()\n    pipe_logger.report_plotly('Class distribution', 'Train', train_distrib)\n    pipe_logger.report_plotly('Class distribution', 'Test', test_distrib)\n    return (pl.from_pandas(train, include_index=False), pl.from_pandas(test, include_index=False), prepared_dataset.id)\n\nif __name__ == '__main__':\n    task = Task.init(\n        auto_connect_frameworks=True,\n        auto_connect_arg_parser=True,\n    )\n    kwargs = {'dataset_name': '${pipeline.dataset_name}', 'dataset_project': '${pipeline.dataset_project}', 'dataset_version': '${pipeline.dataset_version}', 'test_size': '${pipeline.test_size}', 'random_state': '${pipeline.random_state}', 'version_postfix': '1'}\n    task.connect(kwargs, name='kwargs')\n    function_input_artifacts = {}\n    params = task.get_parameters(cast=True) or dict()\n    argspec = inspect.getfullargspec(dataset_train_test_split)\n    if argspec.varkw is not None or argspec.varargs is not None:\n        for k, v in params.items():\n            if k.startswith('kwargs/'):\n                kwargs[k.replace('kwargs/', '', 1)] = v\n    return_section = 'return'\n    for k, v in params.items():\n        if not v or not k.startswith('kwargs_artifacts/'):\n            continue\n        k = k.replace('kwargs_artifacts/', '', 1)\n        task_id, artifact_name = v.split('.', 1)\n        parent_task = Task.get_task(task_id=task_id)\n        if artifact_name in parent_task.artifacts:\n            kwargs[k] = parent_task.artifacts[artifact_name].get(deserialization_function=None)\n        else:\n            kwargs[k] = parent_task.get_parameters(cast=True).get(return_section + '/' + artifact_name)\n    if '0' in kwargs:  # *args arguments are present\n        pos_args = [kwargs.pop(arg, None) for arg in (argspec.args or [])]\n        other_pos_args_index = 0\n        while str(other_pos_args_index) in kwargs:\n            pos_args.append(kwargs.pop(str(other_pos_args_index)))\n            other_pos_args_index += 1\n        results = dataset_train_test_split(*pos_args, **kwargs)\n    else:\n        results = dataset_train_test_split(**kwargs)\n    result_names = ['raw_train_dataframe', 'raw_test_dataframe', 'splited_dataset_id']\n    if result_names:\n        if not isinstance(results, (tuple, list)) or len(result_names) == 1:\n            results = [results]\n        parameters = dict()\n        parameters_types = dict()\n        for name, artifact in zip(result_names, results):\n            if type(artifact) in (float, int, bool, str):\n                parameters[return_section + '/' + name] = artifact\n                parameters_types[return_section + '/' + name] = get_basic_type(artifact)\n            else:\n                task.upload_artifact(\n                    name=name,\n                    artifact_object=artifact,\n                    extension_name='.pkl' if isinstance(artifact, dict) else None,\n                    serialization_function=None\n                )\n        if parameters:\n            task._set_parameters(parameters, __parameters_types=parameters_types, __update=True)\n\nПрописываем все функцию для препроцессинга данных с помощью nltk.\n\ndef dataset_preprocessing(\n    dataframe,\n    parent_dataset,\n    dataset_name,\n    dataset_project,\n    dataset_version,\n    version_postfix,\n    frame_name,\n):\n    from pathlib import Path\n\n    import nltk\n    import polars as pl\n    import pyarrow\n    from clearml import Dataset\n\n    print(pyarrow.__version__)\n\n    nltk.download(\"stopwords\")\n    nltk.download(\"wordnet\")\n\n    prepared_dataset = Dataset.create(\n        dataset_name=dataset_name,\n        dataset_project=dataset_project,\n        dataset_version=f\"{dataset_version}.{version_postfix}\",\n        parent_datasets=[parent_dataset],\n    )\n    dataframe: pl.DataFrame\n    processed_dataframe = dataframe_preprocessing(dataframe, \"Review\")\n\n    result_path = Path(\"data/prepared/processed\")\n    result_path.mkdir(exist_ok=True, parents=True)\n    processed_dataframe.write_parquet(result_path / f\"processed_{frame_name}.parquet\")\n\n    prepared_dataset.add_files(result_path)\n    prepared_dataset.upload()\n    prepared_dataset.finalize()\n    return processed_dataframe, prepared_dataset.id\n\nИ задаем для нее два шага, для обработки обучающей и тестовой выборок. Можно заметить что в параметризации функции у нас также используются и сохраненные артефакты шагаtrain_test_split, а также появился параметр parents, позволяющий строить пайплайн. Кстати, эти шаги будут выполняться паралельно.\n\npipe.add_function_step(\n    name=\"train_processing\",\n    function=dataset_preprocessing,\n    function_kwargs=dict(\n        dataframe=\"${train_test_split.raw_train_dataframe}\",\n        parent_dataset=\"${train_test_split.splited_dataset_id}\",\n        dataset_name=\"${pipeline.dataset_name}\",\n        dataset_project=\"${pipeline.dataset_project}\",\n        dataset_version=\"${pipeline.dataset_version}\",\n        version_postfix=\"2\",\n        frame_name=\"train\",\n    ),\n    function_return=[\"processed_train_dataframe\", \"dataset_id\"],\n    cache_executed_step=True,\n    execution_queue=\"default\",\n    helper_functions=[lemmatize, dataframe_preprocessing, text_preprocessing],\n    parents=[\"train_test_split\"],\n    packages=[\n        \"plotly&gt;=6.2.0,&lt;7\",\n        \"plotly-express&gt;=0.4.1,&lt;0.5\",\n        \"clearml-serving&gt;=1.3.5,&lt;2\",\n        \"scikit-learn==1.2.2\",\n        \"numpy==1.26.4\",\n        \"pandas&gt;=2.3.0,&lt;3\",\n        \"polars&gt;=1.31.0,&lt;2\",\n        \"nltk&gt;=3.9.1,&lt;4\",\n        \"pyarrow&gt;=20.0.0,&lt;21\",\n    ],\n)\n\npipe.add_function_step(\n    name=\"test_processing\",\n    function=dataset_preprocessing,\n    function_kwargs=dict(\n        dataframe=\"${train_test_split.raw_test_dataframe}\",\n        parent_dataset=\"${train_test_split.splited_dataset_id}\",\n        dataset_name=\"${pipeline.dataset_name}\",\n        dataset_project=\"${pipeline.dataset_project}\",\n        dataset_version=\"${pipeline.dataset_version}\",\n        version_postfix=\"3\",\n        frame_name=\"test\",\n    ),\n    function_return=[\"processed_test_dataframe\", \"dataset_id\"],\n    cache_executed_step=True,\n    execution_queue=\"default\",\n    helper_functions=[lemmatize, dataframe_preprocessing, text_preprocessing],\n    parents=[\"train_test_split\"],\n    packages=[\n        \"plotly&gt;=6.2.0,&lt;7\",\n        \"plotly-express&gt;=0.4.1,&lt;0.5\",\n        \"clearml-serving&gt;=1.3.5,&lt;2\",\n        \"scikit-learn==1.2.2\",\n        \"numpy==1.26.4\",\n        \"pandas&gt;=2.3.0,&lt;3\",\n        \"polars&gt;=1.31.0,&lt;2\",\n        \"nltk&gt;=3.9.1,&lt;4\",\n        \"pyarrow&gt;=20.0.0,&lt;21\",\n    ],\n)\n\nТеперь непосредственно команда запуска. Есть два варианта запуска start и start_locally.Первая (start) запускает сборку и исполнение pipeline на стороне агента, то есть агент установит окружение пайплайна и начнемт подготовку кода для каждого из шагов, затем непосредсвенно начнет выполнение шагов. По сути это не блокирующая команда которая направляет задачу агенту и он ее выполняет. Второй вариант start_locally позволяет сконфигурировать пайплайн локлаьно и только шаги исполнить удаленно, но если указать start_locally(run_pipeline_steps_locally=True), то и шаги пайплайна будут исполнены локально, что может быть удобно для дебага.\n\npipe.start()\nВы можете перейти в clearml и увидеть что ваш pipeline выполняется:  Посмотреть его логи можно в поде clearml-id-xxxxxxx:  Или в консоле пайплайна.\n\nКогда пайплайн завершился, можно посотреть всю инфомрацию о нем: настройки, изменения, заисимости, артефакты и тд.     \nТеперь мы легко можем запускать этот пайплайн для других верси датасета, для этого надо клинкнуть по нему пкм и надать run, тогда появится окно задания настрое, напрмиер поставим версию 1.3.   В процессе вы увидите что у вас динамически создаются worker для обработки шагов пайплайна",
    "crumbs": [
      "Практика",
      "ClearML Pipelines"
    ]
  },
  {
    "objectID": "3. clearml_work.html",
    "href": "3. clearml_work.html",
    "title": "Работа с ClearML",
    "section": "",
    "text": "Для начала зайдите на свой ClearML, в примере он развернут на http://51.250.106.18:30080/. Его адрес можно найти в информации об узле на котором развернут pod: \nЗайдите в Settings -&gt; Workspace и там нажмите Create new credentials: \nВам покажется модельное окно с сгенерированными credentials, выполните инструкцию написанную в нем: скопируйте текст credentials в ~/clearml.conf:\napi {\n    web_server:http://51.250.106.18:30080/\n    api_server:http://51.250.106.18:30008\n    files_server:http://51.250.106.18:30081\n    credentials {\n        \"access_key\"=\"ACCESSKEY\"\n        \"secret_key\"=\"SECRETKEY\"\n    }\n}\nОсталось установить библиотеку clearml для полноценной работы.\n\n\n\nДля примера использовался пакетный менеджер pixi, что бы его установить выполните команду:\necho PIXI_VERSION=0.48.2 && curl -fsSL https://pixi.sh/install.sh | sh\nПоскольку инструмент еще на стадии активной разработки то меду версиями могут быть различия и breaking changes, поэтому обратите внимание на версию 0.48.2.\nПосле успешной установки перейдите в папку mlops-example и выполните команду:\npixi install -a\nСразу обращу внимание, что не стоит гнаться за последними версиями библиотек. Ограничитесь python==3.11, scikit-learn==1.2.2, numpy==1.26.4. Это важно потому что на шагах связанных с разверткой моделей у вас могут появиться не состыковки по версиям поддерживаемых зависимостей и придется или менять версии библиотек в ваших экспериментах (как это было при подготовке примера), или собирать свои кастомные образы для serving’а моделей с обновленными зависимостями.\nДля дальнейшей работы в окружении вы можете выполнить команду pixi shell или каждую команду начинать с pixi run ...",
    "crumbs": [
      "Практика",
      "Работа с ClearML"
    ]
  },
  {
    "objectID": "3. clearml_work.html#настройка-clearml",
    "href": "3. clearml_work.html#настройка-clearml",
    "title": "Работа с ClearML",
    "section": "",
    "text": "Для начала зайдите на свой ClearML, в примере он развернут на http://51.250.106.18:30080/. Его адрес можно найти в информации об узле на котором развернут pod: \nЗайдите в Settings -&gt; Workspace и там нажмите Create new credentials: \nВам покажется модельное окно с сгенерированными credentials, выполните инструкцию написанную в нем: скопируйте текст credentials в ~/clearml.conf:\napi {\n    web_server:http://51.250.106.18:30080/\n    api_server:http://51.250.106.18:30008\n    files_server:http://51.250.106.18:30081\n    credentials {\n        \"access_key\"=\"ACCESSKEY\"\n        \"secret_key\"=\"SECRETKEY\"\n    }\n}\nОсталось установить библиотеку clearml для полноценной работы.",
    "crumbs": [
      "Практика",
      "Работа с ClearML"
    ]
  },
  {
    "objectID": "3. clearml_work.html#настройка-окружения-mlops-example",
    "href": "3. clearml_work.html#настройка-окружения-mlops-example",
    "title": "Работа с ClearML",
    "section": "",
    "text": "Для примера использовался пакетный менеджер pixi, что бы его установить выполните команду:\necho PIXI_VERSION=0.48.2 && curl -fsSL https://pixi.sh/install.sh | sh\nПоскольку инструмент еще на стадии активной разработки то меду версиями могут быть различия и breaking changes, поэтому обратите внимание на версию 0.48.2.\nПосле успешной установки перейдите в папку mlops-example и выполните команду:\npixi install -a\nСразу обращу внимание, что не стоит гнаться за последними версиями библиотек. Ограничитесь python==3.11, scikit-learn==1.2.2, numpy==1.26.4. Это важно потому что на шагах связанных с разверткой моделей у вас могут появиться не состыковки по версиям поддерживаемых зависимостей и придется или менять версии библиотек в ваших экспериментах (как это было при подготовке примера), или собирать свои кастомные образы для serving’а моделей с обновленными зависимостями.\nДля дальнейшей работы в окружении вы можете выполнить команду pixi shell или каждую команду начинать с pixi run ...",
    "crumbs": [
      "Практика",
      "Работа с ClearML"
    ]
  },
  {
    "objectID": "1. yandex_kube.html",
    "href": "1. yandex_kube.html",
    "title": "Настройка Yandex Kubernetes",
    "section": "",
    "text": "Общая инструкция по настройке Yandex Kubernetes\n\n\nСоздайте кластер вот с такой конфигурацией: \nСоздайте В нем группу узлов вот с такой конфигурацией: \n\n\n\nИнструкция по установке от yandex\nСкачайте скрипт установки и запустите:\ncurl -sSL https://storage.yandexcloud.net/yandexcloud-yc/install.sh | bash\nПолучите ваш OauthToken и задайте его yc.\nyc config set token &lt;OAuth-токен&gt;\n\n\n\nИнструкция по установке от Kubernetes\nСкачайте к себе собранный бинарник kubectl\ncurl -LO https://dl.k8s.io/release/v1.33.0/bin/linux/amd64/kubectl\nИзмените права для исполнения kubectl\nchmod +x ./kubectl\nПереместите его в системную папку bin\nsudo mv ./kubectl /usr/local/bin/kubectl\n\n\n\nНастройте доступ к kubectl к кластеру\nyc managed-kubernetes cluster get-credentials --id &lt;Cluster ID&gt; --external\n\nПроверьте что все работает\nkubectl config view\nили\nkubectl get nodes\n\n\n\nСкачайте скрипт установки (см инструкцию helm)\ncurl -fsSL -o get_helm.sh https://raw.githubusercontent.com/helm/helm/main/scripts/get-helm-3\nИзмените права для запуска\nchmod 700 get_helm.sh\nЗапустите установку\n./get_helm.sh\n\n\n\nЧто бы подключить helm к yc выполните команду, воспользуйтесь своим OauthToken\nhelm registry login registry.yandexcloud.net -u oauth\nPassword: &lt;OAuth-токен&gt;",
    "crumbs": [
      "Практика",
      "Настройка Yandex Kubernetes"
    ]
  },
  {
    "objectID": "1. yandex_kube.html#создание-кластера-kubernetes",
    "href": "1. yandex_kube.html#создание-кластера-kubernetes",
    "title": "Настройка Yandex Kubernetes",
    "section": "",
    "text": "Создайте кластер вот с такой конфигурацией: \nСоздайте В нем группу узлов вот с такой конфигурацией:",
    "crumbs": [
      "Практика",
      "Настройка Yandex Kubernetes"
    ]
  },
  {
    "objectID": "1. yandex_kube.html#установка-yc",
    "href": "1. yandex_kube.html#установка-yc",
    "title": "Настройка Yandex Kubernetes",
    "section": "",
    "text": "Инструкция по установке от yandex\nСкачайте скрипт установки и запустите:\ncurl -sSL https://storage.yandexcloud.net/yandexcloud-yc/install.sh | bash\nПолучите ваш OauthToken и задайте его yc.\nyc config set token &lt;OAuth-токен&gt;",
    "crumbs": [
      "Практика",
      "Настройка Yandex Kubernetes"
    ]
  },
  {
    "objectID": "1. yandex_kube.html#установка-kubectl",
    "href": "1. yandex_kube.html#установка-kubectl",
    "title": "Настройка Yandex Kubernetes",
    "section": "",
    "text": "Инструкция по установке от Kubernetes\nСкачайте к себе собранный бинарник kubectl\ncurl -LO https://dl.k8s.io/release/v1.33.0/bin/linux/amd64/kubectl\nИзмените права для исполнения kubectl\nchmod +x ./kubectl\nПереместите его в системную папку bin\nsudo mv ./kubectl /usr/local/bin/kubectl",
    "crumbs": [
      "Практика",
      "Настройка Yandex Kubernetes"
    ]
  },
  {
    "objectID": "1. yandex_kube.html#настройка-доступов-kubectl",
    "href": "1. yandex_kube.html#настройка-доступов-kubectl",
    "title": "Настройка Yandex Kubernetes",
    "section": "",
    "text": "Настройте доступ к kubectl к кластеру\nyc managed-kubernetes cluster get-credentials --id &lt;Cluster ID&gt; --external\n\nПроверьте что все работает\nkubectl config view\nили\nkubectl get nodes",
    "crumbs": [
      "Практика",
      "Настройка Yandex Kubernetes"
    ]
  },
  {
    "objectID": "1. yandex_kube.html#установка-helm",
    "href": "1. yandex_kube.html#установка-helm",
    "title": "Настройка Yandex Kubernetes",
    "section": "",
    "text": "Скачайте скрипт установки (см инструкцию helm)\ncurl -fsSL -o get_helm.sh https://raw.githubusercontent.com/helm/helm/main/scripts/get-helm-3\nИзмените права для запуска\nchmod 700 get_helm.sh\nЗапустите установку\n./get_helm.sh",
    "crumbs": [
      "Практика",
      "Настройка Yandex Kubernetes"
    ]
  },
  {
    "objectID": "1. yandex_kube.html#настройка-доступов-helm",
    "href": "1. yandex_kube.html#настройка-доступов-helm",
    "title": "Настройка Yandex Kubernetes",
    "section": "",
    "text": "Что бы подключить helm к yc выполните команду, воспользуйтесь своим OauthToken\nhelm registry login registry.yandexcloud.net -u oauth\nPassword: &lt;OAuth-токен&gt;",
    "crumbs": [
      "Практика",
      "Настройка Yandex Kubernetes"
    ]
  },
  {
    "objectID": "slides/3.clearml.html#section",
    "href": "slides/3.clearml.html#section",
    "title": "ClearML",
    "section": "",
    "text": "Для начала давайте рассмотрим, что нам предлагает clearml, как фреймворк для проведения исследований. ClearML предоставляет как унифицированную платформу с открытым исходным кодом для непрерывного использования искусственного интеллекта, так и набор модулей для совместного взаимодействия. То есть авторы инструмента имеют в виду, что можно как ограничиться использование только clearml и проводить исследования в рамках платформы, так и использовать определенные модули clearml в своих процессах проведения исследований.\nClearml действительно имеет обширные возможности:\n\nвозможности dataops (версионирование и управление данными)\nтрекинг экспериментов\nплатформа для обучение моделей\nгенерация отчетов и реестр для их хранения\nmodel store, для упрощения поставок моделей и переиспользования предыдущих наработок\nзапуск CI-CD\nmodel servering - автоматическое развертывание моделей\n\nИ все это с уже настроенной оркестрацией, планировщиками и распределенными вычислениями. Звучит очень круто, как инструмент позволяющий покрыть практически весь процесс создания и поставки моделей.",
    "crumbs": [
      "Лекции",
      "ClearML"
    ]
  },
  {
    "objectID": "slides/3.clearml.html#варианты-использования",
    "href": "slides/3.clearml.html#варианты-использования",
    "title": "ClearML",
    "section": "Варианты использования",
    "text": "Варианты использования\n\nClearML SaaS\nЧастное облако (VPC)\nЛокальная развертка\nУправляемое VPC\n\n\nClearML предлагает 4 варианта использования:\n\nУправляемый ClearML SaaS. Развертывание выделенного облачного сервера Clear ML. Все данные и вычисления остаются в контуре клиентов или VPC.\nРазвертывание виртуального частного облака. Все данные остаются в контуре клиента. Самоуправление с полной удаленной поддержкой.\nЛокально Запускайте ClearML на собственных локальных серверах и персональных устройствах клиентов. Самоуправление с полной удаленной поддержкой.\nVPC Полностью управляется ClearML в контуре.\n\nДалее мы будем рассматривать локальный запуск.",
    "crumbs": [
      "Лекции",
      "ClearML"
    ]
  },
  {
    "objectID": "slides/3.clearml.html#архитектура-clearml",
    "href": "slides/3.clearml.html#архитектура-clearml",
    "title": "ClearML",
    "section": "Архитектура ClearML",
    "text": "Архитектура ClearML\n\n\nClearML Server – решение поставляемое clearml – это внутренняя инфраструктура из набора сервисов ClearML . Существует бесплатная опенсорс-реализация этого ClearML Server. Ее можно развернуть на свои собственных мощностях и использовать внутри команды для совместной работы.\nClearML Server содержит следующие компоненты:\n\nВеб-приложение ClearML — одностраничный пользовательский интерфейс для управления экспериментами и просмотра данных.\nRESTful API для:\n\nДокументирование и регистрация информации, статистики и результатов эксперимента.\nЗапрос истории экспериментов, журналов и результатов\n\nЛокальный файловый сервер для хранения изображений и моделей, обеспечивающий легкий доступ к ним с помощью веб-приложения. При желании его можно заменить на s3-совместимое хранилище.\n\nЕго можно быстро развернуть с помощью Docker, AWS EC2 AMI или Kubernetes. Есть две конфигурации сервера с зафиксированными портами или саб-деменами. Дефолтно используются следующие порты\n\nВеб-приложение на порту 8080\nСлужба API на порту 8008\nСлужба хранения файлов на порту 8081\n\nОзнакомиться с запуском вы можете в документации, он несколько различается для разных систем. Но заключается в запуске docker-compose или kubectl. При запуске у вас будут запущены все компоненты clear ml, а также elatic, mongo db и redis для хранения информации на сервере clear ml.\nВажный нюанс, дефолтно clear ml не запускается функции аутентификации, и соответственно на селфхостед версию может зайти кто угодно. Для подключения аутентификации нужно изменить конфиг и прописать список пользователей (логин + пароль) для кого будет доступе сервис, то есть это будет дополнительная работа для админа.",
    "crumbs": [
      "Лекции",
      "ClearML"
    ]
  },
  {
    "objectID": "slides/3.clearml.html#clearml-agent",
    "href": "slides/3.clearml.html#clearml-agent",
    "title": "ClearML",
    "section": "ClearML agent",
    "text": "ClearML agent\n\n\nClearML Agent — это виртуальная среда и менеджер выполнения решений DL/ML на машинах с графическим процессором. Он интегрируется с пакетом ClearML Python и сервером ClearML, обеспечивая полноценное кластерное решение ИИ. Основное внимание уделяется:\n\nВоспроизведению экспериментов, включая их полную среду.\nМасштабированию рабочих процессов на нескольких целевых машинах.\n\nАгент ClearML выполняет эксперимент или другой рабочий процесс, воспроизводя состояние кода с исходного компьютера на удаленный компьютер. Для этого он клонирует состояние репозитория (определенный коммит) указанные в эксперименте и добавляет git diff от коммита, сохраненный в эксперименте.\nНа предыдущей диаграмме показан типичный процесс, в котором агент выполняет задачу:\n\nПоставьте задачу для выполнения в очередь.\nАгент извлекает задачу из очереди.\nАгент запускает Docker-контейнер, в котором выполняется код задачи.\nНастраивается среда выполнения задачи:\n\nВыполнить любой настроенный сценарий пользовательской установки.\nУстановить все необходимые системные пакеты.\nКлонируется код из репозитория git.\nПрименяются все записанные незафиксированные изменения.\nНастраивает среду Python и необходимые пакеты.\n\nСценарий/код задачи выполняется.\n\n\nАгент ClearML использует версию Python, доступную в среде или докере, в котором он выполняет код. Он не устанавливает Python, поэтому обязательно используйте докер или среду той версии, которая вам нужна.\n\n\nАгент ClearML может работать на Google Colab. Это помогает пользователям использовать вычислительные ресурсы, предоставляемые Google Colab, и отправлять на них эксперименты для выполнения.",
    "crumbs": [
      "Лекции",
      "ClearML"
    ]
  },
  {
    "objectID": "slides/3.clearml.html#clearml-serving",
    "href": "slides/3.clearml.html#clearml-serving",
    "title": "ClearML",
    "section": "ClearML serving",
    "text": "ClearML serving\n\n\nClearML serving – это сервис для развертывания и оркестровки моделей. Он позволяет развертывать модели, включая обслуживание и предварительную обработку кода в кластере Kubernetes или пользовательском решении на основе контейнера.\nВажные качества такого подхода:\n\nПростота развертывания и настройки\n\nПоддержка моделей машинного обучения (Scikit Learn, XGBoost, LightGBM)\nПоддержка моделей глубокого обучения (TensorFlow, PyTorch, ONNX)\nНастраиваемый RestAPI для обслуживания (т.е. позволяет выполнять предварительную и последующую обработку для каждой модели для легкой интеграции)\n\nГибкость\n\nРазвертывание модели в режиме онлайн\nРазвертывание модели/версии конечной точки в режиме онлайн (т.е. нет необходимости останавливать работу сервиса)\nОтдельная предварительная и постобработка кода Python для каждой модели\n\nМасштабируемость\n\nНесколько моделей на контейнер\nНесколько моделей на одну услугу обслуживания\nПоддержка нескольких служб (полностью разделенные многофункциональные службы, работающие независимо)\nПоддержка нескольких кластеров\nАвтоматическое масштабирование узлов «из коробки» на основе нагрузки/использования\n\nЭффективность\n\nИспользование ресурсов нескольких контейнеров\nПоддержка узлов CPU и GPU\nАвтоматическое пакетирование для моделей DL\nАвтоматическое развертывание\nАвтоматические обновления моделей с поддержкой Canary\nПрограммируемый API для развертывания модели\nРазвертывание Canary A/B — онлайн-обновления Canary\n\nМониторинг\n\nОтчетность по показателям использования\nМетрическая панель инструментов\nМетрика производительности модели\nПанель управления производительностью модели",
    "crumbs": [
      "Лекции",
      "ClearML"
    ]
  },
  {
    "objectID": "slides/3.clearml.html#подключение-к-clearml-серверу",
    "href": "slides/3.clearml.html#подключение-к-clearml-серверу",
    "title": "ClearML",
    "section": "Подключение к ClearML серверу",
    "text": "Подключение к ClearML серверу\n~/clearml.conf\napi {\n    web_server: \"http://localhost:8008\"\n    api_server: \"http://localhost:8080\"\n    files_server: \"http://localhost:8081\"\n}\n\nПредварительно установите clearml в ваш проект с помощью pip/poetry/pdm и тд.\nДля подключения к серверу есть два варианта:\n\nЗапустить команду clearml-init для интерактивной настройки\nРучками прописать в файле ~/clearml.conf адреса основных компонент clear ml.\n\nПосле настройки вы легко сможете подключать clearm ml к серверу, загружать или выгружать данные, модели, результаты экспериментов. буквально парой строк кода.\nЕсть важное примечание, если вы используете саб-доменную конфигурацию, то нужно указывать протокол http/https, а так же порты если они отличаются от 80 и 443",
    "crumbs": [
      "Лекции",
      "ClearML"
    ]
  },
  {
    "objectID": "slides/3.clearml.html#трекинг-экспериментов",
    "href": "slides/3.clearml.html#трекинг-экспериментов",
    "title": "ClearML",
    "section": "Трекинг экспериментов",
    "text": "Трекинг экспериментов\n\n\nfrom clearml import Task\n\n\ndef main():\n    ...\n    task = Task.init(project_name='great project', task_name='best experiment')\n    ...\n    task.set_progress(0)\n    ...\n    task.set_progress(50)\n    print(task.get_progress())\n    ...\n    task.set_progress(100)\n\n\n\n\nВ ClearML эксперименты организованы в виде задач. ClearML автоматически регистрирует ваш эксперимент и код, включая выходные данные и параметры из популярных платформ машинного обучения, как только вы интегрируете ClearML со своим кодом.\nДля этого импортируете класс Task в код, инициализируйте Task, указав проект и имя эксперимента. Если проект еще не существует, новый создается автоматически. Действительно этих двух строк хватит что бы логировать практически любые эксперименты",
    "crumbs": [
      "Лекции",
      "ClearML"
    ]
  },
  {
    "objectID": "slides/3.clearml.html#что-логирует-clear-ml",
    "href": "slides/3.clearml.html#что-логирует-clear-ml",
    "title": "ClearML",
    "section": "Что логирует clear ml",
    "text": "Что логирует clear ml\n\n\n\nHyperparameters\n\nCommand Line Parsing\n\nclick\nargparse\nPython Fire\nLightningCLI\n\nTensorFlow Definitions (absl-py)\nHydra\n\nMetrics, scalars, plots\n\nMatplotlib\nTensorboard\nTensorboardX\n\nExecution details including\n\nGit information\nUncommitted code modifications\nPython environment\nExecution configuration\n\n\n\n\nModels\n\nTensorFlow\nKeras\nPyTorch\nAutoKeras\nCatBoost\nFast.ai\nLightGBM\nMegEngine\nMONAI\nscikit-learn (only using joblib)\nXGBoost (only using joblib)\nYOLOv8\nYOLOv5",
    "crumbs": [
      "Лекции",
      "ClearML"
    ]
  },
  {
    "objectID": "slides/3.clearml.html#clearml-task",
    "href": "slides/3.clearml.html#clearml-task",
    "title": "ClearML",
    "section": "ClearML Task",
    "text": "ClearML Task\n\n\nПолучение эксперимента по ID\nprev_task = Task.get_task(task_id='123456deadbeef')\nПолучение эксперимента по имени\nprev_task = Task.get_task(\n    project_name='great project',\n    task_name='best experiment',\n)\n\nФильтрация экспериментов по разным параметрам\ntask_list = Task.get_tasks(\n    task_ids=None,  # type Optional[Sequence[str]]\n    project_name=None,  # Optional[str]\n    task_name=None,  # Optional[str]\n    allow_archived=True, # [bool]\n    task_filter=None,  # Optional[Dict]#\n    # tasks with tag `included_tag` or without tag `excluded_tag`\n    tags=['included_tag', '-excluded_tag']\n)\n\n\nКаждый ранее выполненный эксперимент сохраняется как Задача. То есть атомарной единицей исследования в clearml является разовый запуск какого-то эксперимента. Эксперименту-задаче автоматически присваивается автоматически сгенерированный уникальный идентификатор (строка UUID), который нельзя изменить и который всегда определяет одну и ту же задачу в системе.\nМожно получить объект Task программным путем, запросив систему на основе идентификатора задачи или комбинации проекта и имени. Вы также можете запрашивать задачи на основе их свойств, например теговб имени проекта или задачи и тд.\nКогда вы получили объект Task, то можете получить его состояние: модель, датасет, метрики, параметры и тд.",
    "crumbs": [
      "Лекции",
      "ClearML"
    ]
  },
  {
    "objectID": "slides/3.clearml.html#clearml-artifacts",
    "href": "slides/3.clearml.html#clearml-artifacts",
    "title": "ClearML",
    "section": "ClearML artifacts",
    "text": "ClearML artifacts\n\n\nДобавление артефактов\n# конкретный файл\ntask.upload_artifact(\n    name='data',\n    artifact_object='/path/to/preprocess_data.csv',\n)\n# дирректория и все файлы внутри нее\ntask.upload_artifact(name='folder', artifact_object='/path/to/folder/')\n# объект python\nnumpy_object = np.eye(100, 100)\ntask.upload_artifact(name='features', artifact_object=numpy_object)\n\nИспользование артефактов\npreprocess_task = Task.get_task(task_id='preprocessing_task_id')\nlocal_csv = preprocess_task.artifacts['data'].get_local_copy()\n\n\nprev_task = Task.get_task(task_id='the_training_task')\nlast_snapshot = prev_task.models['output'][-1]\nlocal_weights_path = last_snapshot.get_local_copy()\n\n\nClearML позволяет легко хранить выходные продукты эксперимента — снимок модели/файл весов, предварительную обработку данных, функциональное представление данных и многое другое!\nПо сути, артефакты — это файлы (или объекты Python), загруженные из сценария и хранящиеся вместе с задачей. К этим артефактам можно легко получить доступ через веб-интерфейс или программно.\nАртефакты можно хранить где угодно: на сервере ClearML, в любом решении для хранения объектов или в общей папке.\nЗарегистрированные артефакты могут использоваться другими задачами, будь то предварительно обученная модель или обработанные данные. Чтобы использовать артефакт, сначала вам необходимо получить экземпляр задачи, которая его изначально создала, затем вы либо загружаете его и получаете путь к нему, либо получаете объект артефакта напрямую.\ntask.artifacts— это словарь, ключами которого являются имена артефактов, а возвращаемый объект — это объект артефакта.\n\nВызов get_local_copy() создает локально копию артефакта и возвращает путь до объекта. Таким образом, при следующем выполнении кода вам не потребуется повторно загружать артефакт.\nВызов get() возвращает десериализованный python объект, не сохраняя его в локальный кеш.\n\nЕще хотелось бы уделить внимание моделям. Модели — это особый вид артефакта. Модели, созданные с помощью популярных платформ (таких как PyTorch, TensorFlow, Scikit-learn), автоматически регистрируются ClearML. Все снимки автоматически записываются. Чтобы убедиться, что вы также автоматически загружаете снимок модели (вместо сохранения ее локального пути), укажите место хранения файлов модели, в которые будут загружены. для этого надо добавить аргумент output_uri в инициализацию Task.\n\nОбщая папка:/mnt/share/folder\nS3:s3://bucket/folder\nСервисы, отличные от AWS S3 (например, MinIO):s3://host_addr:port/bucket\nОблачное хранилище Google:gs://bucket-name/folder\nХранилище Azure:azure://.blob.core.windows.net/path/to/file\n\nЧто бы получить модель, нужно получить экземпляр задачи, обучающей исходные файлы весов, затем вы можете запросить у задачи ее выходные модели (список снимков) и получить последний снимок.",
    "crumbs": [
      "Лекции",
      "ClearML"
    ]
  },
  {
    "objectID": "slides/3.clearml.html#clearml-metrics",
    "href": "slides/3.clearml.html#clearml-metrics",
    "title": "ClearML",
    "section": "ClearML metrics",
    "text": "ClearML metrics\n\n\nАвтоматическое логирование\n\nTensorBoard\nTensorBoardX\nMatplotlib\n\n\n\n\n\n\n\nРучное логирование метрик\nlogger = task.get_logger()\n\nfor i in range(100):\n    logger.report_scalar(\n        \"unified graph\", \"series A\", iteration=i, value=1./(i+1)\n    )\n    logger.report_scalar(\n        \"unified graph\", \"series B\", iteration=i, value=10./(i+1)\n    )\n\n\n\n\n\n\n\nClearML автоматически фиксирует показатели, передаваемые в ведущие библиотеки визуализации, такие как TensorBoard и Matplotlib, без необходимости использования дополнительного кода.\nКроме того, ClearML фиксирует и регистрирует все, что выводится на стандартный вывод, — от сообщений отладки до ошибок и предупреждающих сообщений библиотеки.\nИнформация о графическом процессоре, процессоре, памяти и сети также фиксируется автоматически.\nClearML также поддерживает составление вручную отчетов по нескольким типам показателей и графиков, таких как линейные графики, гистограммы и даже графические диаграммы.\nОбъект, используемый для ручного логирования метрик, называется logger и получается путем вызова Task.get_logger(). Например в него можно залогировать набор значений и в дальнейшем clearml построит график по тим значениям.",
    "crumbs": [
      "Лекции",
      "ClearML"
    ]
  },
  {
    "objectID": "slides/3.clearml.html#clearml-logging",
    "href": "slides/3.clearml.html#clearml-logging",
    "title": "ClearML",
    "section": "ClearML logging",
    "text": "ClearML logging\n\n\n\nТекст report_text\nСкаляры report_scalar\nОдинарное значение метрики report_single_value\nОтладочные примеры\n\nИзображений report_image\nHTML и Медиа (аудио, видео) report_media\n\nJupyter Notebook как отчет по эксперименту jupiter logging\n\n\n\nГрафики\n\n2D графики report_scatter2d\n\nГистограммы\nМатрицы ошибок\nДиаграммы рассеяния\n\n3D графики report_scatter3d\n\nГрафики поверхностей(surface)\nДиаграммы рассеяния\n\nТаблицы report_table\n\nPandas DataFrame\nCSV-файл\n\nMatplotlib figures report_matplotlib_figure\nPlotly figures report_plotly\n\n\n\n\nЭто весь список того что можно передать в logger, то есть можно сохранить текст, метрики, динамику метрик, какие-то графики из сырых данных, matplolib или plotly figures, различные таблицы данных и все это потом будет доступно в clearml при просмотре эксперимента.",
    "crumbs": [
      "Лекции",
      "ClearML"
    ]
  },
  {
    "objectID": "slides/3.clearml.html#clearml-data",
    "href": "slides/3.clearml.html#clearml-data",
    "title": "ClearML",
    "section": "ClearML data",
    "text": "ClearML data\n\n\nclearml-data — Утилита CLI для управления датасетами.\nclearml-data create [-h] [--parents [PARENTS [PARENTS ...]]] [--project PROJECT]\n                    --name NAME [--version VERSION] [--output-uri OUTPUT_URI]\n                    [--tags [TAGS [TAGS ...]]\n\nclearml.Dataset — Интерфейс Python для управления данными.\nfrom clearml import Dataset\n\ndataset = Dataset.create(\n  dataset_name='dataset name',\n  dataset_project='dataset project',\n  dataset_version=\"1.0\",\n)\n\n\n\nClearML Data Management решает две важные задачи:\n\nДоступность. Обеспечение легкого доступа к данным с любого компьютера.\nУправление версиями — связывание данных и экспериментов для лучшей прослеживаемости.\n\nНаборы clearml dataset можно настроить для наследования от других наборов данных, что позволяет создавать линии передачи данных, а пользователи могут отслеживать, когда и как изменяются их данные. Изменения набора данных сохраняются с использованием дифференцируемого хранилища, то есть версия будет хранить набор изменений из предыдущего родительского набора данных.\nУправлять можно из CLI и из питона, используя соответствующие инструменты clearml-data и clearml.Dataset.\nК хорошим практикам управления данными относятся:\n\nверсионирование данных (если нужно как-то изменить набор данных, то создайте новую версию набора данных, а не новый датасет, так будет проще отслеживать изменения)\nдокументирование данных (Dataset.get_logger() и вы получаете те же возможности, что и в эксперименте)\nструктура данных, наборы данных можно организовывать в проекты (и подпроекты) . Кроме того, при создании набора данных к набору данных можно применять теги, что упростит поиск набора данных.",
    "crumbs": [
      "Лекции",
      "ClearML"
    ]
  },
  {
    "objectID": "slides/3.clearml.html#clear-ml-pipelines",
    "href": "slides/3.clearml.html#clear-ml-pipelines",
    "title": "ClearML",
    "section": "Clear ML pipelines",
    "text": "Clear ML pipelines\n\n\nПайплайны — это способ оптимизировать и соединить несколько процессов, используя выходные данные одного шага как входные данные другого.\nПайплайны ClearML реализуются с помощью задачи контроллера, которая содержит логику взаимодействия шагов пайплайна. В зависимости от спецификаций, изложенных в задаче контроллера, параметры шага могут быть переопределены, что позволяет использовать продукты выполнения других шагов, такие как артефакты и параметры.\nПри запуске контроллер последовательно запускает этапы пайплайна. Логика и шаги пайплайна могут выполняться локально или на любом компьютере с помощью Clearml-агента.\nClearML поддерживает несколько режимов выполнения пайлайна:\n\nУдаленный режим (по умолчанию). В этом режиме логика pipeline controller выполняется через назначенную очередь, и все шаги пайплайна запускаются удаленно через соответствующие очереди. Поскольку каждая задача выполняется независимо, она может контролировать свой репозиторий git (при необходимости), необходимые пакеты Python и конкретный контейнер, который будет использоваться.\nЛокальный режим. В этом режиме Пайплайн выполняется локально, а шаги выполняются как подпроцессы. Каждый подпроцесс использует ту же среду Python, что и логика основного пайплайна.\nРежим отладки (для PipelineDecorator). В этом режиме весь пайплайн выполняется локально, при этом контроллер пайплайна и шаги вызываются синхронно, как обычные функции Python, обеспечивая полную возможность отладки каждого вызова функции.\n\nПайплайны ClearML создаются из кода с использованием одного из следующих способов:\n\nКласс PipelineController — Pythonic интерфейс для определения и настройки контроллера пайплайна и его шагов. Контроллер и шаги могут быть функциями в вашем коде Python или существующими задачами ClearML .\nКласс PipelineDecorator — набор декораторов Python, которые преобразуют ваши функции в контроллер пайплайна и шаги.\n\n\nПоскольку контроллер пайплайна сам по себе является задачей-экспериментом ClearML , его можно использовать в качестве шага пайплайна. Это позволяет создавать более сложные рабочие процессы, например пайплайны, выполняющие другие пайплайны, или пайплайны, выполняющие несколько задач одновременно.",
    "crumbs": [
      "Лекции",
      "ClearML"
    ]
  },
  {
    "objectID": "slides/1.intro.html#чуть-чуть-интерактива",
    "href": "slides/1.intro.html#чуть-чуть-интерактива",
    "title": "Intro",
    "section": "Чуть-чуть интерактива",
    "text": "Чуть-чуть интерактива\nvk.cc/cNpPry",
    "crumbs": [
      "Лекции",
      "Intro"
    ]
  },
  {
    "objectID": "slides/1.intro.html#план-занятий",
    "href": "slides/1.intro.html#план-занятий",
    "title": "Intro",
    "section": "План занятий",
    "text": "План занятий\n\nОпределимся: Что такое MLOps?\nПоговорим о проблемах ML\nПосмотрим подходы к их решению\nПосвятим много времени ClearML",
    "crumbs": [
      "Лекции",
      "Intro"
    ]
  },
  {
    "objectID": "slides/1.intro.html#что-такое-mlops",
    "href": "slides/1.intro.html#что-такое-mlops",
    "title": "Intro",
    "section": "Что такое MLOps?",
    "text": "Что такое MLOps?",
    "crumbs": [
      "Лекции",
      "Intro"
    ]
  },
  {
    "objectID": "slides/1.intro.html#данные",
    "href": "slides/1.intro.html#данные",
    "title": "Intro",
    "section": "Данные",
    "text": "Данные\n\n\n\nЛежат локально\nМеняются произвольно\nНет настроенных потоков данных\nНет версий датасетов",
    "crumbs": [
      "Лекции",
      "Intro"
    ]
  },
  {
    "objectID": "slides/1.intro.html#исследования",
    "href": "slides/1.intro.html#исследования",
    "title": "Intro",
    "section": "Исследования",
    "text": "Исследования\n\n\n\nНет культуры исследований\nРезультаты теряются\nЧасто не воспроизводимы\nСложно разобраться “а что сделано-то?”",
    "crumbs": [
      "Лекции",
      "Intro"
    ]
  },
  {
    "objectID": "slides/1.intro.html#модели",
    "href": "slides/1.intro.html#модели",
    "title": "Intro",
    "section": "Модели",
    "text": "Модели\n\n\n\n“А где модель то?”\n“Как ее запустить?”\n“А она еще работает?”\n“Что-то не так, дай новую модельку”",
    "crumbs": [
      "Лекции",
      "Intro"
    ]
  },
  {
    "objectID": "slides/1.intro.html#командное-взаимодействие",
    "href": "slides/1.intro.html#командное-взаимодействие",
    "title": "Intro",
    "section": "Командное взаимодействие",
    "text": "Командное взаимодействие\n\n\n\nКаждый кодит как он хочет\nИсследования независимы\nНет обмена знаниями\n“А что мы вообще делаем?”",
    "crumbs": [
      "Лекции",
      "Intro"
    ]
  },
  {
    "objectID": "slides/1.intro.html#как-же-все-это-решать",
    "href": "slides/1.intro.html#как-же-все-это-решать",
    "title": "Intro",
    "section": "Как же все это решать?",
    "text": "Как же все это решать?\nматрица зрелости инженерных практик\n\nПостепенно менять процессы работы\nВнедрять инструменты автоматизации\nПовышать культуру и компетенции команды\nДелать сразу как надо",
    "crumbs": [
      "Лекции",
      "Intro"
    ]
  },
  {
    "objectID": "README.html",
    "href": "README.html",
    "title": "MLOps/DataOps YA.CAMP 2025",
    "section": "",
    "text": "В репозитории представлены материалы для занятий MLOps/DataOps YA.CAMP 2025.\n\n\nИсточники для подготовленных материалов:\n\nДокументация ClearML\nКурс MLOps и production в DS исследованиях 3.0\nКурс Инженерные практики в ML\n\n\n\n\n\nВведение в MLOps, что это и зачем нужно?\nИнструменты MLOps (краткий перечень)\nClearML как единая платформа для ML исследований\nНебольшая справка по Kubernetes\n\n\n\n\n\nclearml-helm-charts – подготовленные helm charts для запуска на YC clearml и выполнения примера. В них заранее заменены образы которые попали под блокировку, поэтому развертка должна пройти без проблем.\nmlops-example – подготовленный демо пример того, как и что можно делать c clearml, показаны основные возможности и способы работы.\nИнстуркции к работе с примером также приложены в репозиторий, надеюсь они помогут разобраться с ним:\n\n1. yandex_kube.md – настрйока kuber в yc, куда нужно посмотреть и как настроить локальные инструменты.\n2.1 clearml_yandex_kube.md – как развернуть на yc kuber нужные для практики сервисы clearml.\n2.2 clearml docker.md – как развернуть clearml через docker compose\n3. clearml_work.md – как настроить окружение демо примера у себя и настроить работу с clearml\n4. clearml_data.md – информация по работе с clearml data, как с ней взаимодействовать и как подготовить данные для демо примера и загрузить в clearml.\n5. clearml_pipeline.md – базовое создание пайплайнов и способы их запуска: локально и удаленно, пример пайплайна по подготовке данных\n6. clearml_research.md – как проводить исследваония в clearml, что для этого нужно, как логировать метрики, артефакты и модели, а так же сравнвивать экперименты между собой.\n7. clearml_reports.md – Немного про отчеты, как их легко делать и хранить в clearml\n8. clearml_serving.md – как развернуть модели с помощью clearml, описание демо примера.\n9. clearml_extend_pipes.md – чуть больше возможностей пайплайнов, как составить пайплайн из готовых задач.\n\n\n\nСначала ознакомьтесь со всеми материалами, а уже потом пробуйте запустить\n\n\n\n\nНа практике необходимо выполнить задание, его подробности вам опишет практик, но основная часть такая:\nПервая практика\n\nРазвернуть инфру на YC1\nЗагрузить несколько версий датасета в clearml\nРеализовать пайплайн обработки версий датасета для подготовки данных для обучения моделей.\n\nВторая практика\n\nРеализовать обучение модели на подготовленном датасет\nНастроить логирования метрик, семплов и моделей в clearml\nЗапустить удаленные эксперименты на агенте clearml\nСформировать отчёт с сравнением моделей в clearml reports\n\nТретья практика\n\nНастроить model servering в YC 2\nЗадеплоить туда одну из моделей\nРеализовать простой интерфейс для взаимодействия с API модели на streamlit/dash"
  },
  {
    "objectID": "README.html#источники",
    "href": "README.html#источники",
    "title": "MLOps/DataOps YA.CAMP 2025",
    "section": "",
    "text": "Источники для подготовленных материалов:\n\nДокументация ClearML\nКурс MLOps и production в DS исследованиях 3.0\nКурс Инженерные практики в ML"
  },
  {
    "objectID": "README.html#теория",
    "href": "README.html#теория",
    "title": "MLOps/DataOps YA.CAMP 2025",
    "section": "",
    "text": "Введение в MLOps, что это и зачем нужно?\nИнструменты MLOps (краткий перечень)\nClearML как единая платформа для ML исследований\nНебольшая справка по Kubernetes"
  },
  {
    "objectID": "README.html#практика",
    "href": "README.html#практика",
    "title": "MLOps/DataOps YA.CAMP 2025",
    "section": "",
    "text": "clearml-helm-charts – подготовленные helm charts для запуска на YC clearml и выполнения примера. В них заранее заменены образы которые попали под блокировку, поэтому развертка должна пройти без проблем.\nmlops-example – подготовленный демо пример того, как и что можно делать c clearml, показаны основные возможности и способы работы.\nИнстуркции к работе с примером также приложены в репозиторий, надеюсь они помогут разобраться с ним:\n\n1. yandex_kube.md – настрйока kuber в yc, куда нужно посмотреть и как настроить локальные инструменты.\n2.1 clearml_yandex_kube.md – как развернуть на yc kuber нужные для практики сервисы clearml.\n2.2 clearml docker.md – как развернуть clearml через docker compose\n3. clearml_work.md – как настроить окружение демо примера у себя и настроить работу с clearml\n4. clearml_data.md – информация по работе с clearml data, как с ней взаимодействовать и как подготовить данные для демо примера и загрузить в clearml.\n5. clearml_pipeline.md – базовое создание пайплайнов и способы их запуска: локально и удаленно, пример пайплайна по подготовке данных\n6. clearml_research.md – как проводить исследваония в clearml, что для этого нужно, как логировать метрики, артефакты и модели, а так же сравнвивать экперименты между собой.\n7. clearml_reports.md – Немного про отчеты, как их легко делать и хранить в clearml\n8. clearml_serving.md – как развернуть модели с помощью clearml, описание демо примера.\n9. clearml_extend_pipes.md – чуть больше возможностей пайплайнов, как составить пайплайн из готовых задач.\n\n\n\nСначала ознакомьтесь со всеми материалами, а уже потом пробуйте запустить"
  },
  {
    "objectID": "README.html#задание",
    "href": "README.html#задание",
    "title": "MLOps/DataOps YA.CAMP 2025",
    "section": "",
    "text": "На практике необходимо выполнить задание, его подробности вам опишет практик, но основная часть такая:\nПервая практика\n\nРазвернуть инфру на YC1\nЗагрузить несколько версий датасета в clearml\nРеализовать пайплайн обработки версий датасета для подготовки данных для обучения моделей.\n\nВторая практика\n\nРеализовать обучение модели на подготовленном датасет\nНастроить логирования метрик, семплов и моделей в clearml\nЗапустить удаленные эксперименты на агенте clearml\nСформировать отчёт с сравнением моделей в clearml reports\n\nТретья практика\n\nНастроить model servering в YC 2\nЗадеплоить туда одну из моделей\nРеализовать простой интерфейс для взаимодействия с API модели на streamlit/dash"
  },
  {
    "objectID": "README.html#footnotes",
    "href": "README.html#footnotes",
    "title": "MLOps/DataOps YA.CAMP 2025",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nЕсли не получается то локлаьно через docker-compose↩︎\nЕсли неполчается, то реализовать приложение fastpai, которое при запуске забирает определенную версию модели из clearml↩︎"
  },
  {
    "objectID": "slides/2.tools.html#tools-types",
    "href": "slides/2.tools.html#tools-types",
    "title": "MLOps Tools",
    "section": "Tools types",
    "text": "Tools types\n\n\n\nData Management\nData Validation\nWorkflow Managment\nModel Lifecycle\n\n\n\nKnowledge Sharing\nModel Serving\nMonitoring & Dashboards\nMLOps Platforms\n\n\nИ это еще не всё…1\nСмотрите в awesome-mlops и mlops-references",
    "crumbs": [
      "Лекции",
      "MLOps Tools"
    ]
  },
  {
    "objectID": "slides/2.tools.html#data-management",
    "href": "slides/2.tools.html#data-management",
    "title": "MLOps Tools",
    "section": "Data Management",
    "text": "Data Management\n\nGit LFS – расширение git для больших файлов\nDVC – система версионирования данных и моделей в ml проектах\nHugging Face – платформа для публикации открытых моделей и датасетов\nLakeFS – git like система версионирования данных в объектных хранилищах",
    "crumbs": [
      "Лекции",
      "MLOps Tools"
    ]
  },
  {
    "objectID": "slides/2.tools.html#data-validation",
    "href": "slides/2.tools.html#data-validation",
    "title": "MLOps Tools",
    "section": "Data Validation",
    "text": "Data Validation\n\nGreat Expectations – фреймворк для валидации данных\nPandera – задание модели данных pandas и polars\nData contract – валидация как хранилищ данных, так и отдельных файлов",
    "crumbs": [
      "Лекции",
      "MLOps Tools"
    ]
  },
  {
    "objectID": "slides/2.tools.html#workflow-managment",
    "href": "slides/2.tools.html#workflow-managment",
    "title": "MLOps Tools",
    "section": "Workflow Managment",
    "text": "Workflow Managment\n\nGNU Make – олдовый workflow manager на основе файлов\nSnakeMake – аналог для управления workflow в DS проектах\nLuigi – python оркестратор workflow\nMetaflow – оркестратор для ML workflow\nMage AI – фреймворк для управления ml workflow\nAirFlow –мощный и популярный оркестратор workflow",
    "crumbs": [
      "Лекции",
      "MLOps Tools"
    ]
  },
  {
    "objectID": "slides/2.tools.html#model-lifecycle",
    "href": "slides/2.tools.html#model-lifecycle",
    "title": "MLOps Tools",
    "section": "Model Lifecycle",
    "text": "Model Lifecycle\n\nMLflow – платформа для трекинга артефактов экспериментов\nNeptune AI – колобаративный инструмент трекинга артефактов и датасетов\nWeights and Biases – инструмент визуализации и отслеживания обучения ваших моделей\nTensorBoard – инструмент визуализации обучения ваших нейронных сетей",
    "crumbs": [
      "Лекции",
      "MLOps Tools"
    ]
  },
  {
    "objectID": "slides/2.tools.html#knowledge-sharing",
    "href": "slides/2.tools.html#knowledge-sharing",
    "title": "MLOps Tools",
    "section": "Knowledge Sharing",
    "text": "Knowledge Sharing\n\nKnowledge Repo – платформа обмена знаниями для исследователей\nKyso – инструмент публикации и ревью отчетов",
    "crumbs": [
      "Лекции",
      "MLOps Tools"
    ]
  },
  {
    "objectID": "slides/2.tools.html#model-serving",
    "href": "slides/2.tools.html#model-serving",
    "title": "MLOps Tools",
    "section": "Model Serving",
    "text": "Model Serving\n\nTriton Inference Server – python сервис для деплоя различных моделей и оптимизацией их исполнения\nTensorFlow Serving – гибкий, мощный инструмент деплоя tensorflow в продакшен\nTorchServe – аналог для моделей pytorch\nOpyrator – простой способ получить API/интерфейс модели\nGradio – инструмент построения простых ML web-приложений",
    "crumbs": [
      "Лекции",
      "MLOps Tools"
    ]
  },
  {
    "objectID": "slides/2.tools.html#monitoring-dashboards",
    "href": "slides/2.tools.html#monitoring-dashboards",
    "title": "MLOps Tools",
    "section": "Monitoring & Dashboards",
    "text": "Monitoring & Dashboards\n\nStreamlit – простой инструмент построения dashboards чего либо на питоне\nDash – аналог от команды plotly\nGrafana – простой сервис для построения dashboards\nPrometheus – инструмент сбора метрик и ошибок\nGrayLog – сборщик и анализатор логов",
    "crumbs": [
      "Лекции",
      "MLOps Tools"
    ]
  },
  {
    "objectID": "slides/2.tools.html#mlops-platforms",
    "href": "slides/2.tools.html#mlops-platforms",
    "title": "MLOps Tools",
    "section": "MLOps Platforms",
    "text": "MLOps Platforms\n\nClearML – платформа все в одном\nKubeflow – платформа для ML на основе kubernetes\nИ много много других",
    "crumbs": [
      "Лекции",
      "MLOps Tools"
    ]
  },
  {
    "objectID": "slides/4.k8s.html#предыстория",
    "href": "slides/4.k8s.html#предыстория",
    "title": "Kubernetes",
    "section": "Предыстория",
    "text": "Предыстория\n\nVM, кластера виртуальных машин\nИзоляция приложений в различные виртуальных машины\nnamespaces, cgroups\nМеханизмы изоляции процессов ядра Linux\nLXC, Docker\nСредства контейнеризации на основе Linux\nKubernetes\nКластерное решение по управлению контейнерами\n\n\n\nVM, кластера виртуальных машин\nИзначально для решения предыдущих проблем популярность набрали различные решения для виртуализации. И, действительно, VM отлично изолированы друг от друга, образа VM можно относительно легко копировать и переносить, а появление решений для облачных вычислений, таких как VMware vSphere или OpenNebula, позволяло достаточно легко управлять целыми кластерами серверов и распределять нагрузки между ними. Но, увы, виртуализация привносит огромные накладные расходы, а высокая степень изоляции нередко избыточна.\nnamespaces, cgroups\nПараллельно с этим в ядре Linux появлялись и совершенствовались механизмы изоляции процессов друг от друга. Основных средств изоляции процессов два: namespaces, который позволяет скрывать от процессов ненужные им сетевые и дисковые ресурсы, а также другие процессы; и cgroups, который позволяет разграничивать вычислительные ресурсы между процессами.\nLXC, Docker\nРазвитие механизмов изоляции породило идею, что, возможно, для решения проблем изоляции и переносимости приложений можно использовать не дорогие VM, а средства ядра Linux. Так появились инструменты контейнеризации: первым стал LXC, который доказал что приложения можно упаковать в изолированные, переносимые и при этом легковесные контейнера, а затем уже знакомый вам Docker, который из простой надстройки для LXC развился в самостоятельный стандарт индустрии.\nKubernetes\nНо этого было мало: нужно было решение, которое не просто позволит легко поднять приложение, но которое бы позволило управлять множеством серверов, распределять нагрузку между ними и легко дублировать и делать параллельным выполнение приложений на множестве машин одновременно. Появился целый ряд решений позволяющих именно это, таких как Google Borg и Apache Mesos, но наиболее распространённым из всех стал Kubernetes.",
    "crumbs": [
      "Лекции",
      "Kubernetes"
    ]
  },
  {
    "objectID": "slides/4.k8s.html#основные-спецификации",
    "href": "slides/4.k8s.html#основные-спецификации",
    "title": "Kubernetes",
    "section": "Основные спецификации",
    "text": "Основные спецификации\n\nOCI — Open Container Initiative\n\nruntime-spec: стандарт конфигурации, жизненного цикла и выполнения контейнеров\nimage-spec: стандарт образов контейнеров\ndistribution-spec: стандарт распространения образов контейнеров\n\nCRI — Container Runtime Interface: стандарт инструментария управления контейнерами\nCNI — Container Network Interface: стандарт управления сетью и обеспечения сетевой связности контейнеров\nCSI — Container Storage Interface: стандарт доступа к системам хранения данных",
    "crumbs": [
      "Лекции",
      "Kubernetes"
    ]
  },
  {
    "objectID": "slides/4.k8s.html#устройство-и-архитектура",
    "href": "slides/4.k8s.html#устройство-и-архитектура",
    "title": "Kubernetes",
    "section": "Устройство и архитектура",
    "text": "Устройство и архитектура\n\n\nКомпоненты кластера Kubernetes подразделяются на два слоя: control plane (выделен на изображении) и data plane. Слоями они именуются, так как в кластере не существует отдельных “управляющих” и “управляемых” физических или виртуальных машин — компоненты могут быть распределены по узлам произвольным образом.\nControl plane состоит из четырёх основных компонент:\n\napiserver: отвечает за API Kubernetes\nscheduler: планировщик, отслеживает созданные поды и распределяет их по узлам в зависимости от требований и доступных ресурсов\ncontroller-manager: отслеживает состояние кластера и приводит его к желаемому (объявленному в конфигурации)\netcd: хранилище данных, хранит состояние кластера\n\nТакже существует опциональный компонент cloud-controller-manager, который может использоваться в облачных окружениях для отслеживания и обновления состояния кластера через API, предоставляемый облачным провайдером.\nData plane состоит всего из двух компонент:\n\nkubelet: создаёт и отслеживает контейнера; сам функционала контейнеризации не имеет, поэтому для работы требует отдельного ПО, реализующего CRI\nproxy: отвечает за сетевую связность между подами, а также за связь подов с внешним миром",
    "crumbs": [
      "Лекции",
      "Kubernetes"
    ]
  },
  {
    "objectID": "slides/4.k8s.html#варианты-kubernetes",
    "href": "slides/4.k8s.html#варианты-kubernetes",
    "title": "Kubernetes",
    "section": "Варианты Kubernetes",
    "text": "Варианты Kubernetes\nКроме основной поставки, существует также множество различных вариаций Kubernetes:\nКоммерческие дистрибутивы:\n\nRed Hat OpenShift: дистрибутив со своей встроенной системой сборки и повышенным фокусом на безопасность\nVMWare Tanzu Kubernetes Grid: дистрибутив с интеграцией с продуктами виртуализации VMWare\nRancher: дистрибутив с фокусом на работу в гибридных облаках\nи т.д.\n\nManaged Kubernetes от облачных провайдеров:\n\nGKE (Google Cloud)\nEKS (Amazon Web Services)\nAKS (Microsoft Azure)\nи т.д., свой вариант встречается у многих крупных облачных провайдеров\n\nМинималистичные дистрибутивы:\n\nMinikube: полноценная, кроссплатформенная, простая в установке поставка от разработчиков Kubernetes, выполняется на VM\nk3s: облегчённый вариант с урезанным функционалом для IoT-устройств, выполняется на VM\nMicroK8s: облегчённая поставка для IoT-устройств, поставляется в Snap\nи т.д.",
    "crumbs": [
      "Лекции",
      "Kubernetes"
    ]
  },
  {
    "objectID": "slides/4.k8s.html#объекты-kubernetes",
    "href": "slides/4.k8s.html#объекты-kubernetes",
    "title": "Kubernetes",
    "section": "Объекты Kubernetes",
    "text": "Объекты Kubernetes\nОжидаемое состояние кластера Kubernetes полностью описано множеством объектов, существующих на нём. Абсолютно всему в кластере, будь то ваше приложение, балансировщик нагрузки, файл конфигурации или узел самого кластера, соответствует некий объект.\nЛюбой объект Kubernetes имеет описание в формате YAML. Для создания нового объекта необходимо передать кластеру его описание, и любой объект может быть запрошен у кластера — тогда вы аналогично получите его YAML-описание. Ниже приведён простейший объект типа Namespace:\napiVersion: v1\nkind: Namespace\nmetadata:\n  name: newnamespace\nspec: {}\nstatus: {}\nВ описании объекта существует четыре обязательных поля:\n\napiVersion: версия API Kubernetes, которой соответствует описание объекта.\nkind: тип объекта.\nmetadata: словарь метаинформации объекта.\nspec: словарь спецификации — ожидаемого состояния объекта.\n\nПри запросе объекта с кластера также будет добавлено пятое поле status, в котором содержится текущее состояние объекта. При создании объекта данное поле не нужно, и даже если оно присутствует, его содержимое будет просто проигнорировано.",
    "crumbs": [
      "Лекции",
      "Kubernetes"
    ]
  },
  {
    "objectID": "slides/4.k8s.html#workload",
    "href": "slides/4.k8s.html#workload",
    "title": "Kubernetes",
    "section": "Workload",
    "text": "Workload\nОбъекты рабочей нагрузки (Workload) являются наиболее полезными и часто используемыми объектами Kubernetes. Именно они используются для запуска практически любого приложения, которое вы можете захотеть запустить на вашем кластере.\nВ основе всех объектов рабочей нагрузки лежит под (Pod). Под — это некоторое множество контейнеров, управляемых Kubernetes и объединённых общей изолированной средой. Все контейнера одного пода всегда запускаются на одном узле, имеют общий жизненный цикл, используют общий сетевой интерфейс и могут использовать общие дисковые ресурсы. Любые другие объекты рабочей нагрузки создают управляемые ими поды и определяют их поведение.\nПоды, как и лёгшие в их основу Docker-контейнеры, по определению stateless. С точки зрения кластера поды сами по себе не имеют никакой ценности, и могут быть в любой момент удалены, перезапущены, перенесены на другой узел (без переноса каких-либо хранившихся внутри данных), и т.д. Поэтому никогда нельзя полагаться на хранимое в поде состояние, на любые изменения, сделанные внутри пода в процессе его работы. Для обеспечения персистентности в Kubernetes существуют отдельные специальные типы объектов.\nМинимальный под выглядит так:\napiVersion: v1\nkind: Pod\nmetadata:\n  name: nginx-pod\nspec:\n  containers:\n    - name: nginx-container\n      image: nginx",
    "crumbs": [
      "Лекции",
      "Kubernetes"
    ]
  },
  {
    "objectID": "slides/4.k8s.html#pod",
    "href": "slides/4.k8s.html#pod",
    "title": "Kubernetes",
    "section": "Pod",
    "text": "Pod\napiVersion: v1 # версия API\nkind: Pod # тип объекта\nmetadata:\n  name: nginx-pod # имя пода\n  namespace: newnamespace # пространство имён\n  labels: # метки\n    app: webserver\nspec:\n  containers: # список контейнеров\n    - name: nginx-container # имя контейнера\n      image: nginx # образ\n      imagePullPolicy: Always # когда скачивать образ\n      envFrom: # объявление переменных\n        - configMapRef:\n            name: nginx-config\n      readinessProbe: # проверка готовности пода\n        exec:\n          command:\n            - cat\n            - /data/file.txt\n      livenessProbe: # проверка работоспособности пода\n        httpGet:\n          path: /\n          port: 80\n      ports: # открытые порты\n        - containerPort: 80\n      resources: # доступные ресурсы\n        requests:\n          cpu: \"0.5\"\n          memory: \"100Mi\"\n        limits:\n          cpu: \"1\"\n          memory: \"200Mi\"\n      volumeMounts: # монтирование томов в контейнер\n        - name: data\n          mountPath: /data\n  initContainers: # список контейнеров инициализации\n    - name: init-container\n      image: busybox\n      imagePullPolicy: IfNotPresent\n      env:\n        - name: STRING\n          value: \"ready ready\"\n      command: [\"sh\", \"-c\", \"echo $(STRING) &gt; /data/file.txt\"]\n      resources: {}\n      volumeMounts:\n        - name: data\n          mountPath: /data\n  restartPolicy: Always # когда перезапускать под\n  volumes: # тома\n    - name: data\n      emptyDir: {}\n\nТак выглядит описание пода с большим количеством параметров. Здесь приведена только часть наиболее используемых параметров.\nРассмотрим присутствующие здесь параметры (в порядке, в котором они видны в файле):\n\nmetadata\n\nname: имя объекта, должно быть уникально среди всех объектов данного типа (здесь это под) в пространстве имён\nnamespace: пространство имён, кластер для удобства может быть поделён на произвольное количество пространств имён\nlabels: метки, используются для разметки и группировки объектов, многие операции могут быть применены с выбором объектов по меткам\n\nspec\n\ncontainers: массив контейнеров внутри пода. Минимальное определение контейнера состоит из его названия и образа\n\nname: имя контейнера\nimage: образ, из которого разворачивается контейнер\nimagePullPolicy: политика получения образа, может быть Always (всегда пытаться получить последнюю версию образа), IfNotPresent (не пытаться обновить образ, если уже есть на узле), Never (никогда не пытаться получить образ, запуск пода завершается ошибкой если подходящего образа нет на узле)\nenv,envFrom: объявление переменных окружения в контейнере. envFrom позволяет получить сразу все переменные в файле конфигурации\nlivenessProbe, readinessProbe: probes — механизм отслеживания состояния приложения в контейнере. Каждый probe указывает на некоторую проверку, которую необходимо периодически проводить для получения достаточной информации о состоянии. Бывает трёх типов:\n\nreadinessProbe: используется для проверки, что приложение готово принимать трафик, если не пройдено, то трафик на контейнер временно не отправляется\nlivenessProbe: используется для проверки, что приложение работает, если не пройдено, контейнер перезапускается\nstartupProbe: используется для проверки, что приложение запустилось, пока не пройдено, трафик не отправляется и другие probe не выполняются, проверяется до первой успешной проверки\n\nports: определение портов, которые слушает контейнер\nresources: ограничения вычислительных ресурсов. Бывает двух видов: requests — минимально доступные контейнеру ресурсы, которые должны быть доступны гарантированно — и limits — максимально доступные ресурсы, не может быть превышено\nvolumeMounts: тома, которые будут подключены к данному контейнеру. Сами тома определяются ниже в блоке volumes\ncommand: произвольная команда, передаваемая контейнеру на запуск вместо определённого в образе entrypoint. Представляет собой массив, аналогичный массиву ENTRYPOINT в Dockerfile\n\ninitContainers: контейнеры инициализации, запускаются для каких-либо подготовительных операций до запуска основных контейнеров. Основные контейнера не запускаются, пока выполнение всех контейнеров здесь не будет успешно выполнено. Определение контейнеров здесь совпадает с определениями в блоке containers, но не все параметры могут быть использованы\nrestartPolicy: политика перезапуска пода при завершении работы любого из контейнеров, может быть Always (под всегда будет перезапущен), OnFailure (под будет перезапущен, только если выполнение любого контейнера завершилось неудачей), Never (под никогда не будет перезапущен)\nvolumes: определение томов, которые могут быть подключены к контейнерам. Может использовать множество различных вариантов определения тома, здесь используется emptyDir, пустая временная директория, содержимое которой будет удалено при удалении самого пода",
    "crumbs": [
      "Лекции",
      "Kubernetes"
    ]
  },
  {
    "objectID": "slides/4.k8s.html#replicaset",
    "href": "slides/4.k8s.html#replicaset",
    "title": "Kubernetes",
    "section": "ReplicaSet",
    "text": "ReplicaSet\napiVersion: apps/v1\nkind: ReplicaSet\nmetadata:\n  name: nginx\n  labels:\n    app: webserver\nspec:\n  replicas: 3 # количество реплик пода\n  selector: # селектор, определяющий управляемые поды\n    matchLabels:\n      app: webserver\n  template: # шаблон пода\n    metadata:\n      labels:\n        app: webserver\n    spec:\n      containers:\n        - name: nginx\n          image: nginx\n\nReplicaSet — следующий уровень управления рабочей нагрузкой после подов. Легко можно заметить, что блок template в описании ReplicaSet очень похож на описание самого пода.\nОсновная задача ReplicaSet — автоматически создавать копии подов. ReplicaSet создаёт одинаковые поды, соответствующие описанию в блоке template, в количестве указанном в блоке replicas. Названия в метаданных для этого пода можно не указывать, так как они всегда генерируются автоматически самим ReplicaSet.\nReplicaSet рассчитан на приложения, которые должны работать постоянно. Существование ReplicaSet указывает, что всегда должен работать один или более под с вашим приложением, поэтому в случае каких-либо проблем поды будут перезапущены или пересозданы.\nВажно обратить внимание на блок selector: здесь указан селектор — объект, позволяющий Kubernetes выбирать некоторое множество подов, в данном случае по их меткам (matchLabels). Только этот селектор определяет, какие поды будут учитываться ReplicaSet. ReplicaSet, селектор которого не соответствует описанному поду в template, не является корректным. При этом поды, созданные до ReplicaSet и соответствующие селектору, попадут под управление ReplicaSet и могут быть уничтожены, даже если их описание не соответствует написанному в ReplicaSet шаблону. Поэтому с ReplicaSet нужно работать аккуратно.",
    "crumbs": [
      "Лекции",
      "Kubernetes"
    ]
  },
  {
    "objectID": "slides/4.k8s.html#deployment",
    "href": "slides/4.k8s.html#deployment",
    "title": "Kubernetes",
    "section": "Deployment",
    "text": "Deployment\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: nginx\n  labels:\n    app: webserver\nspec:\n  replicas: 3 # количество реплик\n  selector:\n    matchLabels:\n      app: webserver\n  strategy: # стратегия обновления\n    rollingUpdate:\n      maxSurge: 1\n      maxUnavailable: 1\n    type: RollingUpdate\n  template:\n    metadata:\n      labels:\n        app: webserver\n    spec:\n      containers:\n        - name: nginx\n          image: nginx\n\nХотя ничего не мешает использовать ReplicaSet напрямую, это обычно не рекомендуется. Как правило, они используются опосредованно через объекты вида Deployment.\nDeployment — объект, создающий объекты типа ReplicaSet. Как видно, определение Deployment похоже на определение ReplicaSet.\nГлавная особенность Deployment состоит в том, что он хранит историю изменений своей конфигурации. В любой момент, если что-то пойдёт не так, можно откатить Deployment на предыдущую версию. Кроме того, Deployment поддерживает разные стратегии обновления, которые настраиваются в блоке strategy. Поддерживается две стратегии обновления: Recreate указывает, что нужно просто удалить все поды предыдущей версии и создать поды новой; RollingUpdate же позволяет заменять поды по частям и направлять трафик как на старые, так и на новые поды одновременно, что позволяет поддерживать непрерывную доступность приложения во время обновления.\nВ отличие от обычного ReplicaSet, Deployment (и созданные им ReplicaSet) никогда не захватывают уже существующие поды — для всех ReplicaSet автоматически генерируется дополнительная метка — хэш конфигурации пода. Несмотря на это, селектор Deployment всё ещё должен соответствовать шаблону пода. Благодаря тому, что в качестве метки используется хэш, при изменении конфигурации Deployment не затрагивающей шаблон пода кластер может сохранить существовавшие до изменения поды и передать их под управление новой версии ReplicaSet.",
    "crumbs": [
      "Лекции",
      "Kubernetes"
    ]
  },
  {
    "objectID": "slides/4.k8s.html#statefulset",
    "href": "slides/4.k8s.html#statefulset",
    "title": "Kubernetes",
    "section": "StatefulSet",
    "text": "StatefulSet\napiVersion: apps/v1\nkind: StatefulSet\nmetadata:\n  name: nginx\n  labels:\n    app: webserver\nspec:\n  serviceName: nginx\n  replicas: 3\n  selector:\n    matchLabels:\n      app: webserver\n  template:\n    metadata:\n      labels:\n        app: webserver\n    spec:\n      containers:\n        - name: nginx\n          image: nginx\n\nStatefulSet — специальный вид рабочей нагрузки, во многом похожий на Deployment, но имеющий одну важную особенность: в отличие от любых других видов рабочей нагрузки, StatefulSet, как понятно из названия, хранит состояние для каждой реплики. Это означает, что у каждого пода, управляемого StatefulSet, есть собственный номер, который известен внутри пода и может быть использован приложением, постоянное хранилище, уникальное внутреннее доменное имя, по которому можно подключиться к поду с конкретным номером. Также у StatefulSet чётко определён порядок, в котором поды запускаются и завершают работу: по возрастанию номера при запуске и по убыванию при завершении работы.\nТакой вид рабочей нагрузки редко нужен и его использование не рекомендуется, если это явно не необходимо. Но некоторые приложения, например многие из тех, у которых взаимодействие между репликами устроено по принципу “ведущий-ведомый”, могут быть корректно запущены только с таким видом рабочей нагрузки.",
    "crumbs": [
      "Лекции",
      "Kubernetes"
    ]
  },
  {
    "objectID": "slides/4.k8s.html#job",
    "href": "slides/4.k8s.html#job",
    "title": "Kubernetes",
    "section": "Job",
    "text": "Job\napiVersion: batch/v1\nkind: Job\nmetadata:\n  name: pi\nspec:\n  template:\n    spec:\n      containers:\n        - name: pi\n          image: perl:5.34.0\n          command: [\"perl\", \"-Mbignum=bpi\", \"-wle\", \"print bpi(2000)\"]\n      restartPolicy: Never\n  completions: 5 # количество успешных выполнений\n  parallelism: 2 # количество одновременных запусков\n  backoffLimit: 6 # допустимое количество провалов\n\nJob — вид рабочей нагрузки, существующий для разовых задач. В отличие от Deployment или StatefulSet, он рассчитан на приложения, выполнение которых когда-либо должно завершиться. Job, как и другие виды рабочей нагрузки, создаёт поды, но эти поды не будут перезапущены после успешного завершения выполнения приложения.\nЗа поведение Job отвечает несколько специальных параметров:\n\ncompletions указывает на то, сколько раз задача должна быть выполнена. Поды будут создаваться, пока не достигнуто указанное здесь количество успешных запусков\nparallelism указывает на то, сколько подов могут выполнять задачу одновременно. Реальное количество созданных подов никогда не превышает количество оставшихся выполнений\nbackoffLimit указывает, после какого количества подов, выполнение которых завершилось ошибкой, выполнение задачи будет остановлено",
    "crumbs": [
      "Лекции",
      "Kubernetes"
    ]
  },
  {
    "objectID": "slides/4.k8s.html#cronjob",
    "href": "slides/4.k8s.html#cronjob",
    "title": "Kubernetes",
    "section": "CronJob",
    "text": "CronJob\napiVersion: batch/v1\nkind: CronJob\nmetadata:\n  name: date\nspec:\n  schedule: \"* * * * *\" # расписание выполнения\n  jobTemplate: # шаблон Job\n    spec:\n      template:\n        spec:\n          containers:\n            - name: date\n              image: busybox\n              command: [\"/bin/sh\", \"-c\", \"date\"]\n          restartPolicy: Never\n\nCronJob — надстройка над Job, которая позволяет запускать какие-то задачи по расписанию. В параметре jobTemplate указывается конфигурация Job, который должен создаваться с некоторой периодичностью, а в параметре schedule — расписание выполнения в формате Cron.",
    "crumbs": [
      "Лекции",
      "Kubernetes"
    ]
  },
  {
    "objectID": "slides/4.k8s.html#networking",
    "href": "slides/4.k8s.html#networking",
    "title": "Kubernetes",
    "section": "Networking",
    "text": "Networking\n\nКаждый под — отдельный виртуальный узел со своим сетевым интерфейсом.\nВнутри кластера существует единая сеть, и каждый под имеет собственный IP-адрес внутри этой сети.\n\nКаждый под внутри кластера считается отдельной и независимой единицей. Вдобавок, каждый под имеет свои требования к использованию сети. Поэтому чтобы не было конфликтов между разными подами, каждый отдельный под получает свой собственный виртуальный сетевой интерфейс, и может использовать его так, как пожелает. По сути, работу с подами внутри сети кластера можно воспринимать аналогичной работе с физическими узлами в некой реальной сети.\nВнутри кластера существует единое пространство IP-адресов, которые выдаются сетевым интерфейсам подов (Pod CIDR). У каждого узла в кластере есть своё подпространство адресов, в котором выдаются адреса подам, запущенным на данном узле, но все поды кластера всегда находятся в единой сети. Благодаря этому любой под может подключаться напрямую к любому другому поду.\nНо важно заметить, что эти IP-адреса не статичны — в любой момент под может быть пересоздан, и в этот момент он может получить новый IP-адрес. Вдобавок часто у вас в кластере поднято более одного экземпляра приложения, и вы скорее всего хотите подключаться именно к приложению где бы оно ни было доступно, вместо того чтобы привязываться к конкретному поду который может упасть или исчезнуть. Для решения этой проблемы существуют Service.",
    "crumbs": [
      "Лекции",
      "Kubernetes"
    ]
  },
  {
    "objectID": "slides/4.k8s.html#service",
    "href": "slides/4.k8s.html#service",
    "title": "Kubernetes",
    "section": "Service",
    "text": "Service\napiVersion: v1\nkind: Service\nmetadata:\n  name: nginx\nspec:\n  type: ClusterIP # тип Service\n  selector: # селектор, определяющий целевые поды для трафика\n    app: webserver\n  ports: # открытые порты\n    - name: \"http\" # название\n      protocol: TCP # протокол TCP/UDP/SCTP\n      port: 80 # открытый порт сервиса\n      targetPort: 80 # целевой порт пода\n\nService — объект Kubernetes, существующий для получения трафика и перенаправления его к подам. Каждый Service, аналогично подам, имеет свой IP-адрес. Для всех Service кластера существует пространство IP-адресов (Service CIDR), который находится в одной внутренней сети с пространством адресов подов, Благодаря чему любой под также может подключаться напрямую к любому Service и наоборот. Кроме того, каждый Service получает своё собственное постоянное внутреннее доменное имя вида [servicename].[namespacename].svc.[clusterdomain.name], которое известно всем подам кластера. Подключиться к конкретному поду за Service можно по адресу [pod-ip-address].[service-name].[namespace-name].svc.[cluster-domain.name], в случае подов управляемых StatefulSet также есть нумерованные доменные имена [statefulset-name]-[pod-index].[service-name].[namespace-name].svc.[cluster-domain.name].\nОсновная задача Service состоит в перенаправлении трафика. Весь трафик, приходящий на Service, автоматически перенаправляется на определённые конфигурацией Service поды. Выбор подов осуществляется через селектор (параметр selector), который аналогичен тем селекторам, которые можно было увидеть ранее в конфигурации ReplicaSet или Deployment. Если селектор соответствует более чем одному поду, трафик распределяется равномерно между всеми подами. Трафик направляется только на те поды, которые могут его принимать — если под по каким-то причинам не запущен, либо проверка его readinessProbe не была успешной, то трафик на этот под не направляется.\nВ блоке ports задаются порты, которые будет слушать Service. Портов может быть произвольное количество. Основные параметры:\n\nname: произвольное имя, задаётся в основном для удобства использования\nprotocol: TCP / UDP / SCTP\nport: порт, который будет слушать Service, единственный обязательный параметр\ntargetPort: порт пода, на который будет перенаправляться трафик. Если не определён, то используется тот же порт, что и в port\n\nТип Service задаётся в параметре type. Cуществуют Service четырёх типов:\n\nClusterIP: тип по умолчанию, не имеет особых свойств\nNodePort: для каждого порта сервиса также выбирается порт в каком-то диапазоне (по умолчанию 30000-32767), который открывается непосредственно на узлах кластера. Любой трафик, попадающий на этот порт любого узла кластера, попадает внутрь кластера и перенаправляется подам в соответствии с конфигурацией Service. Открытый порт выбирается случайным образом из свободных, либо может быть определён вручную через дополнительный параметр nodePort в конфигурации порта.\nLoadBalancer: надстройка над NodePort, позволяющая использовать для распределения трафика внешний управляемый балансировщик нагрузки. Для использования на кластере должна быть настроена интеграция с этим самым балансировщиком.\nExternalName: специальный вид Service, который позволяет направлять трафик не на поды, а на какие-то внешние ресурсы. Для этого типа Service селектор игнорируется, вместо этого задаётся доменное имя внешнего ресурса (IP-адреса не поддерживаются) через дополнительный параметр externalName.",
    "crumbs": [
      "Лекции",
      "Kubernetes"
    ]
  },
  {
    "objectID": "slides/4.k8s.html#ingress",
    "href": "slides/4.k8s.html#ingress",
    "title": "Kubernetes",
    "section": "Ingress",
    "text": "Ingress\napiVersion: networking.k8s.io/v1\nkind: Ingress\nmetadata:\n  name: nginx\n  labels:\n    name: webserver\nspec:\n  rules:\n    - host: webserver.lan\n      http:\n        paths:\n          - pathType: Prefix\n            path: \"/\"\n            backend:\n              service:\n                name: nginx\n                port:\n                  number: 80\n\nОбъекты Service используются для настройки трафика внутри кластера. Хотя получить трафик снаружи кластера можно при помощи NodePort, это обычно не применимо для продуктивного использования, и NodePort используются чаще всего только для задач отладки и тестирования. Исторически существовало множество (часть из них всё ещё развиваются и используются) различных надстроек над Kubernetes, позволявших настраивать получение трафика кластером, требовавших различных подходов к использованию и настройке. Сейчас в Kubernetes для таких задач есть общий механизм Ingress.\nIngress — унифицированное решение для управления попадающим в кластер снаружи трафиком независимо от того, как настроен кластер и как трафик доходит непосредственно до его узлов. Объекты типа Ingress позволяют управлять надстройкой IngressController, которых существует огромное множество под разные виды инфраструктуры, разные нужды и разные личные предпочтения. При наличии в кластере IngressController объект типа Ingress позволяет весьма просто получить трафик снаружи и направить его на Service внутри.\nIngress рассчитаны исключительно на стандартный HTTP/HTTPS. Хотя некоторые IngressController могут позволять какие-то более сложные конфигурации, стандартный Ingress позволяет исключительно получать соединения на стандартные порты 80/443 и распределять трафик на основании доменных имён или путей, аналогично тому, как это может делать классический reverse proxy.\nПоведение Ingress определяется набором правил, который описан в блоке rules. В типичном правиле для Ingress указано, на какой backend (как правило, это Service) отправлять запросы, пришедшие на определённые доменное имя и путь.",
    "crumbs": [
      "Лекции",
      "Kubernetes"
    ]
  },
  {
    "objectID": "slides/4.k8s.html#configmap",
    "href": "slides/4.k8s.html#configmap",
    "title": "Kubernetes",
    "section": "ConfigMap",
    "text": "ConfigMap\n\n\napiVersion: v1\nkind: ConfigMap\nmetadata:\n  name: nginx-config\n  labels:\n    app: webserver\ndata:\n  nginx_entrypoint_quiet_logs: \"0\"\n  nginx_conf: |\n    server {\n        listen 80;\n        server_name localhost;\n\n        location / {\n            root /usr/share/nginx/html;\n            index index.html;\n        }\n    }\n\napiVersion: v1\nkind: Pod\nmetadata:\n  name: nginx-pod\n  labels:\n    name: webserver\nspec:\n  containers:\n    - name: nginx-container\n      image: nginx\n      env:\n        - name: NGINX_ENTRYPOINT_QUIET_LOGS\n          valueFrom:\n            configMapKeyRef:\n              name: nginx-config\n              key: nginx_entrypoint_quiet_logs\n      ports:\n        - containerPort: 80\n      volumeMounts:\n        - name: config\n          mountPath: \"/etc/nginx/conf.d\"\n          readOnly: true\n  volumes:\n    - name: config\n      configMap:\n        name: nginx-config\n        items:\n          - key: \"nginx_conf\"\n            path: \"default.conf\"\n\n\nКак уже упоминалось, поды в Kubernetes stateless. Они не хранят состояние, поэтому привычный сценарий “запустить приложение и настроить его” обычно малоприменим. Конечно, можно было бы собирать образа контейнеров с уже настроенным приложением внутри, но это было бы довольно неудобно — малейшее изменение конфигурации потребовало бы пересборки и последующей доставки образов. Поэтому в Kubernetes существуют специальные объекты, которые отвечают за хранение конфигурации для подов.\nConfigMap отвечает за хранение конфигурации внутри кластера. Все данные, необходимые для конфигурации приложения, будь то переменные окружения или файлы конфигурации, задаются непосредственно внутри ConfigMap.\nConfigMap крайне прост: блок data (здесь стоит обратить внимание, что описание ConfigMap не содержит типичного блока spec) содержит в себе данные в формате ключ-значение. Эти данные затем могут быть переданы в контейнера как переменные окружения через параметры env и envFrom, либо как файлы через volumes и volumeMounts.",
    "crumbs": [
      "Лекции",
      "Kubernetes"
    ]
  },
  {
    "objectID": "slides/4.k8s.html#secret",
    "href": "slides/4.k8s.html#secret",
    "title": "Kubernetes",
    "section": "Secret",
    "text": "Secret\napiVersion: v1\nkind: Secret\nmetadata:\n  name: certs\ntype: Opaque\ndata:\n  ca: &gt;-\n    LS0tLS1CRUdJTiBDRVJUSUZJQ0FURS0tLS0tCk1JSUJkakNDQVJ5Z0F3SUJBZ0lSQU5aWXNXb3JrTXFjNzNpQ3phWVZKcEl3Q2dZSUtvWkl6ajBFQXdJ\n    d0R6RU4KTUFzR0ExVUVDaE1FYm1sc01UQWdGdzB5TXpFeU1qZ3dOakUxTVRGYUdBOHlNVEl6TVRJd05EQTJNVFV4TVZvdwpEekVOTUFzR0ExVUVDaE1F\n    Ym1sc01UQlpNQk1HQnlxR1NNNDlBZ0VHQ0NxR1NNNDlBd0VIQTBJQUJHaXNUSThGCnNZMExuWGFTOFFKSEh0SUlvRkE2VzVUZmg2ckdvc1A1d1k2bHhx\n    STNJQjNESTE4b0xWZ2h2cnVLVCtIaDFBK1AKeVVNYmFMLzRmSnFpbVk2alZ6QlZNQTRHQTFVZER3RUIvd1FFQXdJQ0JEQVRCZ05WSFNVRUREQUtCZ2dy\n    QmdFRgpCUWNEQVRBUEJnTlZIUk1CQWY4RUJUQURBUUgvTUIwR0ExVWREZ1FXQkJRdTJyMWFNbkw3UFl4cU1ybmtSZXdkCmZ0a0hLREFLQmdncWhrak9Q\n    UVFEQWdOSUFEQkZBaUJFRnlpRUFaY2FKVW96SzZzdFpzYVdOa2N2dVBSRFNXR3QKU2M1TTJ3NXFoUUloQU90NEJxb09uc2JSaWhjQ1FLOE5VNnJRWW80\n    VmRYRUJQVEgzMTBLZ0s1cXcKLS0tLS1FTkQgQ0VSVElGSUNBVEUtLS0tLQo=\n  cert: &gt;-\n    LS0tLS1CRUdJTiBDRVJUSUZJQ0FURS0tLS0tCk1JSUJ1akNDQVdDZ0F3SUJBZ0lRVEZKL3ZtRStuNjlvSy9HQ0xDVGRwekFLQmdncWhrak9QUVFEQWpB\n    UE1RMHcKQ3dZRFZRUUtFd1J1YVd3eE1DQVhEVEl6TVRJeU9EQTJNVFV4TVZvWUR6SXhNak14TWpBME1EWXhOVEV4V2pBUApNUTB3Q3dZRFZRUUtFd1J1\n    YVd3eU1Ga3dFd1lIS29aSXpqMENBUVlJS29aSXpqMERBUWNEUWdBRVZHcjE4aXVBCkJBUDE4Wnd4M1NuZURZNEhBZ1NSK3VjQ3lXRGR1dHBFYVI5TURH\n    bmNjNWwzckZ6WW9CM2FYcWFnclp4aC9BSDYKdERrQzc0Ung3Y3d0VnFPQm16Q0JtREFPQmdOVkhROEJBZjhFQkFNQ0JhQXdFd1lEVlIwbEJBd3dDZ1lJ\n    S3dZQgpCUVVIQXdFd0RBWURWUjBUQVFIL0JBSXdBREJqQmdOVkhSRUVYREJhZ2lKcGJtZHlaWE56TFc1bmFXNTRMV052CmJuUnliMnhzWlhJdFlXUnRh\n    WE56YVc5dWdqUnBibWR5WlhOekxXNW5hVzU0TFdOdmJuUnliMnhzWlhJdFlXUnQKYVhOemFXOXVMbWx1WjNKbGMzTXRibWRwYm5ndWMzWmpNQW9HQ0Nx\n    R1NNNDlCQU1DQTBnQU1FVUNJUUN4Nk5NYQp6TDJ5SXVTZnZLekZRMThqMWdRd0FzaEVnYmdSZ1Myd2ZZc0MrUUlnTFZ0bHJ6NjBIbGhISGt4eERYbFVV\n    N1RyClU2NkdBcWZMRXUxakl0dVN0c009Ci0tLS0tRU5EIENFUlRJRklDQVRFLS0tLS0K\n  key: &gt;-\n    LS0tLS1CRUdJTiBFQyBQUklWQVRFIEtFWS0tLS0tCk1IY0NBUUVFSUJhWVVQNGZLRExxaFYxUU44aElNNWthMCt2QVVQRTVYRXA6VzgvMGJKUUdvQW9H\n    Q0NxR2NNNDkKQXdFSG9VUURRZ1FFVkdyMThpdUFCQVAxOFp3eDNTbmVEWTRIQWdTUit1Y0N5V0RkdXRwRWFSOU1EO25jYzVsMwpyRnpZb0IzYVhxYWdy\n    WnhoL0FINnREa0M3NFJ4N2N3dFZnPT0KLS0tLS1FTkQgRUMgUFJJVkFURSBLRVktLS0tLQo=\n\nОбъект типа Secret является полным аналогом ConfigMap и используется аналогично, но имеет несколько отличий. В отличие от ConfigMap, Secret, как понятно из названия, существует для хранения секретных данных. Самым заметным отличием является то, что в конфигурации Secret данные закодированы base64, что конечно не даёт особой безопасности, но позволяет защитить данные от “подглядывания из-за спины”. Кроме того, кластер Kubernetes ограничивает доступ к ним для подов, избегает записи данных в них на диск всегда, когда возможно, и поддерживает опциональное шифрование данных Secret в хранилище etcd.\nСуществует несколько разных типов Secret (определяются в блоке type). В большинстве случаев используется тип Opaque, не имеющий никаких специфических свойств, то также существует ряд специальных типов, используемых для авторизации SSH, Docker или даже в сам кластер Kubernetes.\nПри создании Secret можно заменить блок data блоком stringData, и в нем указать все хранимые в Secret в явном виде, без base64. При сохранении они будут закодированы автоматически.",
    "crumbs": [
      "Лекции",
      "Kubernetes"
    ]
  },
  {
    "objectID": "slides/4.k8s.html#persistentvolume",
    "href": "slides/4.k8s.html#persistentvolume",
    "title": "Kubernetes",
    "section": "PersistentVolume",
    "text": "PersistentVolume\n\n\napiVersion: v1\nkind: PersistentVolumeClaim\nmetadata:\n  name: nginx-stored-data\n  labels:\n    name: webserver\nspec:\n  storageClassName: manual\n  accessModes:\n    - ReadWriteOnce\n  resources:\n    requests:\n      storage: 3Gi\napiVersion: v1\nkind: PersistentVolume\nmetadata:\n  name: volume001\n  labels:\n    type: local\nspec:\n  storageClassName: manual\n  capacity:\n    storage: 10Gi\n  accessModes:\n    - ReadWriteOnce\n  hostPath:\n    path: \"/mnt/data\"\n\napiVersion: v1\nkind: Pod\nmetadata:\n  name: nginx-pod\n  labels:\n    name: webserver\nspec:\n  containers:\n    - name: nginx-container\n      image: nginx\n      ports:\n        - containerPort: 80\n      volumeMounts:\n        - name: uploads\n          mountPath: \"/var/www/upload\"\n  volumes:\n    - name: uploads\n      persistentVolumeClaim:\n        claimName: stored-data\n\n\nКроме конфигурации часто нужно хранить и какие-то данные, появившиеся непосредственно во время работы приложения. Для этого существуют PersistentVolume, во многом схожие с томами Docker.\nОбъект PersistentVolume описывает том — некое постоянное хранилище определённого объёма, доступное кластеру. Сам по себе Kubernetes управлять хранилищами не может, вместо него за это отвечают плагины. PersistentVolume бывают множества разных типов, соответствующих разным видам подлежащих хранилищ, поддержка разных типов зависит от установленных на кластере плагинов. В актуальных версиях Kubernetes доступ к различным видам подлежащих хранилищ предоставляется через общий интерфейс CSI, и потому большинство других плагинов и типов PersistentVolume объявлены устаревшими и не рекомендуются к использованию без явной необходимости. Как правило, PersistentVolume в современных кластерах создаются автоматически посредством динамического провизионирования, и создавать их вручную мало где требуется.\nPersistentVolume существуют для объявления некоего хранилища, доступного кластеру — поэтому PersistentVolume никогда не относятся к никакому пространству имён и любой свободный PersistentVolume может быть использован кем угодно. Для того, чтобы объявить что PersistentVolume занят и будет использован приложением, необходимо создать объект PersistentVolumeClaim.\nPersistentVolumeClaim описывает запрос на постоянное хранилище с определёнными параметрами. При наличии свободных подходящих PersistentVolume (либо возможности создать такой автоматически) он будет привязан к PersistentVolumeClaim и может быть немедленно использован приложением, в противном случае PersistentVolumeClaim будет ожидать появления подходящего хранилища.\nPersistentVolumeClaim занимает ближайший подходящий требованиям PersistentVolume. Это означает, что если в кластере существуют тома только размером, например, 10GB, то PersistentVolumeClaim запрашивающий 100MB займёт 10GB, а PersistentVolumeClaim запрашивающий 10.1GB зависнет в ожидании нужного ему тома.\nОсновные параметры PersistentVolumeClaim: - storageClassName: класс хранилища. В кластере могут быть определены любые произвольные классы. storageClassName PersistentVolumeClaim всегда строго соответствует аналогичному параметру PersistentVolume. Данный параметр может быть опущен — тогда будет выбран класс по умолчанию. При использовании динамического провизионирования класс обязательно должен быть такой, какие выделяются доступным провизионером. - accessModes: режимы доступа, бывают четырёх типов: - ReadWriteOnce (RWO): доступен для чтения и записи только с одного узла кластера; - ReadOnlyMany (ROX): доступен только для чтения со всех узлов кластера; - ReadWriteMany (RWX): доступен для чтения и записи со всех узлов кластера; - ReadWriteOncePod (RWOP): доступен для чтения и записи только для одного пода, поддерживается только при использовании CSI. - resources: запрашиваемые объёмы хранилища. Аналогичен параметру resources в конфигурации пода, но может запрашивать только ресурсы storage.",
    "crumbs": [
      "Лекции",
      "Kubernetes"
    ]
  },
  {
    "objectID": "slides/4.k8s.html#minikube",
    "href": "slides/4.k8s.html#minikube",
    "title": "Kubernetes",
    "section": "Minikube",
    "text": "Minikube\nПростейшей для установки и запуска в целях обучения поставкой Kubernetes является Minikube.\nMinikube поставляется в виде одного исполняемого файла, работает на Linux, Windows и macOS, для работы требует только наличия среды виртуализации (KVM, Hyper-V, HyperKit и др.)\nДля установки достаточно скачать исполняемый файл.\nЧасто используемые команды:\n\nminikube start — запускает Kubernetes\n\nminikube start --driver=virtualbox --cpus=4 --memory=16gb --disk-size=32gb — + параметры запуска (VM VirtualBox, 4 vCPU, 16GB RAM, 32GB storage)\n\nminikube stop — останавливает Kubernetes\nminikube pause — приостанавливает Kubernetes\nminikube unpause — продолжает работу после приостановки\nminikube kubectl -- &lt;command&gt; — встроенный клиент kubectl\nminikube dashboard — запускает и даёт доступ к плагину dashboard, позволяющему просматривать состояние кластера через браузер\nminikube addons — управление аддонами Minikube\n\nminikube addons list — выводит список доступных аддонов\nminikube addons enable &lt;name&gt; — включает аддон\nminikube addons disable &lt;name&gt; — выключает аддон\nрекомендуется установить хотя бы следующие аддоны: dashboard, ingress, storage-provisioner\n\nminikube config — управление настройками\n\nminikube config get &lt;name&gt; — выводит значение параметра настройки\nminikube config set &lt;name&gt; &lt;value&gt; — устанавливает значение параметра настройки\nminikube config view — выводит все установленные нестандартные настройки\n\nminikube ip — выводит IP-адрес VM Minikube\nminikube delete — удаляет VM Minikube",
    "crumbs": [
      "Лекции",
      "Kubernetes"
    ]
  },
  {
    "objectID": "slides/4.k8s.html#kubectl",
    "href": "slides/4.k8s.html#kubectl",
    "title": "Kubernetes",
    "section": "kubectl",
    "text": "kubectl\nkubectl — CLI-клиент Kubernetes, базовый инструмент для взаимодействия с кластером.\nЧасто используемые команды:\n\nkubectl --help — вывод встроенной справки, флаг --help может быть использован с любой командой kubectl для получения справки о ней\nkubectl create -f &lt;filename&gt; — создаёт объект из его YAML-конфигурации в файле\nkubectl create &lt;type&gt; &lt;name&gt; — создаёт объект с определённым типом и названием (поддерживается только небольшое количество объектов, параметры определяются через флаги, свои для каждого типа объектов)\nkubectl run &lt;name&gt; --image=&lt;image&gt; — запускает приложение из докер-образа в простейшем поде с одним контейнером\nkubectl expose &lt;type&gt; &lt;name&gt; --port=&lt;port&gt; — создаёт простейший Service, открывающий порт для указанного объекта\nkubectl rollout — управление версиями Deployment и StatefulSet\nkubectl scale &lt;type&gt; &lt;name&gt; --replicas=&lt;count&gt; — изменяет количество реплик для ReplicaSet, Deployment и StatefulSet\nkubectl get &lt;type&gt; — выводит все объекты указанного типа\n\nфлаг -o / --output позволяет установить формат вывода, некоторые форматы: name позволяет получить только имя, wide выдаёт больше информации, yaml/json позволяет получить описание объекта целиком в формате YAML/JSON, jsonpath позволяет запрашивать форматированные и отфильтрованные данные с использованием шаблонов JSONPath\nфлаг -l / --selector позволяет фильтровать выводимые объекты по меткам, например kubectl get pods -l app=webserver выведет все поды с меткой app: webserver\n\nkubectl get &lt;type&gt; &lt;name&gt; — выводит указанный объект\nkubectl explain &lt;type&gt; — выводит документацию по типу объектов\nkubectl describe &lt;type&gt; &lt;name&gt; — выводит подробную информацию по объекту\nkubectl edit &lt;type&gt; &lt;name&gt; — интерактивное редактирование объекта при помощи текстового редактора\n\nредактор можно выбрать, указав его исполняемый файл в переменной окружения KUBE_EDITOR\n\nkubectl delete &lt;type&gt; &lt;name&gt; — удаляет объект\nkubectl exec &lt;pod&gt; -c &lt;container&gt; -- &lt;command&gt; — запускает произвольную команду в контейнере\nkubectl logs &lt;pod&gt; -c &lt;container&gt; — выводит лог контейнера",
    "crumbs": [
      "Лекции",
      "Kubernetes"
    ]
  },
  {
    "objectID": "slides/4.k8s.html#helm",
    "href": "slides/4.k8s.html#helm",
    "title": "Kubernetes",
    "section": "helm",
    "text": "helm\nhelm — это это менеджер пакетов для Kubernetes. Helm поможет управлять приложениями Kubernetes — Helm Charts помогут вам определить, установить и обновить даже самое сложное приложение Kubernetes.\nЧасто используемые команды:\n\nhelm --help — вывод встроенной справки, флаг --help можно использовать с любой командой Helm для получения справки\n\nhelm version — показывает версию Helm (клиента и сервера, если подключён к кластеру)\n\nhelm repo add &lt;name&gt; &lt;url&gt; — добавляет репозиторий чартов\n\nhelm repo update — обновляет список доступных чартов из всех добавленных репозиториев\n\nhelm repo list — выводит список добавленных репозиториев\n\nhelm search repo &lt;keyword&gt; — ищет чарты в добавленных репозиториях\n\nhelm install &lt;release-name&gt; &lt;chart&gt; — устанавливает чарт в кластер\n\n-f &lt;values.yaml&gt; — переопределяет значения из файла конфигурации\n\n--set key=value — переопределяет конкретные параметры\n\n--dry-run — тестовый запуск без реального деплоя\n\n--atomic — автоматически откатывает изменения при ошибке\n\n\nhelm list — выводит список установленных релизов\n\n-a / --all — показывает все релизы, включая удалённые\n\n-n / --namespace — фильтрует по неймспейсу\n\n\nhelm status &lt;release-name&gt; — показывает состояние релиза\n\nhelm upgrade &lt;release-name&gt; &lt;chart&gt; — обновляет релиз до новой версии чарта\n\nhelm rollback &lt;release-name&gt; &lt;revision&gt; — откатывает релиз до предыдущей версии\n\nhelm uninstall &lt;release-name&gt; — удаляет релиз из кластера\n\nhelm history &lt;release-name&gt; — показывает историю изменений релиза\n\nhelm get values &lt;release-name&gt; — выводит установленные значения конфигурации релиза\n\nhelm lint &lt;chart-path&gt; — проверяет чарт на ошибки\n\nhelm template &lt;release-name&gt; &lt;chart&gt; — рендерит манифесты чарта без установки (полезно для отладки)\n\nhelm pull &lt;chart&gt; — скачивает чарт в локальную директорию\n\nhelm create &lt;name&gt; — создаёт шаблон нового чарта\n\nhelm env — выводит переменные окружения Helm\n\nhelm plugin list — показывает установленные плагины",
    "crumbs": [
      "Лекции",
      "Kubernetes"
    ]
  },
  {
    "objectID": "2. clearml_yandex_kube.html",
    "href": "2. clearml_yandex_kube.html",
    "title": "Настройка ClearML Yandex",
    "section": "",
    "text": "Скачайте репозиторий clearml helm charts\n\n\nУпакуйте helm для дальнейшего использования\nhelm package clearml-helm-charts/charts/clearml \n\n\n\nСоздайте Cloud Registry для helm/docker.\nhelm push clearml-7.14.5.tgz oci://registry.yandexcloud.net/&lt;Cloud registry ID&gt;\n\n\n\nЗапустите готовый helm на вашем кластере kubernetes\nhelm install clearml oci://registry.yandexcloud.net/&lt;Cloud registry ID&gt;/clearml:7.14.5",
    "crumbs": [
      "Практика",
      "Настройка ClearML Yandex"
    ]
  },
  {
    "objectID": "2. clearml_yandex_kube.html#package-helm-chart",
    "href": "2. clearml_yandex_kube.html#package-helm-chart",
    "title": "Настройка ClearML Yandex",
    "section": "",
    "text": "Упакуйте helm для дальнейшего использования\nhelm package clearml-helm-charts/charts/clearml",
    "crumbs": [
      "Практика",
      "Настройка ClearML Yandex"
    ]
  },
  {
    "objectID": "2. clearml_yandex_kube.html#push-helm-chart",
    "href": "2. clearml_yandex_kube.html#push-helm-chart",
    "title": "Настройка ClearML Yandex",
    "section": "",
    "text": "Создайте Cloud Registry для helm/docker.\nhelm push clearml-7.14.5.tgz oci://registry.yandexcloud.net/&lt;Cloud registry ID&gt;",
    "crumbs": [
      "Практика",
      "Настройка ClearML Yandex"
    ]
  },
  {
    "objectID": "2. clearml_yandex_kube.html#deploy-helm-chart",
    "href": "2. clearml_yandex_kube.html#deploy-helm-chart",
    "title": "Настройка ClearML Yandex",
    "section": "",
    "text": "Запустите готовый helm на вашем кластере kubernetes\nhelm install clearml oci://registry.yandexcloud.net/&lt;Cloud registry ID&gt;/clearml:7.14.5",
    "crumbs": [
      "Практика",
      "Настройка ClearML Yandex"
    ]
  },
  {
    "objectID": "2. clearml_yandex_kube.html#package-helm-chart-1",
    "href": "2. clearml_yandex_kube.html#package-helm-chart-1",
    "title": "Настройка ClearML Yandex",
    "section": "Package helm chart",
    "text": "Package helm chart\nУпакуйте helm для дальнейшего использования\nhelm package clearml-helm-charts/charts/clearml-agent",
    "crumbs": [
      "Практика",
      "Настройка ClearML Yandex"
    ]
  },
  {
    "objectID": "2. clearml_yandex_kube.html#push-helm-chart-1",
    "href": "2. clearml_yandex_kube.html#push-helm-chart-1",
    "title": "Настройка ClearML Yandex",
    "section": "Push helm chart",
    "text": "Push helm chart\nСоздайте Cloud Registry для helm/docker.\nhelm push clearml-agent-5.3.3.tgz oci://registry.yandexcloud.net/&lt;Cloud registry ID&gt;",
    "crumbs": [
      "Практика",
      "Настройка ClearML Yandex"
    ]
  },
  {
    "objectID": "2. clearml_yandex_kube.html#deploy-helm-chart-1",
    "href": "2. clearml_yandex_kube.html#deploy-helm-chart-1",
    "title": "Настройка ClearML Yandex",
    "section": "Deploy helm chart",
    "text": "Deploy helm chart\nЗапустите готовый helm на вашем кластере kubernetes.\nhelm install clearml-agent oci://registry.yandexcloud.net/&lt;Cloud registry ID&gt;/clearml-agent:5.3.3  --set clearml.agentk8sglueKey=ACCESSKEY --set clearml.agentk8sglueSecret=SECRETKEY --set agentk8sglue.apiServerUrlReference=APISERVERURL --set agentk8sglue.fileServerUrlReference=FILESERVERURL --set agentk8sglue.webServerUrlReference=WEBSERVERURL\nСоздайте доступы в clearml (см. clearml_work.md) и заполните эти поля: * ACCESSKEY значение access_key в новых доступах * SECRETKEY значение secret_key в новых доступах * APISERVERURL значение api_server в новых доступах * FILESSERVERURL значение files_server в новых доступах * WEBSERVERURL значение web_server в новых доступах",
    "crumbs": [
      "Практика",
      "Настройка ClearML Yandex"
    ]
  },
  {
    "objectID": "2. clearml_yandex_kube.html#package-helm-chart-2",
    "href": "2. clearml_yandex_kube.html#package-helm-chart-2",
    "title": "Настройка ClearML Yandex",
    "section": "Package helm chart",
    "text": "Package helm chart\nУпакуйте helm для дальнейшего использования\nhelm package clearml-helm-charts/charts/clearml-serving",
    "crumbs": [
      "Практика",
      "Настройка ClearML Yandex"
    ]
  },
  {
    "objectID": "2. clearml_yandex_kube.html#push-helm-chart-2",
    "href": "2. clearml_yandex_kube.html#push-helm-chart-2",
    "title": "Настройка ClearML Yandex",
    "section": "Push helm chart",
    "text": "Push helm chart\nСоздайте Cloud Registry для helm/docker.\nhelm push clearml-serving-1.6.0.tgz oci://registry.yandexcloud.net/&lt;Cloud registry ID&gt;",
    "crumbs": [
      "Практика",
      "Настройка ClearML Yandex"
    ]
  },
  {
    "objectID": "2. clearml_yandex_kube.html#deploy-helm-chart-2",
    "href": "2. clearml_yandex_kube.html#deploy-helm-chart-2",
    "title": "Настройка ClearML Yandex",
    "section": "Deploy helm chart",
    "text": "Deploy helm chart\nЗапустите готовый helm на вашем кластере kubernetes.\nhelm install clearml-serving oci://registry.yandexcloud.net/&lt;Cloud registry ID&gt;/clearml-serving:1.6.0  --set clearml.apiAccessKey=ACCESSKEY --set clearml.apiSecretKey=SECRETKEY --set clearml.apiHost=APISERVERURL --set clearml.filesHost=FILESERVERURL --set clearml.webHost=WEBSERVERURL --set clearml.servingTaskId=SERVERINGID\nСоздайте доступы в clearml (см. clearml_work.md) и заполните эти поля: * ACCESSKEY значение access_key в новых доступах * SECRETKEY значение secret_key в новых доступах * APISERVERURL значение api_server в новых доступах * FILESSERVERURL значение files_server в новых доступах * WEBSERVERURL значение web_server в новых доступах\nСоздайте с помощью clearml-serving пространство (8. clearml_serving.md), SERVERINGID это его id.",
    "crumbs": [
      "Практика",
      "Настройка ClearML Yandex"
    ]
  },
  {
    "objectID": "4. clearml_data.html",
    "href": "4. clearml_data.html",
    "title": "ClearML Data",
    "section": "",
    "text": "ClearML Data\nВ примере для загрузки начальных данных использовался скрипт mlops-example/1.upload_dataset.ipynb. Для того что бы он работал скачайте датасет Amazon reviews и разархивируйте его в папку mlops-example/data.\nОткройте mlops-example/1.upload_dataset.ipynb и начните его выполнение.\n\nВ самом начале он создает пустой Clearml Dataset (мы рассмотрим работу через SDK, но есть еще и CLI), который мы будем постепенно наполнять данными из данных Amazon reviews. Вы сможете найти ваш датасет в разделе /datasets: http://51.250.106.18:30080/datasets.\n\ndataset = Dataset.create(\n    dataset_name=\"Amazon reviews dataset\",\n    dataset_project=\"Amazon reviews\",\n    dataset_version=\"1.0\",\n    description=\"Data from kagle project\",\n)\ndataset.finalize()\n\nРазбивает обучающую выборки на батчи по 25000 строк в цикле и обрабатывает каждый батч.\n\nfor index, batch in enumerate(\n    pl.read_csv(\n        \"data/train.csv\",\n        has_header=False,\n        new_columns=[\"Polarity\", \"Title\", \"Review\"],\n    )\n    .with_row_index()\n    .with_columns(pl.col(\"index\") // 25000)\n    .partition_by(\"index\")\n):\n\nСначала сохраняет batch локально под уникальным номером.\n\n    batch.write_csv(f\"data/raw/batch_{index}.csv\")\n\nСчитает для него распределение классов\n\n    polaritu_distrib = batch.group_by(\"Polarity\").len()\n\nСоздает новую версию датасета и добавляет в нее новый файл. Заметьте, что у датасета в качестве parent_datasets указана предыдущая версия датасета, это позволяет строить цепочку датасетов.\n\n    dataset = Dataset.create(\n        dataset_name=\"Amazon reviews dataset\",\n        dataset_project=\"Amazon reviews\",\n        parent_datasets=[dataset],\n        dataset_version=f\"1.{index}\",\n        description=\"Data from kagle project\",\n    )\n    dataset.add_files(path=f\"data/raw/batch_{index}.csv\")\n\n\nЗадает мета информацию об изменении датасета в виде гистограммы распределения классов и head добавляемой таблицы.\n\n    dataset.get_logger().report_table(\n        \"Dataset Preview\", \"Dataset Preview\", table_plot=batch.head(5).to_pandas()\n    )\n    dataset.get_logger().report_histogram(\n        title=\"Polarity distribution\",\n        series=\"Polarity distribution\",\n        values=polaritu_distrib[\"len\"].to_list(),\n        xlabels=polaritu_distrib[\"Polarity\"].to_list(),\n        yaxis=\"Number of samples\",\n    )\n\nЗагружает данные в датасет и финализирует новую версию.\n\n    dataset.upload()\n    dataset.finalize()\n\nТеперь вы можете легко получать данные из вашего датасета на любое рабочее место, выполнив такой код: ```python dataset = Dataset.get( dataset_name=“Amazon reviews dataset”, dataset_project=“Amazon reviews”, dataset_version=“1.143”, )",
    "crumbs": [
      "Практика",
      "ClearML Data"
    ]
  },
  {
    "objectID": "6. clearml_research.html",
    "href": "6. clearml_research.html",
    "title": "ClearML Research",
    "section": "",
    "text": "Теперь разберем самое интересное – как можно в ClearML проводить исследования. ClearML предоставляет комплексную платформу для управления ML-экспериментами: - Автоматическое отслеживание кода, параметров, метрик и артефактов - Воспроизводимость экспериментов через фиксацию данных, кода и зависимостей - Масштабирование с помощью удаленных агентов - Сравнение экспериментов через веб-интерфейс\nНиже объясняется как проводить исследования с примерами из 3.tf_idf.py и 4.bert_amazon.ipynb\n\n\n\nИнициализация задачи. Каждый эксперимент начинается с инициализации задачи, вот небольшой пример, но стоит посмотреть на документацию.\n\nfrom clearml import Task\ntask = Task.init(\n    project_name=\"Amazon reviews\",\n    task_name=\"TF-IDF Vectorize BernoulliNB\",  # или \"Bert\"\n    output_uri=True  # Автоматическое логирование артефактов\n)\n\nУправление конфигурацией. ClearML позволяет настроить отслеживание гиперпараметров и настроек:\n\nargs = {\n    \"random_state\": 42,\n    \"max_features\": 1000,\n    \"analyzer\": \"word\"\n}\ntask.connect(args)  # Логирует параметры в ClearML\n\n\nСтоит использовать не локальные данные, а данные которые у нас уже преобразованы в датасет. Это обеспечивает воспроизводимость:\n\nfrom clearml import Dataset\n\n# Получение конкретной версии датасета\ntrain_dataset = Dataset.get(\n    dataset_name=\"Amazon reviews dataset\",\n    dataset_project=\"Amazon reviews\",\n    dataset_version=\"1.2.1\"  # Фиксация версии\n)\nframe_path = train_dataset.get_local_copy()\n\nОбучение моделей и их логирование. Для этого у clearml есть специальный класс который позволяет задавать специальные артефакты–модели, которые в дальнейшем можно будет засерверить.\n\nfrom clearml import OutputModel\n\npipe = Pipeline([\n    (\"tfidf\", TfidfVectorizer()),\n    (\"bernoulli\", BernoulliNB())\n])\npipe.fit(train_x, train_y)\n\n# Сохранение и логирование модели\njoblib.dump(pipe, \"model.pkl\")\noutput_model = OutputModel(task=task, framework=\"scikit-learn\")\noutput_model.update_weights(weights_filename=\"model.pkl\")\n \n\nОтслеживание экспериментов и метрик может производиться как в отношении эксперимента, так и отдельных артефактов моделей/датасетов, ниже приведен пример как можно залогировать classification_report и он будет сохранен и в задании и в описании модели.\n\nimport pandas as pd\nfrom sklearn.metrics import classification_report\nfrom clearml import Logger\n\nlogger: Logger = task.get_logger()\n\npred_y = pipe.predict(test_x[\"corpus\"])\nclassification_report_table = pd.DataFrame(\n    classification_report(test_y, pred_y, output_dict=True)\n).T\nlogger.report_table(\n    \"Classifiacation Report\", \"Metrics\", table_plot=classification_report_table\n)\noutput_model.report_table(\n    \"Classifiacation Report\", \"Metrics\", table_plot=classification_report_table\n)\nclassification_report_table\n\n\nМожно заниматься логированием отдельных артефактов в задания, например эмбендингов полученных от bert’a, что бы использовать их в других экспериментах.\n\n# Загрузка эмбеддингов (пример BERT)\ntask.upload_artifact(\"train_embeddings\", train_embeddings)\n\nClearML автоматически фиксирует:\n\n\nКонсольный вывод\nИсходный код (с созданием Git-снимка)\nУстановленные зависимости\nСистемные метрики (CPU/GPU/память) Для этого не требуется дополнительный код.\n\n\nСравнение экспериментов в ClearML есть инструменты для сравнения экспериментов, вы можете легко сравнивать результаты разных экспериментов и графики и метрики.\n\n\n\n\n\n\nИнициализация задачи: Начните отслеживание перед выполнением кода\nКонфигурация параметров: Используйте task.connect() для воспроизводимости и повторных удаленных запусков на clearml agent с другими параметрами.\nВерсионирование данных: Выбирайте версии датасетов через Dataset.get(), и лучше установить версию как параметр, что бы вы легко могли воспроизвести эксперимент на следующих инкрементах данных.\nВыполнение эксперимента:\n\nАвтоматическое/ручное логирование метрик\nСохранение моделей через OutputModel\nЛогирование артефактов через task.upload_artifact()\n\nФинализация: task.mark_completed() – по завершении пометьте эксперимент выполненным\nВоспроизведение:\n\nКлонирование задачи через веб-интерфейс\nЗапуск на удаленном агенте с новыми параметрами\n\nСравнение экспериментов с различными параметрами в веб интерфейсе",
    "crumbs": [
      "Практика",
      "ClearML Research"
    ]
  },
  {
    "objectID": "6. clearml_research.html#ключевые-шаги-исследований-в-clearml",
    "href": "6. clearml_research.html#ключевые-шаги-исследований-в-clearml",
    "title": "ClearML Research",
    "section": "",
    "text": "Инициализация задачи. Каждый эксперимент начинается с инициализации задачи, вот небольшой пример, но стоит посмотреть на документацию.\n\nfrom clearml import Task\ntask = Task.init(\n    project_name=\"Amazon reviews\",\n    task_name=\"TF-IDF Vectorize BernoulliNB\",  # или \"Bert\"\n    output_uri=True  # Автоматическое логирование артефактов\n)\n\nУправление конфигурацией. ClearML позволяет настроить отслеживание гиперпараметров и настроек:\n\nargs = {\n    \"random_state\": 42,\n    \"max_features\": 1000,\n    \"analyzer\": \"word\"\n}\ntask.connect(args)  # Логирует параметры в ClearML\n\n\nСтоит использовать не локальные данные, а данные которые у нас уже преобразованы в датасет. Это обеспечивает воспроизводимость:\n\nfrom clearml import Dataset\n\n# Получение конкретной версии датасета\ntrain_dataset = Dataset.get(\n    dataset_name=\"Amazon reviews dataset\",\n    dataset_project=\"Amazon reviews\",\n    dataset_version=\"1.2.1\"  # Фиксация версии\n)\nframe_path = train_dataset.get_local_copy()\n\nОбучение моделей и их логирование. Для этого у clearml есть специальный класс который позволяет задавать специальные артефакты–модели, которые в дальнейшем можно будет засерверить.\n\nfrom clearml import OutputModel\n\npipe = Pipeline([\n    (\"tfidf\", TfidfVectorizer()),\n    (\"bernoulli\", BernoulliNB())\n])\npipe.fit(train_x, train_y)\n\n# Сохранение и логирование модели\njoblib.dump(pipe, \"model.pkl\")\noutput_model = OutputModel(task=task, framework=\"scikit-learn\")\noutput_model.update_weights(weights_filename=\"model.pkl\")\n \n\nОтслеживание экспериментов и метрик может производиться как в отношении эксперимента, так и отдельных артефактов моделей/датасетов, ниже приведен пример как можно залогировать classification_report и он будет сохранен и в задании и в описании модели.\n\nimport pandas as pd\nfrom sklearn.metrics import classification_report\nfrom clearml import Logger\n\nlogger: Logger = task.get_logger()\n\npred_y = pipe.predict(test_x[\"corpus\"])\nclassification_report_table = pd.DataFrame(\n    classification_report(test_y, pred_y, output_dict=True)\n).T\nlogger.report_table(\n    \"Classifiacation Report\", \"Metrics\", table_plot=classification_report_table\n)\noutput_model.report_table(\n    \"Classifiacation Report\", \"Metrics\", table_plot=classification_report_table\n)\nclassification_report_table\n\n\nМожно заниматься логированием отдельных артефактов в задания, например эмбендингов полученных от bert’a, что бы использовать их в других экспериментах.\n\n# Загрузка эмбеддингов (пример BERT)\ntask.upload_artifact(\"train_embeddings\", train_embeddings)\n\nClearML автоматически фиксирует:\n\n\nКонсольный вывод\nИсходный код (с созданием Git-снимка)\nУстановленные зависимости\nСистемные метрики (CPU/GPU/память) Для этого не требуется дополнительный код.\n\n\nСравнение экспериментов в ClearML есть инструменты для сравнения экспериментов, вы можете легко сравнивать результаты разных экспериментов и графики и метрики.",
    "crumbs": [
      "Практика",
      "ClearML Research"
    ]
  },
  {
    "objectID": "6. clearml_research.html#шаги-рабочего-процесса",
    "href": "6. clearml_research.html#шаги-рабочего-процесса",
    "title": "ClearML Research",
    "section": "",
    "text": "Инициализация задачи: Начните отслеживание перед выполнением кода\nКонфигурация параметров: Используйте task.connect() для воспроизводимости и повторных удаленных запусков на clearml agent с другими параметрами.\nВерсионирование данных: Выбирайте версии датасетов через Dataset.get(), и лучше установить версию как параметр, что бы вы легко могли воспроизвести эксперимент на следующих инкрементах данных.\nВыполнение эксперимента:\n\nАвтоматическое/ручное логирование метрик\nСохранение моделей через OutputModel\nЛогирование артефактов через task.upload_artifact()\n\nФинализация: task.mark_completed() – по завершении пометьте эксперимент выполненным\nВоспроизведение:\n\nКлонирование задачи через веб-интерфейс\nЗапуск на удаленном агенте с новыми параметрами\n\nСравнение экспериментов с различными параметрами в веб интерфейсе",
    "crumbs": [
      "Практика",
      "ClearML Research"
    ]
  },
  {
    "objectID": "8. clearml_serving.html",
    "href": "8. clearml_serving.html",
    "title": "ClearML Servering",
    "section": "",
    "text": "Установите clearml-serving\n\npixi add --pypi clearml-serving\npixi install -a\n\nСоздайте clearml serving controller:\n\npixi run clearml-serving create --name  \"Amazon Reviews\"\nПолучите его ID для развертки clearml-serving в kubernetess\nNew Serving Service created: id=3e0e2ce884444da694fb774ef94ecc5f\n\nПерейдите к инструкции из 2. clearml_yandex_kube.md. Используйте полученный ID как SERVERINGID. Обратите внимание, что в serving нужно добавить зависимости в values.yaml\n\nclearml_serving_inference:\n  ...\n  extraPythonPackages:\n  - nltk==3.9.1\n  - polars&gt;=1.31.0,&lt;2\n\nДалее работаем с clearml-serving, (Вот тут документация)\n\n\n\n\n\nСтоит опубликовать вашу модель, которую вы хотите использовать, выберете в артефактах вашу модель и нажмите publish в ее меню. \nДалее нужно подготовить prepreprocessing для данных на вход модели, варианты можно найти в примерах. Вам нужно по сути написать класс Preprocessing в виде класса в фалйле, вот пример для подготовки данных в tf-idf\n\nclass Preprocess(object):\n    def __init__(self):\n        # set internal state, this will be called only once. (i.e. not per request)\n        pass\n\n    def preprocess(\n        self, body: dict, state: dict, collect_custom_statistics_fn=None\n    ) -&gt; Any:\n        # we expect to get two valid on the dict x0, and x1\n        text = body.get(\"text\", None)\n        processed_words = text_preprocessing(text).split(\" \")\n        lemmatizer = WordNetLemmatizer()\n        processed_text = \" \".join(\n            [lemmatizer.lemmatize(token) for token in processed_words]\n        )\n        return [processed_text]\n\n    def postprocess(\n        self, data: Any, state: dict, collect_custom_statistics_fn=None\n    ) -&gt; dict:\n        # post process the data returned from the model inference engine\n        # data is the return value from model.predict we will put is inside a return value as Y\n        return dict(y=data.tolist() if isinstance(data, np.ndarray) else data)\n\nДобавьте модель в serving:\n\npixi run clearml-serving --id 3e0e2ce884444da694fb774ef94ecc5f model auto-update --engine sklearn --endpoint \"sentiment_analyze\" --published --project \"Amazon reviews\" --name \"TF-IDF Vectorize BernoulliNB\" --max-versions 5 --preprocess \"mlops-example/mlops_example/preprocessing.py\"\nВот разбор команды: - Указываем --id   3e0e2ce884444da694fb774ef94ecc5f созданного контроллера - Выбираем режим модели model auto-update для автообновления при публикации новых моделей - Указываем фреймворк модели --engine sklearn (см документацию) - Определяем ендпоинт для доступа к модели --endpoint \"sentiment_analyze\" - Указываем параметры модели: опубликованные модели --published определенного проекта --project \"Amazon reviews\" под названием --name \"TF-IDF Vectorize BernoulliNB\" - Максимальное количество версий модели которые могут быть запущены --max-versions 5 - Указываем скрипт препроцессинга --preprocess \"mlops-example/mlops_example/preprocessing.py\"\n\nТеперь перейдите в проект DevOps, там в задаче Amazon Reviews - serve instance будут логи добавления модели.  Так же можете выполнить команду:\n\npixi run clearml-serving --id 3e0e2ce884444da694fb774ef94ecc5f model list\nИ увидеть что модели загружены:\nclearml-serving - CLI for launching ClearML serving engine\nList model serving and endpoints, control task id=3e0e2ce884444da694fb774ef94ecc5f\nInfo: syncing model endpoint configuration, state hash=378b860f5e9c7c07f37320fe4033bdad\nEndpoints:\n{}\nModel Monitoring:\n{\n  \"sentiment_analyze\": {\n    \"base_serving_url\": \"sentiment_analyze\",\n    \"engine_type\": \"sklearn\",\n    \"monitor_project\": \"Amazon reviews\",\n    \"monitor_name\": \"TF-IDF Vectorize BernoulliNB\",\n    \"monitor_tags\": [],\n    \"only_published\": true,\n    \"max_versions\": 5,\n    \"input_size\": null,\n    \"input_type\": null,\n    \"input_name\": null,\n    \"output_size\": null,\n    \"output_type\": null,\n    \"output_name\": null,\n    \"preprocess_artifact\": \"py_code_sentiment_analyze\",\n    \"auxiliary_cfg\": null\n  }\n}\nCanary:\n{}\n\n\n\nПопробуем потестировать модель, сразу оговорюсь нужно делать тесты мз сети yc, так как для моделей не проброшены внешние порты, для этого можно развернуть виртуалку. Попробуем первый запрос, мы будем обращаться к модели с ID=27c2c1bb0af74984a3a22e702f65fdf9, поэтому в url указываем версию 2.\ncurl -X POST \"http://10.112.135.102:8080/serve/sentiment_analyze/2\" -H \"accept: application/json\" -H \"Content-Type: application/json\" -d \"{\\\"text\\\": \\\"Taking this out of my daughter's library, I found this book and thought the illustrtions were absolutey beautiful -- a true work of artistry. However, I didn't read it through before I bought it. I was reading it to my daughter when I discovered how disturbing the story turns with the spanking scenes. I stopped reading the book and I will take it out of my house.\\\"}\"\nОтвет модели: {\"y\":[2]}\nТеперь второй запрос:\ncurl -X POST \"http://10.112.135.102:8080/serve/sentiment_analyze/2\" -H \"accept: application/json\" -H \"Content-Type: application/json\" -d \"{\\\"text\\\": \\\"Scratched the lens with a kleenex,I used these once then used a Kleenex to wipe one lens that was a little smudged. I have microscopic vision and I noticed it was scratched AFTER I used the Kleenex, so to be sure, I used it again and sure enough, it scratched the lens some more. I compared the 2 lenses and the other lens looked pristine, whereas the one I used the kleenex on was scratched all over Very low quality lenses! Unusable after one use\\\"}\"\nОтвет модели: {\"y\":[1]}\nВидим что модель работает и назначает соответствующие лейблы. Отлично у вас есть развернутая модель которую можно использовать и отправлять ей разные запросы.",
    "crumbs": [
      "Практика",
      "ClearML Servering"
    ]
  },
  {
    "objectID": "8. clearml_serving.html#базовая-настройка",
    "href": "8. clearml_serving.html#базовая-настройка",
    "title": "ClearML Servering",
    "section": "",
    "text": "Установите clearml-serving\n\npixi add --pypi clearml-serving\npixi install -a\n\nСоздайте clearml serving controller:\n\npixi run clearml-serving create --name  \"Amazon Reviews\"\nПолучите его ID для развертки clearml-serving в kubernetess\nNew Serving Service created: id=3e0e2ce884444da694fb774ef94ecc5f\n\nПерейдите к инструкции из 2. clearml_yandex_kube.md. Используйте полученный ID как SERVERINGID. Обратите внимание, что в serving нужно добавить зависимости в values.yaml\n\nclearml_serving_inference:\n  ...\n  extraPythonPackages:\n  - nltk==3.9.1\n  - polars&gt;=1.31.0,&lt;2\n\nДалее работаем с clearml-serving, (Вот тут документация)",
    "crumbs": [
      "Практика",
      "ClearML Servering"
    ]
  },
  {
    "objectID": "8. clearml_serving.html#добвавлние-моделей",
    "href": "8. clearml_serving.html#добвавлние-моделей",
    "title": "ClearML Servering",
    "section": "",
    "text": "Стоит опубликовать вашу модель, которую вы хотите использовать, выберете в артефактах вашу модель и нажмите publish в ее меню. \nДалее нужно подготовить prepreprocessing для данных на вход модели, варианты можно найти в примерах. Вам нужно по сути написать класс Preprocessing в виде класса в фалйле, вот пример для подготовки данных в tf-idf\n\nclass Preprocess(object):\n    def __init__(self):\n        # set internal state, this will be called only once. (i.e. not per request)\n        pass\n\n    def preprocess(\n        self, body: dict, state: dict, collect_custom_statistics_fn=None\n    ) -&gt; Any:\n        # we expect to get two valid on the dict x0, and x1\n        text = body.get(\"text\", None)\n        processed_words = text_preprocessing(text).split(\" \")\n        lemmatizer = WordNetLemmatizer()\n        processed_text = \" \".join(\n            [lemmatizer.lemmatize(token) for token in processed_words]\n        )\n        return [processed_text]\n\n    def postprocess(\n        self, data: Any, state: dict, collect_custom_statistics_fn=None\n    ) -&gt; dict:\n        # post process the data returned from the model inference engine\n        # data is the return value from model.predict we will put is inside a return value as Y\n        return dict(y=data.tolist() if isinstance(data, np.ndarray) else data)\n\nДобавьте модель в serving:\n\npixi run clearml-serving --id 3e0e2ce884444da694fb774ef94ecc5f model auto-update --engine sklearn --endpoint \"sentiment_analyze\" --published --project \"Amazon reviews\" --name \"TF-IDF Vectorize BernoulliNB\" --max-versions 5 --preprocess \"mlops-example/mlops_example/preprocessing.py\"\nВот разбор команды: - Указываем --id   3e0e2ce884444da694fb774ef94ecc5f созданного контроллера - Выбираем режим модели model auto-update для автообновления при публикации новых моделей - Указываем фреймворк модели --engine sklearn (см документацию) - Определяем ендпоинт для доступа к модели --endpoint \"sentiment_analyze\" - Указываем параметры модели: опубликованные модели --published определенного проекта --project \"Amazon reviews\" под названием --name \"TF-IDF Vectorize BernoulliNB\" - Максимальное количество версий модели которые могут быть запущены --max-versions 5 - Указываем скрипт препроцессинга --preprocess \"mlops-example/mlops_example/preprocessing.py\"\n\nТеперь перейдите в проект DevOps, там в задаче Amazon Reviews - serve instance будут логи добавления модели.  Так же можете выполнить команду:\n\npixi run clearml-serving --id 3e0e2ce884444da694fb774ef94ecc5f model list\nИ увидеть что модели загружены:\nclearml-serving - CLI for launching ClearML serving engine\nList model serving and endpoints, control task id=3e0e2ce884444da694fb774ef94ecc5f\nInfo: syncing model endpoint configuration, state hash=378b860f5e9c7c07f37320fe4033bdad\nEndpoints:\n{}\nModel Monitoring:\n{\n  \"sentiment_analyze\": {\n    \"base_serving_url\": \"sentiment_analyze\",\n    \"engine_type\": \"sklearn\",\n    \"monitor_project\": \"Amazon reviews\",\n    \"monitor_name\": \"TF-IDF Vectorize BernoulliNB\",\n    \"monitor_tags\": [],\n    \"only_published\": true,\n    \"max_versions\": 5,\n    \"input_size\": null,\n    \"input_type\": null,\n    \"input_name\": null,\n    \"output_size\": null,\n    \"output_type\": null,\n    \"output_name\": null,\n    \"preprocess_artifact\": \"py_code_sentiment_analyze\",\n    \"auxiliary_cfg\": null\n  }\n}\nCanary:\n{}",
    "crumbs": [
      "Практика",
      "ClearML Servering"
    ]
  },
  {
    "objectID": "8. clearml_serving.html#тестирвоание-модели",
    "href": "8. clearml_serving.html#тестирвоание-модели",
    "title": "ClearML Servering",
    "section": "",
    "text": "Попробуем потестировать модель, сразу оговорюсь нужно делать тесты мз сети yc, так как для моделей не проброшены внешние порты, для этого можно развернуть виртуалку. Попробуем первый запрос, мы будем обращаться к модели с ID=27c2c1bb0af74984a3a22e702f65fdf9, поэтому в url указываем версию 2.\ncurl -X POST \"http://10.112.135.102:8080/serve/sentiment_analyze/2\" -H \"accept: application/json\" -H \"Content-Type: application/json\" -d \"{\\\"text\\\": \\\"Taking this out of my daughter's library, I found this book and thought the illustrtions were absolutey beautiful -- a true work of artistry. However, I didn't read it through before I bought it. I was reading it to my daughter when I discovered how disturbing the story turns with the spanking scenes. I stopped reading the book and I will take it out of my house.\\\"}\"\nОтвет модели: {\"y\":[2]}\nТеперь второй запрос:\ncurl -X POST \"http://10.112.135.102:8080/serve/sentiment_analyze/2\" -H \"accept: application/json\" -H \"Content-Type: application/json\" -d \"{\\\"text\\\": \\\"Scratched the lens with a kleenex,I used these once then used a Kleenex to wipe one lens that was a little smudged. I have microscopic vision and I noticed it was scratched AFTER I used the Kleenex, so to be sure, I used it again and sure enough, it scratched the lens some more. I compared the 2 lenses and the other lens looked pristine, whereas the one I used the kleenex on was scratched all over Very low quality lenses! Unusable after one use\\\"}\"\nОтвет модели: {\"y\":[1]}\nВидим что модель работает и назначает соответствующие лейблы. Отлично у вас есть развернутая модель которую можно использовать и отправлять ей разные запросы.",
    "crumbs": [
      "Практика",
      "ClearML Servering"
    ]
  }
]