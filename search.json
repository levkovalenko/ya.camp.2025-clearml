[
  {
    "objectID": "9. clearml_extend_pipes.html",
    "href": "9. clearml_extend_pipes.html",
    "title": "Расширение ClearML pipelines",
    "section": "",
    "text": "Расширение ClearML pipelines\nЕще немного вернемся к пайплайнам, кроме пайплайнов из кода, как это было показано в 5. clearml_pipeline.md, можно создавать пайплайны из задач. Давайте разберемся, что для этого надо и рассмотрим файл mlops-example/5.full_pipe.py.\n\nТочно также инициализируем пайплайн, как делали ранее и задаем ему все необходимые параметры:\n\nfrom clearml import PipelineController\n\npipe = PipelineController(\n    name=\"FullPipeline\",\n    project=\"Amazon reviews\",\n    version=\"0.0.1\",\n    packages=[\"./mlops-example\"],\n    docker=\"python:3.11.13-slim-bookworm\",\n    enable_local_imports=True,\n    # working_dir=\"./mlops-example\",\n)\n\npipe.add_parameter(\n    name=\"dataset_name\",\n    description=\"ClearML dataset name\",\n    default=\"Amazon reviews dataset\",\n)\npipe.add_parameter(\n    name=\"dataset_project\",\n    description=\"ClearML project\",\n    default=\"Amazon reviews\",\n)\npipe.add_parameter(\n    name=\"dataset_version\",\n    description=\"ClearML dataset version\",\n    default=\"1.2\",\n)\npipe.add_parameter(\n    name=\"test_size\", description=\"Test ratio size\", default=0.2, param_type=\"float\"\n)\npipe.add_parameter(\n    name=\"random_state\", description=\"Random state\", default=42, param_type=\"int\"\n)\npipe.add_parameter(\n    name=\"max_features\",\n    description=\"Tf-idf features limit\",\n    default=1000,\n    param_type=\"int\",\n)\npipe.add_parameter(\n    name=\"analyzer\",\n    description=\"Tf-idf analyzer\",\n    default=\"word\",\n    param_type=\"str\",\n)\n\nЗададим первый шаг и включим в него весь пайплайн подготовки данных из mlops-example/5.full_pipe.py. В нем указываем base_task_id=\"1ecd1cacb1db4f40a362a67d629fe14f\", которая определит задачу которая должна выполняться на этом шаге, переопределим ее параметры и донастроим. По параметрам, их нужно писать так: Section/Param name, что бы корректно переопределить.\n\npipe.add_step(\n    name=\"data_prepare\",\n    base_task_id=\"1ecd1cacb1db4f40a362a67d629fe14f\",\n    parameter_override={\n        \"Args/dataset_name\": \"${pipeline.dataset_name}\",\n        \"Args/dataset_project\": \"${pipeline.dataset_project}\",\n        \"Args/dataset_version\": \"${pipeline.dataset_version}\",\n        \"Args/random_state\": \"${pipeline.random_state}\",\n        \"Args/test_size\": \"${pipeline.test_size}\",\n    },\n    cache_executed_step=True,\n    execution_queue=\"default\",\n)\nВ результате при выполнении у нас будет запускаться дополнительно этот пайплайн \n\nЗададим шаг на основе mlops-example/3.tf_idf.py, работа с ним описана в 6. clearml_research.md. Точно также указываем base_task_id=\"b5217b5ef85e4e4aa630c672f8177973\" из clearml и переопределяем параметры, а также указываем что следует она после выполнения подпайплайна data_prepare.\n\npipe.add_step(\n    name=\"fit_model\",\n    base_task_id=\"b5217b5ef85e4e4aa630c672f8177973\",\n    parameter_override={\n        \"General/dataset_name\": \"${pipeline.dataset_name}\",\n        \"General/dataset_project\": \"${pipeline.dataset_project}\",\n        \"General/train_dataset_version\": \"${pipeline.dataset_version}.2\",\n        \"General/test_dataset_version\": \"${pipeline.dataset_version}.3\",\n        \"General/dataset_version\": \"${pipeline.dataset_version}.4\",\n        \"General/random_state\": \"${pipeline.random_state}\",\n        \"General/max_features\": \"${pipeline.max_features}\",\n        \"General/analyzer\": \"${pipeline.analyzer}\",\n    },\n    parents=[\"data_prepare\"],\n    cache_executed_step=True,\n    execution_queue=\"default\",\n)\nПосле выполнения подпайплайна data_prepare переходит к выполнению этой задачи. И так у нас есть цельный пайплайн по обработке данных и обучению модели, который мы можем запустить на любой версии данных.",
    "crumbs": [
      "Практика",
      "Расширение ClearML pipelines"
    ]
  },
  {
    "objectID": "7. clearml_reports.html",
    "href": "7. clearml_reports.html",
    "title": "ClearML Reports",
    "section": "",
    "text": "ClearML предоставляет мощные инструменты для создания отчетов о результатах экспериментов. Отчеты позволяют документировать и визуализировать результаты исследований, сравнивать разные эксперименты и делиться выводами с командой.\n\n\n\nCodeLess отчеты на основе залогированных метрик и артефактов\nСравнение экспериментов в табличном или графическом виде\nВстраивание визуализаций (графики, таблицы, изображения)\nВерсионирование отчетов вместе с экспериментами\n\n\n\n\n\n\nСоздание:\n\nВ разделе Reports → Create New Report\nИспользуйте визуальный редактор или Markdown\n\nНаписание отчета\n\nОписывайте постановку задачи/эксперимента/исследования\nПрикладывайте результаты различных экспериментов и описывайте их\nФиксируйте свои наблюдения и предположения\n\nРевью отчета\n\nОбсуждайте результаты с коллегами\nФиксируйте вопросы к отчетам и замечаниям\nПравьте отчет и дополняйте его\nПосле его полной финализации – опубликуйте его",
    "crumbs": [
      "Практика",
      "ClearML Reports"
    ]
  },
  {
    "objectID": "7. clearml_reports.html#основные-возможности-отчетов",
    "href": "7. clearml_reports.html#основные-возможности-отчетов",
    "title": "ClearML Reports",
    "section": "",
    "text": "CodeLess отчеты на основе залогированных метрик и артефактов\nСравнение экспериментов в табличном или графическом виде\nВстраивание визуализаций (графики, таблицы, изображения)\nВерсионирование отчетов вместе с экспериментами",
    "crumbs": [
      "Практика",
      "ClearML Reports"
    ]
  },
  {
    "objectID": "7. clearml_reports.html#работа-с-отчетами-через-веб-интерфейс",
    "href": "7. clearml_reports.html#работа-с-отчетами-через-веб-интерфейс",
    "title": "ClearML Reports",
    "section": "",
    "text": "Создание:\n\nВ разделе Reports → Create New Report\nИспользуйте визуальный редактор или Markdown\n\nНаписание отчета\n\nОписывайте постановку задачи/эксперимента/исследования\nПрикладывайте результаты различных экспериментов и описывайте их\nФиксируйте свои наблюдения и предположения\n\nРевью отчета\n\nОбсуждайте результаты с коллегами\nФиксируйте вопросы к отчетам и замечаниям\nПравьте отчет и дополняйте его\nПосле его полной финализации – опубликуйте его",
    "crumbs": [
      "Практика",
      "ClearML Reports"
    ]
  },
  {
    "objectID": "5. clearml_pipeline.html",
    "href": "5. clearml_pipeline.html",
    "title": "ClearML Pipelines",
    "section": "",
    "text": "Теперь разберем работу с ClearML agent и ClearML pipeline.\n\n\nБыстрый его запуск разобран в 2. clearml_yandex_kube.md, сейчас мы уделим внимание его более детальной настройки и чуть-уть разберем его helm chart.\nВесь перечень параметров представлен в репозитории clearml-helm-charts\n\nСтоит уделить внимание версии самого ClearML-agent, на момент подготовки курса доступна версия 1.9.3, но она не корректно работает с задачами в очереди (см. issue). Поэту ставим специально понижаем версию до последней рабочей.\n\nagentk8sglue:\n  ...\n  extraEnvs:\n  - name: CLEARML_AGENT_UPDATE_VERSION\n    value: \"==1.9.2\"\n\nТакже стоит изменить образ который будет использоваться для запуска задач на нужный вам (возможно кастомный). Опять же советую использовать python не выше 3.11, что бы не возникало проблем с использованием более старых версий библиотек на следующих этапах.\n\nagentk8sglue:\n  ...\n  defaultContainerImage: python:3.11.13-slim-bookworm\n\nВнеся такие изменения вы в целом можете разворачивать его на kubernetes и использовать для выполнения пайплайнов и экспериментов.\n\n\n\n\nClearML позволяет составлять пайплайны, формируя их из существующих задач или прописывая специализированный код используя pipeline SDK. Сейчас мы разберем пример pipeline реализованного с помощью PipelineController, для этого надо посмотреть в файл 2.train_test_split.py, давайте его запустим:\npixi run python mlops-example/2.train_test_split.py\nА пока он исполняется, разберем код пайплайна:\n\nСоздается основной объект пайплайна, ему указывается имя, проект, версия, специальные зависимости, докер образ для исполнения и возможность локального импорта модулей. Далее мы будем работать с этим объектом и его донастраивать.\n\npipe = PipelineController(\n    name=\"DataPrepare\",\n    project=\"Amazon reviews\",\n    version=\"0.0.1\",\n    packages=[\"./mlops-example\", \"numpy==1.26.4\"],\n    docker=\"python:3.11.13-slim-bookworm\",\n    enable_local_imports=True,\n)\n\nПайплайну задаются основные параметры, которые в дальнейшем мы сможем задавать в интерфейсе clearml.\n\npipe.add_parameter(\n    name=\"dataset_name\",\n    description=\"ClearML dataset name\",\n    default=\"Amazon reviews dataset\",\n)\npipe.add_parameter(\n    name=\"dataset_project\",\n    description=\"ClearML project\",\n    default=\"Amazon reviews\",\n)\npipe.add_parameter(\n    name=\"dataset_version\",\n    description=\"ClearML dataset version\",\n    default=\"1.2\",\n)\npipe.add_parameter(\n    name=\"test_size\", description=\"Test ratio size\", default=0.2, param_type=\"float\"\n)\npipe.add_parameter(\n    name=\"random_state\", description=\"Random state\", default=42, param_type=\"int\"\n)\n\n\nДалее описываются функции, которые будут исполняться. Обратит внимание Что основные импорты находятся внутри функции, это позволяет clearml автоматически считать зависимости которые необходимы для работы этого кода, но на практике лучше вручную задавать зависимости для каждого шага, что бы установить корректные версии библиотек. Здесь пример функции которая занимается разделение данные на train и test, и складывает их в новую версию датасета: X.X.1.\n\ndef dataset_train_test_split(\n    dataset_name,\n    dataset_project,\n    dataset_version,\n    test_size,\n    random_state,\n    version_postfix,\n):\n    from pathlib import Path\n\n    import pandas as pd\n    import polars as pl\n    import pyarrow\n    from clearml import Dataset, Logger\n    from sklearn.model_selection import train_test_split\n\n    print(pyarrow.__version__)\n\n    dataset = Dataset.get(\n        dataset_name=dataset_name,\n        dataset_project=dataset_project,\n        dataset_version=dataset_version,\n    )\n    datset_path = Path(dataset.get_local_copy())\n\n    data: pd.DataFrame = pl.concat(\n        [pl.read_csv(data_file) for data_file in datset_path.iterdir()]\n    )\n    train, test = train_test_split(\n        data.to_pandas(), test_size=float(test_size), random_state=int(random_state)\n    )\n    train_distrib = class_distribution(train, \"Polarity\")\n    test_distrib = class_distribution(test, \"Polarity\")\n    result_path = Path(\"data/prepared/split\")\n    result_path.mkdir(exist_ok=True, parents=True)\n    train.to_csv(result_path / \"raw_train.csv\", index=False)\n    test.to_csv(result_path / \"raw_test.csv\", index=False)\n    prepared_dataset = Dataset.create(\n        dataset_name=dataset_name,\n        dataset_project=dataset_project,\n        dataset_version=f\"{dataset_version}.{version_postfix}\",\n        parent_datasets=[dataset],\n    )\n    prepared_dataset.add_files(result_path)\n    prepared_dataset.upload()\n    prepared_dataset.get_logger().report_plotly(\n        \"Class distribution\", \"Train\", train_distrib\n    )\n    prepared_dataset.get_logger().report_plotly(\n        \"Class distribution\", \"Test\", test_distrib\n    )\n    prepared_dataset.finalize()\n\n    pipe_logger = Logger.current_logger()\n    pipe_logger.report_plotly(\"Class distribution\", \"Train\", train_distrib)\n    pipe_logger.report_plotly(\"Class distribution\", \"Test\", test_distrib)\n    return (\n        pl.from_pandas(train, include_index=False),\n        pl.from_pandas(test, include_index=False),\n        prepared_dataset.id,\n    )\n\nДобавляем первый функциональный шаг, указываем его имя, функцию которая его исполняет, ее аргументы, используя параметры pipeline, так же указываем какие артефакты сохранить на этом шаге в качестве возвращаемых значений функции, указываем что этот шаг может быть закеширован, указываем очередь для передачи ее ClearML agent, если вы ее не настраивали, то это default, Так же у нас идут helper fucntions, они нужны что бы код шага корректно сгенерировался, и наконец специфичные зависимости для шага.\n\npipe.add_function_step(\n    name=\"train_test_split\",\n    function=dataset_train_test_split,\n    function_kwargs=dict(\n        dataset_name=\"${pipeline.dataset_name}\",\n        dataset_project=\"${pipeline.dataset_project}\",\n        dataset_version=\"${pipeline.dataset_version}\",\n        test_size=\"${pipeline.test_size}\",\n        random_state=\"${pipeline.random_state}\",\n        version_postfix=\"1\",\n    ),\n    function_return=[\"raw_train_dataframe\", \"raw_test_dataframe\", \"splited_dataset_id\"],\n    cache_executed_step=True,\n    execution_queue=\"default\",\n    helper_functions=[class_distribution],\n    packages=[\n        \"plotly&gt;=6.2.0,&lt;7\",\n        \"plotly-express&gt;=0.4.1,&lt;0.5\",\n        \"clearml-serving&gt;=1.3.5,&lt;2\",\n        \"scikit-learn==1.2.2\",\n        \"numpy==1.26.4\",\n        \"pandas&gt;=2.3.0,&lt;3\",\n        \"polars&gt;=1.31.0,&lt;2\",\n        \"nltk&gt;=3.9.1,&lt;4\",\n        \"pyarrow&gt;=20.0.0,&lt;21\",\n    ],\n)\nЕще стоит сказать про особенность function_step, в нем ваш код будет преобразован в отдельный скрипт который будет исполняться, поэтому есть такие проблемы с import разных библиотек и тд. Вот пример кода для этого шага, который переработал ClearML:\nfrom clearml import Task\nfrom clearml import TaskTypes\nfrom clearml.automation.controller import PipelineDecorator\nimport inspect\n\nfrom clearml.utilities.proxy_object import get_basic_type\n\n\n\n\n\ntry:\n    import pandas as pd\nexcept Exception as e:\n    print('Import error: ' + str(e))\n\ntry:\n    import plotly.express as px\nexcept Exception as e:\n    print('Import error: ' + str(e))\n\ntry:\n    import plotly.graph_objects as go\nexcept Exception as e:\n    print('Import error: ' + str(e))\n\ndef class_distribution(data, target_col):\n    polarity_distribution = data.groupby(target_col, as_index=False).agg(count=pd.NamedAgg(target_col, 'count'))\n    return px.histogram(polarity_distribution, x=target_col, y='count')\n\ntry:\n    from clearml import PipelineController\nexcept Exception as e:\n    print('Import error: ' + str(e))\n\ntry:\n    from mlops_example.preprocessing import dataframe_preprocessing\nexcept Exception as e:\n    print('Import error: ' + str(e))\n\ntry:\n    from mlops_example.preprocessing import lemmatize\nexcept Exception as e:\n    print('Import error: ' + str(e))\n\ntry:\n    from mlops_example.preprocessing import text_preprocessing\nexcept Exception as e:\n    print('Import error: ' + str(e))\n\ntry:\n    from mlops_example.visualisation import class_distribution\nexcept Exception as e:\n    print('Import error: ' + str(e))\n\ndef dataset_train_test_split(dataset_name, dataset_project, dataset_version, test_size, random_state, version_postfix):\n    from pathlib import Path\n    import pandas as pd\n    import polars as pl\n    import pyarrow\n    from clearml import Dataset, Logger\n    from sklearn.model_selection import train_test_split\n    print(pyarrow.__version__)\n    dataset = Dataset.get(dataset_name=dataset_name, dataset_project=dataset_project, dataset_version=dataset_version)\n    datset_path = Path(dataset.get_local_copy())\n    data: pd.DataFrame = pl.concat([pl.read_csv(data_file) for data_file in datset_path.iterdir()])\n    train, test = train_test_split(data.to_pandas(), test_size=float(test_size), random_state=int(random_state))\n    train_distrib = class_distribution(train, 'Polarity')\n    test_distrib = class_distribution(test, 'Polarity')\n    result_path = Path('data/prepared/split')\n    result_path.mkdir(exist_ok=True, parents=True)\n    train.to_csv(result_path / 'raw_train.csv', index=False)\n    test.to_csv(result_path / 'raw_test.csv', index=False)\n    prepared_dataset = Dataset.create(dataset_name=dataset_name, dataset_project=dataset_project, dataset_version=f'{dataset_version}.{version_postfix}', parent_datasets=[dataset])\n    prepared_dataset.add_files(result_path)\n    prepared_dataset.upload()\n    prepared_dataset.get_logger().report_plotly('Class distribution', 'Train', train_distrib)\n    prepared_dataset.get_logger().report_plotly('Class distribution', 'Test', test_distrib)\n    prepared_dataset.finalize()\n    pipe_logger = Logger.current_logger()\n    pipe_logger.report_plotly('Class distribution', 'Train', train_distrib)\n    pipe_logger.report_plotly('Class distribution', 'Test', test_distrib)\n    return (pl.from_pandas(train, include_index=False), pl.from_pandas(test, include_index=False), prepared_dataset.id)\n\nif __name__ == '__main__':\n    task = Task.init(\n        auto_connect_frameworks=True,\n        auto_connect_arg_parser=True,\n    )\n    kwargs = {'dataset_name': '${pipeline.dataset_name}', 'dataset_project': '${pipeline.dataset_project}', 'dataset_version': '${pipeline.dataset_version}', 'test_size': '${pipeline.test_size}', 'random_state': '${pipeline.random_state}', 'version_postfix': '1'}\n    task.connect(kwargs, name='kwargs')\n    function_input_artifacts = {}\n    params = task.get_parameters(cast=True) or dict()\n    argspec = inspect.getfullargspec(dataset_train_test_split)\n    if argspec.varkw is not None or argspec.varargs is not None:\n        for k, v in params.items():\n            if k.startswith('kwargs/'):\n                kwargs[k.replace('kwargs/', '', 1)] = v\n    return_section = 'return'\n    for k, v in params.items():\n        if not v or not k.startswith('kwargs_artifacts/'):\n            continue\n        k = k.replace('kwargs_artifacts/', '', 1)\n        task_id, artifact_name = v.split('.', 1)\n        parent_task = Task.get_task(task_id=task_id)\n        if artifact_name in parent_task.artifacts:\n            kwargs[k] = parent_task.artifacts[artifact_name].get(deserialization_function=None)\n        else:\n            kwargs[k] = parent_task.get_parameters(cast=True).get(return_section + '/' + artifact_name)\n    if '0' in kwargs:  # *args arguments are present\n        pos_args = [kwargs.pop(arg, None) for arg in (argspec.args or [])]\n        other_pos_args_index = 0\n        while str(other_pos_args_index) in kwargs:\n            pos_args.append(kwargs.pop(str(other_pos_args_index)))\n            other_pos_args_index += 1\n        results = dataset_train_test_split(*pos_args, **kwargs)\n    else:\n        results = dataset_train_test_split(**kwargs)\n    result_names = ['raw_train_dataframe', 'raw_test_dataframe', 'splited_dataset_id']\n    if result_names:\n        if not isinstance(results, (tuple, list)) or len(result_names) == 1:\n            results = [results]\n        parameters = dict()\n        parameters_types = dict()\n        for name, artifact in zip(result_names, results):\n            if type(artifact) in (float, int, bool, str):\n                parameters[return_section + '/' + name] = artifact\n                parameters_types[return_section + '/' + name] = get_basic_type(artifact)\n            else:\n                task.upload_artifact(\n                    name=name,\n                    artifact_object=artifact,\n                    extension_name='.pkl' if isinstance(artifact, dict) else None,\n                    serialization_function=None\n                )\n        if parameters:\n            task._set_parameters(parameters, __parameters_types=parameters_types, __update=True)\n\nПрописываем все функцию для препроцессинга данных с помощью nltk.\n\ndef dataset_preprocessing(\n    dataframe,\n    parent_dataset,\n    dataset_name,\n    dataset_project,\n    dataset_version,\n    version_postfix,\n    frame_name,\n):\n    from pathlib import Path\n\n    import nltk\n    import polars as pl\n    import pyarrow\n    from clearml import Dataset\n\n    print(pyarrow.__version__)\n\n    nltk.download(\"stopwords\")\n    nltk.download(\"wordnet\")\n\n    prepared_dataset = Dataset.create(\n        dataset_name=dataset_name,\n        dataset_project=dataset_project,\n        dataset_version=f\"{dataset_version}.{version_postfix}\",\n        parent_datasets=[parent_dataset],\n    )\n    dataframe: pl.DataFrame\n    processed_dataframe = dataframe_preprocessing(dataframe, \"Review\")\n\n    result_path = Path(\"data/prepared/processed\")\n    result_path.mkdir(exist_ok=True, parents=True)\n    processed_dataframe.write_parquet(result_path / f\"processed_{frame_name}.parquet\")\n\n    prepared_dataset.add_files(result_path)\n    prepared_dataset.upload()\n    prepared_dataset.finalize()\n    return processed_dataframe, prepared_dataset.id\n\nИ задаем для нее два шага, для обработки обучающей и тестовой выборок. Можно заметить что в параметризации функции у нас также используются и сохраненные артефакты шагаtrain_test_split, а также появился параметр parents, позволяющий строить пайплайн. Кстати, эти шаги будут выполняться паралельно.\n\npipe.add_function_step(\n    name=\"train_processing\",\n    function=dataset_preprocessing,\n    function_kwargs=dict(\n        dataframe=\"${train_test_split.raw_train_dataframe}\",\n        parent_dataset=\"${train_test_split.splited_dataset_id}\",\n        dataset_name=\"${pipeline.dataset_name}\",\n        dataset_project=\"${pipeline.dataset_project}\",\n        dataset_version=\"${pipeline.dataset_version}\",\n        version_postfix=\"2\",\n        frame_name=\"train\",\n    ),\n    function_return=[\"processed_train_dataframe\", \"dataset_id\"],\n    cache_executed_step=True,\n    execution_queue=\"default\",\n    helper_functions=[lemmatize, dataframe_preprocessing, text_preprocessing],\n    parents=[\"train_test_split\"],\n    packages=[\n        \"plotly&gt;=6.2.0,&lt;7\",\n        \"plotly-express&gt;=0.4.1,&lt;0.5\",\n        \"clearml-serving&gt;=1.3.5,&lt;2\",\n        \"scikit-learn==1.2.2\",\n        \"numpy==1.26.4\",\n        \"pandas&gt;=2.3.0,&lt;3\",\n        \"polars&gt;=1.31.0,&lt;2\",\n        \"nltk&gt;=3.9.1,&lt;4\",\n        \"pyarrow&gt;=20.0.0,&lt;21\",\n    ],\n)\n\npipe.add_function_step(\n    name=\"test_processing\",\n    function=dataset_preprocessing,\n    function_kwargs=dict(\n        dataframe=\"${train_test_split.raw_test_dataframe}\",\n        parent_dataset=\"${train_test_split.splited_dataset_id}\",\n        dataset_name=\"${pipeline.dataset_name}\",\n        dataset_project=\"${pipeline.dataset_project}\",\n        dataset_version=\"${pipeline.dataset_version}\",\n        version_postfix=\"3\",\n        frame_name=\"test\",\n    ),\n    function_return=[\"processed_test_dataframe\", \"dataset_id\"],\n    cache_executed_step=True,\n    execution_queue=\"default\",\n    helper_functions=[lemmatize, dataframe_preprocessing, text_preprocessing],\n    parents=[\"train_test_split\"],\n    packages=[\n        \"plotly&gt;=6.2.0,&lt;7\",\n        \"plotly-express&gt;=0.4.1,&lt;0.5\",\n        \"clearml-serving&gt;=1.3.5,&lt;2\",\n        \"scikit-learn==1.2.2\",\n        \"numpy==1.26.4\",\n        \"pandas&gt;=2.3.0,&lt;3\",\n        \"polars&gt;=1.31.0,&lt;2\",\n        \"nltk&gt;=3.9.1,&lt;4\",\n        \"pyarrow&gt;=20.0.0,&lt;21\",\n    ],\n)\n\nТеперь непосредственно команда запуска. Есть два варианта запуска start и start_locally.Первая (start) запускает сборку и исполнение pipeline на стороне агента, то есть агент установит окружение пайплайна и начнемт подготовку кода для каждого из шагов, затем непосредсвенно начнет выполнение шагов. По сути это не блокирующая команда которая направляет задачу агенту и он ее выполняет. Второй вариант start_locally позволяет сконфигурировать пайплайн локлаьно и только шаги исполнить удаленно, но если указать start_locally(run_pipeline_steps_locally=True), то и шаги пайплайна будут исполнены локально, что может быть удобно для дебага.\n\npipe.start()\nВы можете перейти в clearml и увидеть что ваш pipeline выполняется:  Посмотреть его логи можно в поде clearml-id-xxxxxxx:  Или в консоле пайплайна.\n\nКогда пайплайн завершился, можно посотреть всю инфомрацию о нем: настройки, изменения, заисимости, артефакты и тд.     \nТеперь мы легко можем запускать этот пайплайн для других верси датасета, для этого надо клинкнуть по нему пкм и надать run, тогда появится окно задания настрое, напрмиер поставим версию 1.3.   В процессе вы увидите что у вас динамически создаются worker для обработки шагов пайплайна",
    "crumbs": [
      "Практика",
      "ClearML Pipelines"
    ]
  },
  {
    "objectID": "5. clearml_pipeline.html#настойка-clearml-agent",
    "href": "5. clearml_pipeline.html#настойка-clearml-agent",
    "title": "ClearML Pipelines",
    "section": "",
    "text": "Быстрый его запуск разобран в 2. clearml_yandex_kube.md, сейчас мы уделим внимание его более детальной настройки и чуть-уть разберем его helm chart.\nВесь перечень параметров представлен в репозитории clearml-helm-charts\n\nСтоит уделить внимание версии самого ClearML-agent, на момент подготовки курса доступна версия 1.9.3, но она не корректно работает с задачами в очереди (см. issue). Поэту ставим специально понижаем версию до последней рабочей.\n\nagentk8sglue:\n  ...\n  extraEnvs:\n  - name: CLEARML_AGENT_UPDATE_VERSION\n    value: \"==1.9.2\"\n\nТакже стоит изменить образ который будет использоваться для запуска задач на нужный вам (возможно кастомный). Опять же советую использовать python не выше 3.11, что бы не возникало проблем с использованием более старых версий библиотек на следующих этапах.\n\nagentk8sglue:\n  ...\n  defaultContainerImage: python:3.11.13-slim-bookworm\n\nВнеся такие изменения вы в целом можете разворачивать его на kubernetes и использовать для выполнения пайплайнов и экспериментов.",
    "crumbs": [
      "Практика",
      "ClearML Pipelines"
    ]
  },
  {
    "objectID": "5. clearml_pipeline.html#clearml-pipeline",
    "href": "5. clearml_pipeline.html#clearml-pipeline",
    "title": "ClearML Pipelines",
    "section": "",
    "text": "ClearML позволяет составлять пайплайны, формируя их из существующих задач или прописывая специализированный код используя pipeline SDK. Сейчас мы разберем пример pipeline реализованного с помощью PipelineController, для этого надо посмотреть в файл 2.train_test_split.py, давайте его запустим:\npixi run python mlops-example/2.train_test_split.py\nА пока он исполняется, разберем код пайплайна:\n\nСоздается основной объект пайплайна, ему указывается имя, проект, версия, специальные зависимости, докер образ для исполнения и возможность локального импорта модулей. Далее мы будем работать с этим объектом и его донастраивать.\n\npipe = PipelineController(\n    name=\"DataPrepare\",\n    project=\"Amazon reviews\",\n    version=\"0.0.1\",\n    packages=[\"./mlops-example\", \"numpy==1.26.4\"],\n    docker=\"python:3.11.13-slim-bookworm\",\n    enable_local_imports=True,\n)\n\nПайплайну задаются основные параметры, которые в дальнейшем мы сможем задавать в интерфейсе clearml.\n\npipe.add_parameter(\n    name=\"dataset_name\",\n    description=\"ClearML dataset name\",\n    default=\"Amazon reviews dataset\",\n)\npipe.add_parameter(\n    name=\"dataset_project\",\n    description=\"ClearML project\",\n    default=\"Amazon reviews\",\n)\npipe.add_parameter(\n    name=\"dataset_version\",\n    description=\"ClearML dataset version\",\n    default=\"1.2\",\n)\npipe.add_parameter(\n    name=\"test_size\", description=\"Test ratio size\", default=0.2, param_type=\"float\"\n)\npipe.add_parameter(\n    name=\"random_state\", description=\"Random state\", default=42, param_type=\"int\"\n)\n\n\nДалее описываются функции, которые будут исполняться. Обратит внимание Что основные импорты находятся внутри функции, это позволяет clearml автоматически считать зависимости которые необходимы для работы этого кода, но на практике лучше вручную задавать зависимости для каждого шага, что бы установить корректные версии библиотек. Здесь пример функции которая занимается разделение данные на train и test, и складывает их в новую версию датасета: X.X.1.\n\ndef dataset_train_test_split(\n    dataset_name,\n    dataset_project,\n    dataset_version,\n    test_size,\n    random_state,\n    version_postfix,\n):\n    from pathlib import Path\n\n    import pandas as pd\n    import polars as pl\n    import pyarrow\n    from clearml import Dataset, Logger\n    from sklearn.model_selection import train_test_split\n\n    print(pyarrow.__version__)\n\n    dataset = Dataset.get(\n        dataset_name=dataset_name,\n        dataset_project=dataset_project,\n        dataset_version=dataset_version,\n    )\n    datset_path = Path(dataset.get_local_copy())\n\n    data: pd.DataFrame = pl.concat(\n        [pl.read_csv(data_file) for data_file in datset_path.iterdir()]\n    )\n    train, test = train_test_split(\n        data.to_pandas(), test_size=float(test_size), random_state=int(random_state)\n    )\n    train_distrib = class_distribution(train, \"Polarity\")\n    test_distrib = class_distribution(test, \"Polarity\")\n    result_path = Path(\"data/prepared/split\")\n    result_path.mkdir(exist_ok=True, parents=True)\n    train.to_csv(result_path / \"raw_train.csv\", index=False)\n    test.to_csv(result_path / \"raw_test.csv\", index=False)\n    prepared_dataset = Dataset.create(\n        dataset_name=dataset_name,\n        dataset_project=dataset_project,\n        dataset_version=f\"{dataset_version}.{version_postfix}\",\n        parent_datasets=[dataset],\n    )\n    prepared_dataset.add_files(result_path)\n    prepared_dataset.upload()\n    prepared_dataset.get_logger().report_plotly(\n        \"Class distribution\", \"Train\", train_distrib\n    )\n    prepared_dataset.get_logger().report_plotly(\n        \"Class distribution\", \"Test\", test_distrib\n    )\n    prepared_dataset.finalize()\n\n    pipe_logger = Logger.current_logger()\n    pipe_logger.report_plotly(\"Class distribution\", \"Train\", train_distrib)\n    pipe_logger.report_plotly(\"Class distribution\", \"Test\", test_distrib)\n    return (\n        pl.from_pandas(train, include_index=False),\n        pl.from_pandas(test, include_index=False),\n        prepared_dataset.id,\n    )\n\nДобавляем первый функциональный шаг, указываем его имя, функцию которая его исполняет, ее аргументы, используя параметры pipeline, так же указываем какие артефакты сохранить на этом шаге в качестве возвращаемых значений функции, указываем что этот шаг может быть закеширован, указываем очередь для передачи ее ClearML agent, если вы ее не настраивали, то это default, Так же у нас идут helper fucntions, они нужны что бы код шага корректно сгенерировался, и наконец специфичные зависимости для шага.\n\npipe.add_function_step(\n    name=\"train_test_split\",\n    function=dataset_train_test_split,\n    function_kwargs=dict(\n        dataset_name=\"${pipeline.dataset_name}\",\n        dataset_project=\"${pipeline.dataset_project}\",\n        dataset_version=\"${pipeline.dataset_version}\",\n        test_size=\"${pipeline.test_size}\",\n        random_state=\"${pipeline.random_state}\",\n        version_postfix=\"1\",\n    ),\n    function_return=[\"raw_train_dataframe\", \"raw_test_dataframe\", \"splited_dataset_id\"],\n    cache_executed_step=True,\n    execution_queue=\"default\",\n    helper_functions=[class_distribution],\n    packages=[\n        \"plotly&gt;=6.2.0,&lt;7\",\n        \"plotly-express&gt;=0.4.1,&lt;0.5\",\n        \"clearml-serving&gt;=1.3.5,&lt;2\",\n        \"scikit-learn==1.2.2\",\n        \"numpy==1.26.4\",\n        \"pandas&gt;=2.3.0,&lt;3\",\n        \"polars&gt;=1.31.0,&lt;2\",\n        \"nltk&gt;=3.9.1,&lt;4\",\n        \"pyarrow&gt;=20.0.0,&lt;21\",\n    ],\n)\nЕще стоит сказать про особенность function_step, в нем ваш код будет преобразован в отдельный скрипт который будет исполняться, поэтому есть такие проблемы с import разных библиотек и тд. Вот пример кода для этого шага, который переработал ClearML:\nfrom clearml import Task\nfrom clearml import TaskTypes\nfrom clearml.automation.controller import PipelineDecorator\nimport inspect\n\nfrom clearml.utilities.proxy_object import get_basic_type\n\n\n\n\n\ntry:\n    import pandas as pd\nexcept Exception as e:\n    print('Import error: ' + str(e))\n\ntry:\n    import plotly.express as px\nexcept Exception as e:\n    print('Import error: ' + str(e))\n\ntry:\n    import plotly.graph_objects as go\nexcept Exception as e:\n    print('Import error: ' + str(e))\n\ndef class_distribution(data, target_col):\n    polarity_distribution = data.groupby(target_col, as_index=False).agg(count=pd.NamedAgg(target_col, 'count'))\n    return px.histogram(polarity_distribution, x=target_col, y='count')\n\ntry:\n    from clearml import PipelineController\nexcept Exception as e:\n    print('Import error: ' + str(e))\n\ntry:\n    from mlops_example.preprocessing import dataframe_preprocessing\nexcept Exception as e:\n    print('Import error: ' + str(e))\n\ntry:\n    from mlops_example.preprocessing import lemmatize\nexcept Exception as e:\n    print('Import error: ' + str(e))\n\ntry:\n    from mlops_example.preprocessing import text_preprocessing\nexcept Exception as e:\n    print('Import error: ' + str(e))\n\ntry:\n    from mlops_example.visualisation import class_distribution\nexcept Exception as e:\n    print('Import error: ' + str(e))\n\ndef dataset_train_test_split(dataset_name, dataset_project, dataset_version, test_size, random_state, version_postfix):\n    from pathlib import Path\n    import pandas as pd\n    import polars as pl\n    import pyarrow\n    from clearml import Dataset, Logger\n    from sklearn.model_selection import train_test_split\n    print(pyarrow.__version__)\n    dataset = Dataset.get(dataset_name=dataset_name, dataset_project=dataset_project, dataset_version=dataset_version)\n    datset_path = Path(dataset.get_local_copy())\n    data: pd.DataFrame = pl.concat([pl.read_csv(data_file) for data_file in datset_path.iterdir()])\n    train, test = train_test_split(data.to_pandas(), test_size=float(test_size), random_state=int(random_state))\n    train_distrib = class_distribution(train, 'Polarity')\n    test_distrib = class_distribution(test, 'Polarity')\n    result_path = Path('data/prepared/split')\n    result_path.mkdir(exist_ok=True, parents=True)\n    train.to_csv(result_path / 'raw_train.csv', index=False)\n    test.to_csv(result_path / 'raw_test.csv', index=False)\n    prepared_dataset = Dataset.create(dataset_name=dataset_name, dataset_project=dataset_project, dataset_version=f'{dataset_version}.{version_postfix}', parent_datasets=[dataset])\n    prepared_dataset.add_files(result_path)\n    prepared_dataset.upload()\n    prepared_dataset.get_logger().report_plotly('Class distribution', 'Train', train_distrib)\n    prepared_dataset.get_logger().report_plotly('Class distribution', 'Test', test_distrib)\n    prepared_dataset.finalize()\n    pipe_logger = Logger.current_logger()\n    pipe_logger.report_plotly('Class distribution', 'Train', train_distrib)\n    pipe_logger.report_plotly('Class distribution', 'Test', test_distrib)\n    return (pl.from_pandas(train, include_index=False), pl.from_pandas(test, include_index=False), prepared_dataset.id)\n\nif __name__ == '__main__':\n    task = Task.init(\n        auto_connect_frameworks=True,\n        auto_connect_arg_parser=True,\n    )\n    kwargs = {'dataset_name': '${pipeline.dataset_name}', 'dataset_project': '${pipeline.dataset_project}', 'dataset_version': '${pipeline.dataset_version}', 'test_size': '${pipeline.test_size}', 'random_state': '${pipeline.random_state}', 'version_postfix': '1'}\n    task.connect(kwargs, name='kwargs')\n    function_input_artifacts = {}\n    params = task.get_parameters(cast=True) or dict()\n    argspec = inspect.getfullargspec(dataset_train_test_split)\n    if argspec.varkw is not None or argspec.varargs is not None:\n        for k, v in params.items():\n            if k.startswith('kwargs/'):\n                kwargs[k.replace('kwargs/', '', 1)] = v\n    return_section = 'return'\n    for k, v in params.items():\n        if not v or not k.startswith('kwargs_artifacts/'):\n            continue\n        k = k.replace('kwargs_artifacts/', '', 1)\n        task_id, artifact_name = v.split('.', 1)\n        parent_task = Task.get_task(task_id=task_id)\n        if artifact_name in parent_task.artifacts:\n            kwargs[k] = parent_task.artifacts[artifact_name].get(deserialization_function=None)\n        else:\n            kwargs[k] = parent_task.get_parameters(cast=True).get(return_section + '/' + artifact_name)\n    if '0' in kwargs:  # *args arguments are present\n        pos_args = [kwargs.pop(arg, None) for arg in (argspec.args or [])]\n        other_pos_args_index = 0\n        while str(other_pos_args_index) in kwargs:\n            pos_args.append(kwargs.pop(str(other_pos_args_index)))\n            other_pos_args_index += 1\n        results = dataset_train_test_split(*pos_args, **kwargs)\n    else:\n        results = dataset_train_test_split(**kwargs)\n    result_names = ['raw_train_dataframe', 'raw_test_dataframe', 'splited_dataset_id']\n    if result_names:\n        if not isinstance(results, (tuple, list)) or len(result_names) == 1:\n            results = [results]\n        parameters = dict()\n        parameters_types = dict()\n        for name, artifact in zip(result_names, results):\n            if type(artifact) in (float, int, bool, str):\n                parameters[return_section + '/' + name] = artifact\n                parameters_types[return_section + '/' + name] = get_basic_type(artifact)\n            else:\n                task.upload_artifact(\n                    name=name,\n                    artifact_object=artifact,\n                    extension_name='.pkl' if isinstance(artifact, dict) else None,\n                    serialization_function=None\n                )\n        if parameters:\n            task._set_parameters(parameters, __parameters_types=parameters_types, __update=True)\n\nПрописываем все функцию для препроцессинга данных с помощью nltk.\n\ndef dataset_preprocessing(\n    dataframe,\n    parent_dataset,\n    dataset_name,\n    dataset_project,\n    dataset_version,\n    version_postfix,\n    frame_name,\n):\n    from pathlib import Path\n\n    import nltk\n    import polars as pl\n    import pyarrow\n    from clearml import Dataset\n\n    print(pyarrow.__version__)\n\n    nltk.download(\"stopwords\")\n    nltk.download(\"wordnet\")\n\n    prepared_dataset = Dataset.create(\n        dataset_name=dataset_name,\n        dataset_project=dataset_project,\n        dataset_version=f\"{dataset_version}.{version_postfix}\",\n        parent_datasets=[parent_dataset],\n    )\n    dataframe: pl.DataFrame\n    processed_dataframe = dataframe_preprocessing(dataframe, \"Review\")\n\n    result_path = Path(\"data/prepared/processed\")\n    result_path.mkdir(exist_ok=True, parents=True)\n    processed_dataframe.write_parquet(result_path / f\"processed_{frame_name}.parquet\")\n\n    prepared_dataset.add_files(result_path)\n    prepared_dataset.upload()\n    prepared_dataset.finalize()\n    return processed_dataframe, prepared_dataset.id\n\nИ задаем для нее два шага, для обработки обучающей и тестовой выборок. Можно заметить что в параметризации функции у нас также используются и сохраненные артефакты шагаtrain_test_split, а также появился параметр parents, позволяющий строить пайплайн. Кстати, эти шаги будут выполняться паралельно.\n\npipe.add_function_step(\n    name=\"train_processing\",\n    function=dataset_preprocessing,\n    function_kwargs=dict(\n        dataframe=\"${train_test_split.raw_train_dataframe}\",\n        parent_dataset=\"${train_test_split.splited_dataset_id}\",\n        dataset_name=\"${pipeline.dataset_name}\",\n        dataset_project=\"${pipeline.dataset_project}\",\n        dataset_version=\"${pipeline.dataset_version}\",\n        version_postfix=\"2\",\n        frame_name=\"train\",\n    ),\n    function_return=[\"processed_train_dataframe\", \"dataset_id\"],\n    cache_executed_step=True,\n    execution_queue=\"default\",\n    helper_functions=[lemmatize, dataframe_preprocessing, text_preprocessing],\n    parents=[\"train_test_split\"],\n    packages=[\n        \"plotly&gt;=6.2.0,&lt;7\",\n        \"plotly-express&gt;=0.4.1,&lt;0.5\",\n        \"clearml-serving&gt;=1.3.5,&lt;2\",\n        \"scikit-learn==1.2.2\",\n        \"numpy==1.26.4\",\n        \"pandas&gt;=2.3.0,&lt;3\",\n        \"polars&gt;=1.31.0,&lt;2\",\n        \"nltk&gt;=3.9.1,&lt;4\",\n        \"pyarrow&gt;=20.0.0,&lt;21\",\n    ],\n)\n\npipe.add_function_step(\n    name=\"test_processing\",\n    function=dataset_preprocessing,\n    function_kwargs=dict(\n        dataframe=\"${train_test_split.raw_test_dataframe}\",\n        parent_dataset=\"${train_test_split.splited_dataset_id}\",\n        dataset_name=\"${pipeline.dataset_name}\",\n        dataset_project=\"${pipeline.dataset_project}\",\n        dataset_version=\"${pipeline.dataset_version}\",\n        version_postfix=\"3\",\n        frame_name=\"test\",\n    ),\n    function_return=[\"processed_test_dataframe\", \"dataset_id\"],\n    cache_executed_step=True,\n    execution_queue=\"default\",\n    helper_functions=[lemmatize, dataframe_preprocessing, text_preprocessing],\n    parents=[\"train_test_split\"],\n    packages=[\n        \"plotly&gt;=6.2.0,&lt;7\",\n        \"plotly-express&gt;=0.4.1,&lt;0.5\",\n        \"clearml-serving&gt;=1.3.5,&lt;2\",\n        \"scikit-learn==1.2.2\",\n        \"numpy==1.26.4\",\n        \"pandas&gt;=2.3.0,&lt;3\",\n        \"polars&gt;=1.31.0,&lt;2\",\n        \"nltk&gt;=3.9.1,&lt;4\",\n        \"pyarrow&gt;=20.0.0,&lt;21\",\n    ],\n)\n\nТеперь непосредственно команда запуска. Есть два варианта запуска start и start_locally.Первая (start) запускает сборку и исполнение pipeline на стороне агента, то есть агент установит окружение пайплайна и начнемт подготовку кода для каждого из шагов, затем непосредсвенно начнет выполнение шагов. По сути это не блокирующая команда которая направляет задачу агенту и он ее выполняет. Второй вариант start_locally позволяет сконфигурировать пайплайн локлаьно и только шаги исполнить удаленно, но если указать start_locally(run_pipeline_steps_locally=True), то и шаги пайплайна будут исполнены локально, что может быть удобно для дебага.\n\npipe.start()\nВы можете перейти в clearml и увидеть что ваш pipeline выполняется:  Посмотреть его логи можно в поде clearml-id-xxxxxxx:  Или в консоле пайплайна.\n\nКогда пайплайн завершился, можно посотреть всю инфомрацию о нем: настройки, изменения, заисимости, артефакты и тд.     \nТеперь мы легко можем запускать этот пайплайн для других верси датасета, для этого надо клинкнуть по нему пкм и надать run, тогда появится окно задания настрое, напрмиер поставим версию 1.3.   В процессе вы увидите что у вас динамически создаются worker для обработки шагов пайплайна",
    "crumbs": [
      "Практика",
      "ClearML Pipelines"
    ]
  },
  {
    "objectID": "3. clearml_work.html",
    "href": "3. clearml_work.html",
    "title": "Работа с ClearML",
    "section": "",
    "text": "Для начала зайдите на свой ClearML, в примере он развернут на http://51.250.106.18:30080/. Его адрес можно найти в информации об узле на котором развернут pod: \nЗайдите в Settings -&gt; Workspace и там нажмите Create new credentials: \nВам покажется модельное окно с сгенерированными credentials, выполните инструкцию написанную в нем: скопируйте текст credentials в ~/clearml.conf:\napi {\n    web_server:http://51.250.106.18:30080/\n    api_server:http://51.250.106.18:30008\n    files_server:http://51.250.106.18:30081\n    credentials {\n        \"access_key\"=\"ACCESSKEY\"\n        \"secret_key\"=\"SECRETKEY\"\n    }\n}\nОсталось установить библиотеку clearml для полноценной работы.\n\n\n\nДля примера использовался пакетный менеджер pixi, что бы его установить выполните команду:\necho PIXI_VERSION=0.48.2 && curl -fsSL https://pixi.sh/install.sh | sh\nПоскольку инструмент еще на стадии активной разработки то меду версиями могут быть различия и breaking changes, поэтому обратите внимание на версию 0.48.2.\nПосле успешной установки перейдите в папку mlops-example и выполните команду:\npixi install -a\nСразу обращу внимание, что не стоит гнаться за последними версиями библиотек. Ограничитесь python==3.11, scikit-learn==1.2.2, numpy==1.26.4. Это важно потому что на шагах связанных с разверткой моделей у вас могут появиться не состыковки по версиям поддерживаемых зависимостей и придется или менять версии библиотек в ваших экспериментах (как это было при подготовке примера), или собирать свои кастомные образы для serving’а моделей с обновленными зависимостями.\nДля дальнейшей работы в окружении вы можете выполнить команду pixi shell или каждую команду начинать с pixi run ...",
    "crumbs": [
      "Практика",
      "Работа с ClearML"
    ]
  },
  {
    "objectID": "3. clearml_work.html#настройка-clearml",
    "href": "3. clearml_work.html#настройка-clearml",
    "title": "Работа с ClearML",
    "section": "",
    "text": "Для начала зайдите на свой ClearML, в примере он развернут на http://51.250.106.18:30080/. Его адрес можно найти в информации об узле на котором развернут pod: \nЗайдите в Settings -&gt; Workspace и там нажмите Create new credentials: \nВам покажется модельное окно с сгенерированными credentials, выполните инструкцию написанную в нем: скопируйте текст credentials в ~/clearml.conf:\napi {\n    web_server:http://51.250.106.18:30080/\n    api_server:http://51.250.106.18:30008\n    files_server:http://51.250.106.18:30081\n    credentials {\n        \"access_key\"=\"ACCESSKEY\"\n        \"secret_key\"=\"SECRETKEY\"\n    }\n}\nОсталось установить библиотеку clearml для полноценной работы.",
    "crumbs": [
      "Практика",
      "Работа с ClearML"
    ]
  },
  {
    "objectID": "3. clearml_work.html#настройка-окружения-mlops-example",
    "href": "3. clearml_work.html#настройка-окружения-mlops-example",
    "title": "Работа с ClearML",
    "section": "",
    "text": "Для примера использовался пакетный менеджер pixi, что бы его установить выполните команду:\necho PIXI_VERSION=0.48.2 && curl -fsSL https://pixi.sh/install.sh | sh\nПоскольку инструмент еще на стадии активной разработки то меду версиями могут быть различия и breaking changes, поэтому обратите внимание на версию 0.48.2.\nПосле успешной установки перейдите в папку mlops-example и выполните команду:\npixi install -a\nСразу обращу внимание, что не стоит гнаться за последними версиями библиотек. Ограничитесь python==3.11, scikit-learn==1.2.2, numpy==1.26.4. Это важно потому что на шагах связанных с разверткой моделей у вас могут появиться не состыковки по версиям поддерживаемых зависимостей и придется или менять версии библиотек в ваших экспериментах (как это было при подготовке примера), или собирать свои кастомные образы для serving’а моделей с обновленными зависимостями.\nДля дальнейшей работы в окружении вы можете выполнить команду pixi shell или каждую команду начинать с pixi run ...",
    "crumbs": [
      "Практика",
      "Работа с ClearML"
    ]
  },
  {
    "objectID": "1. yandex_kube.html",
    "href": "1. yandex_kube.html",
    "title": "Настройка Yandex Kubernetes",
    "section": "",
    "text": "Общая инструкция по настройке Yandex Kubernetes\n\n\nСоздайте кластер вот с такой конфигурацией: \nСоздайте В нем группу узлов вот с такой конфигурацией: \n\n\n\nИнструкция по установке от yandex\nСкачайте скрипт установки и запустите:\ncurl -sSL https://storage.yandexcloud.net/yandexcloud-yc/install.sh | bash\nПолучите ваш OauthToken и задайте его yc.\nyc config set token &lt;OAuth-токен&gt;\n\n\n\nИнструкция по установке от Kubernetes\nСкачайте к себе собранный бинарник kubectl\ncurl -LO https://dl.k8s.io/release/v1.33.0/bin/linux/amd64/kubectl\nИзмените права для исполнения kubectl\nchmod +x ./kubectl\nПереместите его в системную папку bin\nsudo mv ./kubectl /usr/local/bin/kubectl\n\n\n\nНастройте доступ к kubectl к кластеру\nyc managed-kubernetes cluster get-credentials --id &lt;Cluster ID&gt; --external\n\nПроверьте что все работает\nkubectl config view\nили\nkubectl get nodes\n\n\n\nСкачайте скрипт установки (см инструкцию helm)\ncurl -fsSL -o get_helm.sh https://raw.githubusercontent.com/helm/helm/main/scripts/get-helm-3\nИзмените права для запуска\nchmod 700 get_helm.sh\nЗапустите установку\n./get_helm.sh\n\n\n\nЧто бы подключить helm к yc выполните команду, воспользуйтесь своим OauthToken\nhelm registry login registry.yandexcloud.net -u oauth\nPassword: &lt;OAuth-токен&gt;",
    "crumbs": [
      "Практика",
      "Настройка Yandex Kubernetes"
    ]
  },
  {
    "objectID": "1. yandex_kube.html#создание-кластера-kubernetes",
    "href": "1. yandex_kube.html#создание-кластера-kubernetes",
    "title": "Настройка Yandex Kubernetes",
    "section": "",
    "text": "Создайте кластер вот с такой конфигурацией: \nСоздайте В нем группу узлов вот с такой конфигурацией:",
    "crumbs": [
      "Практика",
      "Настройка Yandex Kubernetes"
    ]
  },
  {
    "objectID": "1. yandex_kube.html#установка-yc",
    "href": "1. yandex_kube.html#установка-yc",
    "title": "Настройка Yandex Kubernetes",
    "section": "",
    "text": "Инструкция по установке от yandex\nСкачайте скрипт установки и запустите:\ncurl -sSL https://storage.yandexcloud.net/yandexcloud-yc/install.sh | bash\nПолучите ваш OauthToken и задайте его yc.\nyc config set token &lt;OAuth-токен&gt;",
    "crumbs": [
      "Практика",
      "Настройка Yandex Kubernetes"
    ]
  },
  {
    "objectID": "1. yandex_kube.html#установка-kubectl",
    "href": "1. yandex_kube.html#установка-kubectl",
    "title": "Настройка Yandex Kubernetes",
    "section": "",
    "text": "Инструкция по установке от Kubernetes\nСкачайте к себе собранный бинарник kubectl\ncurl -LO https://dl.k8s.io/release/v1.33.0/bin/linux/amd64/kubectl\nИзмените права для исполнения kubectl\nchmod +x ./kubectl\nПереместите его в системную папку bin\nsudo mv ./kubectl /usr/local/bin/kubectl",
    "crumbs": [
      "Практика",
      "Настройка Yandex Kubernetes"
    ]
  },
  {
    "objectID": "1. yandex_kube.html#настройка-доступов-kubectl",
    "href": "1. yandex_kube.html#настройка-доступов-kubectl",
    "title": "Настройка Yandex Kubernetes",
    "section": "",
    "text": "Настройте доступ к kubectl к кластеру\nyc managed-kubernetes cluster get-credentials --id &lt;Cluster ID&gt; --external\n\nПроверьте что все работает\nkubectl config view\nили\nkubectl get nodes",
    "crumbs": [
      "Практика",
      "Настройка Yandex Kubernetes"
    ]
  },
  {
    "objectID": "1. yandex_kube.html#установка-helm",
    "href": "1. yandex_kube.html#установка-helm",
    "title": "Настройка Yandex Kubernetes",
    "section": "",
    "text": "Скачайте скрипт установки (см инструкцию helm)\ncurl -fsSL -o get_helm.sh https://raw.githubusercontent.com/helm/helm/main/scripts/get-helm-3\nИзмените права для запуска\nchmod 700 get_helm.sh\nЗапустите установку\n./get_helm.sh",
    "crumbs": [
      "Практика",
      "Настройка Yandex Kubernetes"
    ]
  },
  {
    "objectID": "1. yandex_kube.html#настройка-доступов-helm",
    "href": "1. yandex_kube.html#настройка-доступов-helm",
    "title": "Настройка Yandex Kubernetes",
    "section": "",
    "text": "Что бы подключить helm к yc выполните команду, воспользуйтесь своим OauthToken\nhelm registry login registry.yandexcloud.net -u oauth\nPassword: &lt;OAuth-токен&gt;",
    "crumbs": [
      "Практика",
      "Настройка Yandex Kubernetes"
    ]
  },
  {
    "objectID": "slides/2.tools.html#tools-types",
    "href": "slides/2.tools.html#tools-types",
    "title": "MLOps Tools",
    "section": "Tools types",
    "text": "Tools types\n\n\n\nData Management\nData Validation\nWorkflow Managment\nModel Lifecycle\n\n\n\nKnowledge Sharing\nModel Serving\nMonitoring & Dashboards\nMLOps Platforms\n\n\nИ это еще не всё…1\nСмотрите в awesome-mlops и mlops-references",
    "crumbs": [
      "Лекции",
      "MLOps Tools"
    ]
  },
  {
    "objectID": "slides/2.tools.html#data-management",
    "href": "slides/2.tools.html#data-management",
    "title": "MLOps Tools",
    "section": "Data Management",
    "text": "Data Management\n\nGit LFS – расширение git для больших файлов\nDVC – система версионирования данных и моделей в ml проектах\nHugging Face – платформа для публикации открытых моделей и датасетов\nLakeFS – git like система версионирования данных в объектных хранилищах",
    "crumbs": [
      "Лекции",
      "MLOps Tools"
    ]
  },
  {
    "objectID": "slides/2.tools.html#data-validation",
    "href": "slides/2.tools.html#data-validation",
    "title": "MLOps Tools",
    "section": "Data Validation",
    "text": "Data Validation\n\nGreat Expectations – фреймворк для валидации данных\nPandera – задание модели данных pandas и polars\nData contract – валидация как хранилищ данных, так и отдельных файлов",
    "crumbs": [
      "Лекции",
      "MLOps Tools"
    ]
  },
  {
    "objectID": "slides/2.tools.html#workflow-managment",
    "href": "slides/2.tools.html#workflow-managment",
    "title": "MLOps Tools",
    "section": "Workflow Managment",
    "text": "Workflow Managment\n\nGNU Make – олдовый workflow manager на основе файлов\nSnakeMake – аналог для управления workflow в DS проектах\nLuigi – python оркестратор workflow\nMetaflow – оркестратор для ML workflow\nMage AI – фреймворк для управления ml workflow\nAirFlow –мощный и популярный оркестратор workflow",
    "crumbs": [
      "Лекции",
      "MLOps Tools"
    ]
  },
  {
    "objectID": "slides/2.tools.html#model-lifecycle",
    "href": "slides/2.tools.html#model-lifecycle",
    "title": "MLOps Tools",
    "section": "Model Lifecycle",
    "text": "Model Lifecycle\n\nMLflow – платформа для трекинга артефактов экспериментов\nNeptune AI – колобаративный инструмент трекинга артефактов и датасетов\nWeights and Biases – инструмент визуализации и отслеживания обучения ваших моделей\nTensorBoard – инструмент визуализации обучения ваших нейронных сетей",
    "crumbs": [
      "Лекции",
      "MLOps Tools"
    ]
  },
  {
    "objectID": "slides/2.tools.html#knowledge-sharing",
    "href": "slides/2.tools.html#knowledge-sharing",
    "title": "MLOps Tools",
    "section": "Knowledge Sharing",
    "text": "Knowledge Sharing\n\nKnowledge Repo – платформа обмена знаниями для исследователей\nKyso – инструмент публикации и ревью отчетов",
    "crumbs": [
      "Лекции",
      "MLOps Tools"
    ]
  },
  {
    "objectID": "slides/2.tools.html#model-serving",
    "href": "slides/2.tools.html#model-serving",
    "title": "MLOps Tools",
    "section": "Model Serving",
    "text": "Model Serving\n\nTriton Inference Server – python сервис для деплоя различных моделей и оптимизацией их исполнения\nTensorFlow Serving – гибкий, мощный инструмент деплоя tensorflow в продакшен\nTorchServe – аналог для моделей pytorch\nOpyrator – простой способ получить API/интерфейс модели\nGradio – инструмент построения простых ML web-приложений",
    "crumbs": [
      "Лекции",
      "MLOps Tools"
    ]
  },
  {
    "objectID": "slides/2.tools.html#monitoring-dashboards",
    "href": "slides/2.tools.html#monitoring-dashboards",
    "title": "MLOps Tools",
    "section": "Monitoring & Dashboards",
    "text": "Monitoring & Dashboards\n\nStreamlit – простой инструмент построения dashboards чего либо на питоне\nDash – аналог от команды plotly\nGrafana – простой сервис для построения dashboards\nPrometheus – инструмент сбора метрик и ошибок\nGrayLog – сборщик и анализатор логов",
    "crumbs": [
      "Лекции",
      "MLOps Tools"
    ]
  },
  {
    "objectID": "slides/2.tools.html#mlops-platforms",
    "href": "slides/2.tools.html#mlops-platforms",
    "title": "MLOps Tools",
    "section": "MLOps Platforms",
    "text": "MLOps Platforms\n\nClearML – платформа все в одном\nKubeflow – платформа для ML на основе kubernetes\nИ много много других",
    "crumbs": [
      "Лекции",
      "MLOps Tools"
    ]
  },
  {
    "objectID": "README.html",
    "href": "README.html",
    "title": "MLOps/DataOps YA.CAMP 2025",
    "section": "",
    "text": "В репозитории представлены материалы для занятий MLOps/DataOps YA.CAMP 2025.\n\n\nИсточники для подготовленных материалов:\n\nДокументация ClearML\nКурс MLOps и production в DS исследованиях 3.0\nКурс Инженерные практики в ML\n\n\n\n\n\nВведение в MLOps, что это и зачем нужно?\nИнструменты MLOps (краткий перечень)\nClearML как единая платформа для ML исследований\n\n\n\n\n\nclearml-helm-charts – подготовленные helm charts для запуска на YC clearml и выполнения примера. В них заранее заменены образы которые попали под блокировку, поэтому развертка должна пройти без проблем.\nmlops-example – подготовленный демо пример того, как и что можно делать c clearml, показаны основные возможности и способы работы.\nИнстуркции к работе с примером также приложены в репозиторий, надеюсь они помогут разобраться с ним:\n\n1. yandex_kube.md – настрйока kuber в yc, куда нужно посмотреть и как настроить локальные инструменты.\n2. clearml_yandex_kube.md – как развернуть на yc kuber нужные для практики сервисы clearml.\n3. clearml_work.md – как настроить окружение демо примера у себя и настроить работу с clearml\n4. clearml_data.md – информация по работе с clearml data, как с ней взаимодействовать и как подготовить данные для демо примера и загрузить в clearml.\n5. clearml_pipeline.md – базовое создание пайплайнов и способы их запуска: локально и удаленно, пример пайплайна по подготовке данных\n6. clearml_research.md – как проводить исследваония в clearml, что для этого нужно, как логировать метрики, артефакты и модели, а так же сравнвивать экперименты между собой.\n7. clearml_reports.md – Немного про отчеты, как их легко делать и хранить в clearml\n8. clearml_serving.md – как развернуть модели с помощью clearml, описание демо примера.\n9. clearml_extend_pipes.md – чуть больше возможностей пайплайнов, как составить пайплайн из готовых задач.\n\n\n\nСначала ознакомьтесь со всеми материалами, а уже потом пробуйте запустить\n\n\n\n\nНа практике необходимо выполнить задание, его подробности вам опишет практик, но основная часть такая:\nПервая практика\n\nРазвернуть инфру на YC1\nЗагрузить несколько версий датасета в clearml\nРеализовать пайплайн обработки версий датасета для подготовки данных для обучения моделей.\n\nВторая практика\n\nРеализовать обучение модели на подготовленном датасет\nНастроить логирования метрик, семплов и моделей в clearml\nЗапустить удаленные эксперименты на агенте clearml\nСформировать отчёт с сравнением моделей в clearml reports\n\nТретья практика\n\nНастроить model servering в YC 2\nЗадеплоить туда одну из моделей\nРеализовать простой интерфейс для взаимодействия с API модели на streamlit/dash"
  },
  {
    "objectID": "README.html#источники",
    "href": "README.html#источники",
    "title": "MLOps/DataOps YA.CAMP 2025",
    "section": "",
    "text": "Источники для подготовленных материалов:\n\nДокументация ClearML\nКурс MLOps и production в DS исследованиях 3.0\nКурс Инженерные практики в ML"
  },
  {
    "objectID": "README.html#теория",
    "href": "README.html#теория",
    "title": "MLOps/DataOps YA.CAMP 2025",
    "section": "",
    "text": "Введение в MLOps, что это и зачем нужно?\nИнструменты MLOps (краткий перечень)\nClearML как единая платформа для ML исследований"
  },
  {
    "objectID": "README.html#практика",
    "href": "README.html#практика",
    "title": "MLOps/DataOps YA.CAMP 2025",
    "section": "",
    "text": "clearml-helm-charts – подготовленные helm charts для запуска на YC clearml и выполнения примера. В них заранее заменены образы которые попали под блокировку, поэтому развертка должна пройти без проблем.\nmlops-example – подготовленный демо пример того, как и что можно делать c clearml, показаны основные возможности и способы работы.\nИнстуркции к работе с примером также приложены в репозиторий, надеюсь они помогут разобраться с ним:\n\n1. yandex_kube.md – настрйока kuber в yc, куда нужно посмотреть и как настроить локальные инструменты.\n2. clearml_yandex_kube.md – как развернуть на yc kuber нужные для практики сервисы clearml.\n3. clearml_work.md – как настроить окружение демо примера у себя и настроить работу с clearml\n4. clearml_data.md – информация по работе с clearml data, как с ней взаимодействовать и как подготовить данные для демо примера и загрузить в clearml.\n5. clearml_pipeline.md – базовое создание пайплайнов и способы их запуска: локально и удаленно, пример пайплайна по подготовке данных\n6. clearml_research.md – как проводить исследваония в clearml, что для этого нужно, как логировать метрики, артефакты и модели, а так же сравнвивать экперименты между собой.\n7. clearml_reports.md – Немного про отчеты, как их легко делать и хранить в clearml\n8. clearml_serving.md – как развернуть модели с помощью clearml, описание демо примера.\n9. clearml_extend_pipes.md – чуть больше возможностей пайплайнов, как составить пайплайн из готовых задач.\n\n\n\nСначала ознакомьтесь со всеми материалами, а уже потом пробуйте запустить"
  },
  {
    "objectID": "README.html#задание",
    "href": "README.html#задание",
    "title": "MLOps/DataOps YA.CAMP 2025",
    "section": "",
    "text": "На практике необходимо выполнить задание, его подробности вам опишет практик, но основная часть такая:\nПервая практика\n\nРазвернуть инфру на YC1\nЗагрузить несколько версий датасета в clearml\nРеализовать пайплайн обработки версий датасета для подготовки данных для обучения моделей.\n\nВторая практика\n\nРеализовать обучение модели на подготовленном датасет\nНастроить логирования метрик, семплов и моделей в clearml\nЗапустить удаленные эксперименты на агенте clearml\nСформировать отчёт с сравнением моделей в clearml reports\n\nТретья практика\n\nНастроить model servering в YC 2\nЗадеплоить туда одну из моделей\nРеализовать простой интерфейс для взаимодействия с API модели на streamlit/dash"
  },
  {
    "objectID": "README.html#footnotes",
    "href": "README.html#footnotes",
    "title": "MLOps/DataOps YA.CAMP 2025",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nЕсли не получается то локлаьно через docker-compose↩︎\nЕсли неполчается, то реализовать приложение fastpai, которое при запуске забирает определенную версию модели из clearml↩︎"
  },
  {
    "objectID": "slides/1.intro.html#чуть-чуть-интерактива",
    "href": "slides/1.intro.html#чуть-чуть-интерактива",
    "title": "Intro",
    "section": "Чуть-чуть интерактива",
    "text": "Чуть-чуть интерактива\nvk.cc/cNpPry",
    "crumbs": [
      "Лекции",
      "Intro"
    ]
  },
  {
    "objectID": "slides/1.intro.html#план-занятий",
    "href": "slides/1.intro.html#план-занятий",
    "title": "Intro",
    "section": "План занятий",
    "text": "План занятий\n\nОпределимся: Что такое MLOps?\nПоговорим о проблемах ML\nПосмотрим подходы к их решению\nПосвятим много времени ClearML",
    "crumbs": [
      "Лекции",
      "Intro"
    ]
  },
  {
    "objectID": "slides/1.intro.html#что-такое-mlops",
    "href": "slides/1.intro.html#что-такое-mlops",
    "title": "Intro",
    "section": "Что такое MLOps?",
    "text": "Что такое MLOps?",
    "crumbs": [
      "Лекции",
      "Intro"
    ]
  },
  {
    "objectID": "slides/1.intro.html#данные",
    "href": "slides/1.intro.html#данные",
    "title": "Intro",
    "section": "Данные",
    "text": "Данные\n\n\n\nЛежат локально\nМеняются произвольно\nНет настроенных потоков данных\nНет версий датасетов",
    "crumbs": [
      "Лекции",
      "Intro"
    ]
  },
  {
    "objectID": "slides/1.intro.html#исследования",
    "href": "slides/1.intro.html#исследования",
    "title": "Intro",
    "section": "Исследования",
    "text": "Исследования\n\n\n\nНет культуры исследований\nРезультаты теряются\nЧасто не воспроизводимы\nСложно разобраться “а что сделано-то?”",
    "crumbs": [
      "Лекции",
      "Intro"
    ]
  },
  {
    "objectID": "slides/1.intro.html#модели",
    "href": "slides/1.intro.html#модели",
    "title": "Intro",
    "section": "Модели",
    "text": "Модели\n\n\n\n“А где модель то?”\n“Как ее запустить?”\n“А она еще работает?”\n“Что-то не так, дай новую модельку”",
    "crumbs": [
      "Лекции",
      "Intro"
    ]
  },
  {
    "objectID": "slides/1.intro.html#командное-взаимодействие",
    "href": "slides/1.intro.html#командное-взаимодействие",
    "title": "Intro",
    "section": "Командное взаимодействие",
    "text": "Командное взаимодействие\n\n\n\nКаждый кодит как он хочет\nИсследования независимы\nНет обмена знаниями\n“А что мы вообще делаем?”",
    "crumbs": [
      "Лекции",
      "Intro"
    ]
  },
  {
    "objectID": "slides/1.intro.html#как-же-все-это-решать",
    "href": "slides/1.intro.html#как-же-все-это-решать",
    "title": "Intro",
    "section": "Как же все это решать?",
    "text": "Как же все это решать?\nматрица зрелости инженерных практик\n\nПостепенно менять процессы работы\nВнедрять инструменты автоматизации\nПовышать культуру и компетенции команды\nДелать сразу как надо",
    "crumbs": [
      "Лекции",
      "Intro"
    ]
  },
  {
    "objectID": "slides/3.clearml.html#section",
    "href": "slides/3.clearml.html#section",
    "title": "ClearML",
    "section": "",
    "text": "Для начала давайте рассмотрим, что нам предлагает clearml, как фреймворк для проведения исследований. ClearML предоставляет как унифицированную платформу с открытым исходным кодом для непрерывного использования искусственного интеллекта, так и набор модулей для совместного взаимодействия. То есть авторы инструмента имеют в виду, что можно как ограничиться использование только clearml и проводить исследования в рамках платформы, так и использовать определенные модули clearml в своих процессах проведения исследований.\nClearml действительно имеет обширные возможности:\n\nвозможности dataops (версионирование и управление данными)\nтрекинг экспериментов\nплатформа для обучение моделей\nгенерация отчетов и реестр для их хранения\nmodel store, для упрощения поставок моделей и переиспользования предыдущих наработок\nзапуск CI-CD\nmodel servering - автоматическое развертывание моделей\n\nИ все это с уже настроенной оркестрацией, планировщиками и распределенными вычислениями. Звучит очень круто, как инструмент позволяющий покрыть практически весь процесс создания и поставки моделей.",
    "crumbs": [
      "Лекции",
      "ClearML"
    ]
  },
  {
    "objectID": "slides/3.clearml.html#варианты-использования",
    "href": "slides/3.clearml.html#варианты-использования",
    "title": "ClearML",
    "section": "Варианты использования",
    "text": "Варианты использования\n\nClearML SaaS\nЧастное облако (VPC)\nЛокальная развертка\nУправляемое VPC\n\n\nClearML предлагает 4 варианта использования:\n\nУправляемый ClearML SaaS. Развертывание выделенного облачного сервера Clear ML. Все данные и вычисления остаются в контуре клиентов или VPC.\nРазвертывание виртуального частного облака. Все данные остаются в контуре клиента. Самоуправление с полной удаленной поддержкой.\nЛокально Запускайте ClearML на собственных локальных серверах и персональных устройствах клиентов. Самоуправление с полной удаленной поддержкой.\nVPC Полностью управляется ClearML в контуре.\n\nДалее мы будем рассматривать локальный запуск.",
    "crumbs": [
      "Лекции",
      "ClearML"
    ]
  },
  {
    "objectID": "slides/3.clearml.html#архитектура-clearml",
    "href": "slides/3.clearml.html#архитектура-clearml",
    "title": "ClearML",
    "section": "Архитектура ClearML",
    "text": "Архитектура ClearML\n\n\nClearML Server – решение поставляемое clearml – это внутренняя инфраструктура из набора сервисов ClearML . Существует бесплатная опенсорс-реализация этого ClearML Server. Ее можно развернуть на свои собственных мощностях и использовать внутри команды для совместной работы.\nClearML Server содержит следующие компоненты:\n\nВеб-приложение ClearML — одностраничный пользовательский интерфейс для управления экспериментами и просмотра данных.\nRESTful API для:\n\nДокументирование и регистрация информации, статистики и результатов эксперимента.\nЗапрос истории экспериментов, журналов и результатов\n\nЛокальный файловый сервер для хранения изображений и моделей, обеспечивающий легкий доступ к ним с помощью веб-приложения. При желании его можно заменить на s3-совместимое хранилище.\n\nЕго можно быстро развернуть с помощью Docker, AWS EC2 AMI или Kubernetes. Есть две конфигурации сервера с зафиксированными портами или саб-деменами. Дефолтно используются следующие порты\n\nВеб-приложение на порту 8080\nСлужба API на порту 8008\nСлужба хранения файлов на порту 8081\n\nОзнакомиться с запуском вы можете в документации, он несколько различается для разных систем. Но заключается в запуске docker-compose или kubectl. При запуске у вас будут запущены все компоненты clear ml, а также elatic, mongo db и redis для хранения информации на сервере clear ml.\nВажный нюанс, дефолтно clear ml не запускается функции аутентификации, и соответственно на селфхостед версию может зайти кто угодно. Для подключения аутентификации нужно изменить конфиг и прописать список пользователей (логин + пароль) для кого будет доступе сервис, то есть это будет дополнительная работа для админа.",
    "crumbs": [
      "Лекции",
      "ClearML"
    ]
  },
  {
    "objectID": "slides/3.clearml.html#clearml-agent",
    "href": "slides/3.clearml.html#clearml-agent",
    "title": "ClearML",
    "section": "ClearML agent",
    "text": "ClearML agent\n\n\nClearML Agent — это виртуальная среда и менеджер выполнения решений DL/ML на машинах с графическим процессором. Он интегрируется с пакетом ClearML Python и сервером ClearML, обеспечивая полноценное кластерное решение ИИ. Основное внимание уделяется:\n\nВоспроизведению экспериментов, включая их полную среду.\nМасштабированию рабочих процессов на нескольких целевых машинах.\n\nАгент ClearML выполняет эксперимент или другой рабочий процесс, воспроизводя состояние кода с исходного компьютера на удаленный компьютер. Для этого он клонирует состояние репозитория (определенный коммит) указанные в эксперименте и добавляет git diff от коммита, сохраненный в эксперименте.\nНа предыдущей диаграмме показан типичный процесс, в котором агент выполняет задачу:\n\nПоставьте задачу для выполнения в очередь.\nАгент извлекает задачу из очереди.\nАгент запускает Docker-контейнер, в котором выполняется код задачи.\nНастраивается среда выполнения задачи:\n\nВыполнить любой настроенный сценарий пользовательской установки.\nУстановить все необходимые системные пакеты.\nКлонируется код из репозитория git.\nПрименяются все записанные незафиксированные изменения.\nНастраивает среду Python и необходимые пакеты.\n\nСценарий/код задачи выполняется.\n\n\nАгент ClearML использует версию Python, доступную в среде или докере, в котором он выполняет код. Он не устанавливает Python, поэтому обязательно используйте докер или среду той версии, которая вам нужна.\n\n\nАгент ClearML может работать на Google Colab. Это помогает пользователям использовать вычислительные ресурсы, предоставляемые Google Colab, и отправлять на них эксперименты для выполнения.",
    "crumbs": [
      "Лекции",
      "ClearML"
    ]
  },
  {
    "objectID": "slides/3.clearml.html#clearml-serving",
    "href": "slides/3.clearml.html#clearml-serving",
    "title": "ClearML",
    "section": "ClearML serving",
    "text": "ClearML serving\n\n\nClearML serving – это сервис для развертывания и оркестровки моделей. Он позволяет развертывать модели, включая обслуживание и предварительную обработку кода в кластере Kubernetes или пользовательском решении на основе контейнера. Важные качества такого подхода: - Простота развертывания и настройки - Поддержка моделей машинного обучения (Scikit Learn, XGBoost, LightGBM) - Поддержка моделей глубокого обучения (TensorFlow, PyTorch, ONNX) - Настраиваемый RestAPI для обслуживания (т.е. позволяет выполнять предварительную и последующую обработку для каждой модели для легкой интеграции) - Гибкость - Развертывание модели в режиме онлайн - Развертывание модели/версии конечной точки в режиме онлайн (т.е. нет необходимости останавливать работу сервиса) - Отдельная предварительная и постобработка кода Python для каждой модели - Масштабируемость - Несколько моделей на контейнер - Несколько моделей на одну услугу обслуживания - Поддержка нескольких служб (полностью разделенные многофункциональные службы, работающие независимо) - Поддержка нескольких кластеров - Автоматическое масштабирование узлов «из коробки» на основе нагрузки/использования - Эффективность - Использование ресурсов нескольких контейнеров - Поддержка узлов CPU и GPU - Автоматическое пакетирование для моделей DL - Автоматическое развертывание - Автоматические обновления моделей с поддержкой Canary - Программируемый API для развертывания модели - Развертывание Canary A/B — онлайн-обновления Canary - Мониторинг - Отчетность по показателям использования - Метрическая панель инструментов - Метрика производительности модели - Панель управления производительностью модели",
    "crumbs": [
      "Лекции",
      "ClearML"
    ]
  },
  {
    "objectID": "slides/3.clearml.html#подключение-к-clearml-серверу",
    "href": "slides/3.clearml.html#подключение-к-clearml-серверу",
    "title": "ClearML",
    "section": "Подключение к ClearML серверу",
    "text": "Подключение к ClearML серверу\n~/clearml.conf\napi {\n    web_server: \"http://localhost:8008\"\n    api_server: \"http://localhost:8080\"\n    files_server: \"http://localhost:8081\"\n}\n\nПредварительно установите clearml в ваш проект с помощью pip/poetry/pdm и тд.\nДля подключения к серверу есть два варианта:\n\nЗапустить команду clearml-init для интерактивной настройки\nРучками прописать в файле ~/clearml.conf адреса основных компонент clear ml.\n\nПосле настройки вы легко сможете подключать clearm ml к серверу, загружать или выгружать данные, модели, результаты экспериментов. буквально парой строк кода.\nЕсть важное примечание, если вы используете саб-доменную конфигурацию, то нужно указывать протокол http/https, а так же порты если они отличаются от 80 и 443",
    "crumbs": [
      "Лекции",
      "ClearML"
    ]
  },
  {
    "objectID": "slides/3.clearml.html#трекинг-экспериментов",
    "href": "slides/3.clearml.html#трекинг-экспериментов",
    "title": "ClearML",
    "section": "Трекинг экспериментов",
    "text": "Трекинг экспериментов\n\n\nfrom clearml import Task\n\n\ndef main():\n    ...\n    task = Task.init(project_name='great project', task_name='best experiment')\n    ...\n    task.set_progress(0)\n    ...\n    task.set_progress(50)\n    print(task.get_progress())\n    ...\n    task.set_progress(100)\n\n\n\n\nВ ClearML эксперименты организованы в виде задач. ClearML автоматически регистрирует ваш эксперимент и код, включая выходные данные и параметры из популярных платформ машинного обучения, как только вы интегрируете ClearML со своим кодом.\nДля этого импортируете класс Task в код, инициализируйте Task, указав проект и имя эксперимента. Если проект еще не существует, новый создается автоматически. Действительно этих двух строк хватит что бы логировать практически любые эксперименты",
    "crumbs": [
      "Лекции",
      "ClearML"
    ]
  },
  {
    "objectID": "slides/3.clearml.html#что-логирует-clear-ml",
    "href": "slides/3.clearml.html#что-логирует-clear-ml",
    "title": "ClearML",
    "section": "Что логирует clear ml",
    "text": "Что логирует clear ml\n\n\n\nHyperparameters\n\nCommand Line Parsing\n\nclick\nargparse\nPython Fire\nLightningCLI\n\nTensorFlow Definitions (absl-py)\nHydra\n\nMetrics, scalars, plots\n\nMatplotlib\nTensorboard\nTensorboardX\n\nExecution details including\n\nGit information\nUncommitted code modifications\nPython environment\nExecution configuration\n\n\n\n\nModels\n\nTensorFlow\nKeras\nPyTorch\nAutoKeras\nCatBoost\nFast.ai\nLightGBM\nMegEngine\nMONAI\nscikit-learn (only using joblib)\nXGBoost (only using joblib)\nYOLOv8\nYOLOv5",
    "crumbs": [
      "Лекции",
      "ClearML"
    ]
  },
  {
    "objectID": "slides/3.clearml.html#clearml-task",
    "href": "slides/3.clearml.html#clearml-task",
    "title": "ClearML",
    "section": "ClearML Task",
    "text": "ClearML Task\n\n\nПолучение эксперимента по ID\nprev_task = Task.get_task(task_id='123456deadbeef')\nПолучение эксперимента по имени\nprev_task = Task.get_task(\n    project_name='great project',\n    task_name='best experiment',\n)\n\nФильтрация экспериментов по разным параметрам\ntask_list = Task.get_tasks(\n    task_ids=None,  # type Optional[Sequence[str]]\n    project_name=None,  # Optional[str]\n    task_name=None,  # Optional[str]\n    allow_archived=True, # [bool]\n    task_filter=None,  # Optional[Dict]#\n    # tasks with tag `included_tag` or without tag `excluded_tag`\n    tags=['included_tag', '-excluded_tag']\n)\n\n\nКаждый ранее выполненный эксперимент сохраняется как Задача. То есть атомарной единицей исследования в clearml является разовый запуск какого-то эксперимента. Эксперименту-задаче автоматически присваивается автоматически сгенерированный уникальный идентификатор (строка UUID), который нельзя изменить и который всегда определяет одну и ту же задачу в системе.\nМожно получить объект Task программным путем, запросив систему на основе идентификатора задачи или комбинации проекта и имени. Вы также можете запрашивать задачи на основе их свойств, например теговб имени проекта или задачи и тд.\nКогда вы получили объект Task, то можете получить его состояние: модель, датасет, метрики, параметры и тд.",
    "crumbs": [
      "Лекции",
      "ClearML"
    ]
  },
  {
    "objectID": "slides/3.clearml.html#clearml-artifacts",
    "href": "slides/3.clearml.html#clearml-artifacts",
    "title": "ClearML",
    "section": "ClearML artifacts",
    "text": "ClearML artifacts\n\n\nДобавление артефактов\n# конкретный файл\ntask.upload_artifact(\n    name='data',\n    artifact_object='/path/to/preprocess_data.csv',\n)\n# дирректория и все файлы внутри нее\ntask.upload_artifact(name='folder', artifact_object='/path/to/folder/')\n# объект python\nnumpy_object = np.eye(100, 100)\ntask.upload_artifact(name='features', artifact_object=numpy_object)\n\nИспользование артефактов\npreprocess_task = Task.get_task(task_id='preprocessing_task_id')\nlocal_csv = preprocess_task.artifacts['data'].get_local_copy()\n\n\nprev_task = Task.get_task(task_id='the_training_task')\nlast_snapshot = prev_task.models['output'][-1]\nlocal_weights_path = last_snapshot.get_local_copy()\n\n\nClearML позволяет легко хранить выходные продукты эксперимента — снимок модели/файл весов, предварительную обработку данных, функциональное представление данных и многое другое!\nПо сути, артефакты — это файлы (или объекты Python), загруженные из сценария и хранящиеся вместе с задачей. К этим артефактам можно легко получить доступ через веб-интерфейс или программно.\nАртефакты можно хранить где угодно: на сервере ClearML, в любом решении для хранения объектов или в общей папке.\nЗарегистрированные артефакты могут использоваться другими задачами, будь то предварительно обученная модель или обработанные данные. Чтобы использовать артефакт, сначала вам необходимо получить экземпляр задачи, которая его изначально создала, затем вы либо загружаете его и получаете путь к нему, либо получаете объект артефакта напрямую.\ntask.artifacts— это словарь, ключами которого являются имена артефактов, а возвращаемый объект — это объект артефакта.\n\nВызов get_local_copy() создает локально копию артефакта и возвращает путь до объекта. Таким образом, при следующем выполнении кода вам не потребуется повторно загружать артефакт.\nВызов get() возвращает десериализованный python объект, не сохраняя его в локальный кеш.\n\nЕще хотелось бы уделить внимание моделям. Модели — это особый вид артефакта. Модели, созданные с помощью популярных платформ (таких как PyTorch, TensorFlow, Scikit-learn), автоматически регистрируются ClearML. Все снимки автоматически записываются. Чтобы убедиться, что вы также автоматически загружаете снимок модели (вместо сохранения ее локального пути), укажите место хранения файлов модели, в которые будут загружены. для этого надо добавить аргумент output_uri в инициализацию Task.\n\nОбщая папка:/mnt/share/folder\nS3:s3://bucket/folder\nСервисы, отличные от AWS S3 (например, MinIO):s3://host_addr:port/bucket\nОблачное хранилище Google:gs://bucket-name/folder\nХранилище Azure:azure://.blob.core.windows.net/path/to/file\n\nЧто бы получить модель, нужно получить экземпляр задачи, обучающей исходные файлы весов, затем вы можете запросить у задачи ее выходные модели (список снимков) и получить последний снимок.",
    "crumbs": [
      "Лекции",
      "ClearML"
    ]
  },
  {
    "objectID": "slides/3.clearml.html#clearml-metrics",
    "href": "slides/3.clearml.html#clearml-metrics",
    "title": "ClearML",
    "section": "ClearML metrics",
    "text": "ClearML metrics\n\n\nАвтоматическое логирование\n\nTensorBoard\nTensorBoardX\nMatplotlib\n\n\n\n\n\n\n\nРучное логирование метрик\nlogger = task.get_logger()\n\nfor i in range(100):\n    logger.report_scalar(\n        \"unified graph\", \"series A\", iteration=i, value=1./(i+1)\n    )\n    logger.report_scalar(\n        \"unified graph\", \"series B\", iteration=i, value=10./(i+1)\n    )\n\n\n\n\n\n\n\nClearML автоматически фиксирует показатели, передаваемые в ведущие библиотеки визуализации, такие как TensorBoard и Matplotlib, без необходимости использования дополнительного кода.\nКроме того, ClearML фиксирует и регистрирует все, что выводится на стандартный вывод, — от сообщений отладки до ошибок и предупреждающих сообщений библиотеки.\nИнформация о графическом процессоре, процессоре, памяти и сети также фиксируется автоматически.\nClearML также поддерживает составление вручную отчетов по нескольким типам показателей и графиков, таких как линейные графики, гистограммы и даже графические диаграммы.\nОбъект, используемый для ручного логирования метрик, называется logger и получается путем вызова Task.get_logger(). Например в него можно залогировать набор значений и в дальнейшем clearml построит график по тим значениям.",
    "crumbs": [
      "Лекции",
      "ClearML"
    ]
  },
  {
    "objectID": "slides/3.clearml.html#clearml-logging",
    "href": "slides/3.clearml.html#clearml-logging",
    "title": "ClearML",
    "section": "ClearML logging",
    "text": "ClearML logging\n\n\n\nТекст report_text\nСкаляры report_scalar\nОдинарное значение метрики report_single_value\nОтладочные примеры\n\nИзображений report_image\nHTML и Медиа (аудио, видео) report_media\n\nJupyter Notebook как отчет по эксперименту jupiter logging\n\n\n\nГрафики\n\n2D графики report_scatter2d\n\nГистограммы\nМатрицы ошибок\nДиаграммы рассеяния\n\n3D графики report_scatter3d\n\nГрафики поверхностей(surface)\nДиаграммы рассеяния\n\nТаблицы report_table\n\nPandas DataFrame\nCSV-файл\n\nMatplotlib figures report_matplotlib_figure\nPlotly figures report_plotly\n\n\n\n\nЭто весь список того что можно передать в logger, то есть можно сохранить текст, метрики, динамику метрик, какие-то графики из сырых данных, matplolib или plotly figures, различные таблицы данных и все это потом будет доступно в clearml при просмотре эксперимента.",
    "crumbs": [
      "Лекции",
      "ClearML"
    ]
  },
  {
    "objectID": "slides/3.clearml.html#clearml-data",
    "href": "slides/3.clearml.html#clearml-data",
    "title": "ClearML",
    "section": "ClearML data",
    "text": "ClearML data\n\n\nclearml-data — Утилита CLI для управления датасетами.\nclearml-data create [-h] [--parents [PARENTS [PARENTS ...]]] [--project PROJECT]\n                    --name NAME [--version VERSION] [--output-uri OUTPUT_URI]\n                    [--tags [TAGS [TAGS ...]]\n\nclearml.Dataset — Интерфейс Python для управления данными.\nfrom clearml import Dataset\n\ndataset = Dataset.create(\n  dataset_name='dataset name',\n  dataset_project='dataset project',\n  dataset_version=\"1.0\",\n)\n\n\n\nClearML Data Management решает две важные задачи:\n\nДоступность. Обеспечение легкого доступа к данным с любого компьютера.\nУправление версиями — связывание данных и экспериментов для лучшей прослеживаемости.\n\nНаборы clearml dataset можно настроить для наследования от других наборов данных, что позволяет создавать линии передачи данных, а пользователи могут отслеживать, когда и как изменяются их данные. Изменения набора данных сохраняются с использованием дифференцируемого хранилища, то есть версия будет хранить набор изменений из предыдущего родительского набора данных.\nУправлять можно из CLI и из питона, используя соответствующие инструменты clearml-data и clearml.Dataset.\nК хорошим практикам управления данными относятся:\n\nверсионирование данных (если нужно как-то изменить набор данных, то создайте новую версию набора данных, а не новый датасет, так будет проще отслеживать изменения)\nдокументирование данных (Dataset.get_logger() и вы получаете те же возможности, что и в эксперименте)\nструктура данных, наборы данных можно организовывать в проекты (и подпроекты) . Кроме того, при создании набора данных к набору данных можно применять теги, что упростит поиск набора данных.",
    "crumbs": [
      "Лекции",
      "ClearML"
    ]
  },
  {
    "objectID": "slides/3.clearml.html#clear-ml-pipelines",
    "href": "slides/3.clearml.html#clear-ml-pipelines",
    "title": "ClearML",
    "section": "Clear ML pipelines",
    "text": "Clear ML pipelines\n\n\nПайплайны — это способ оптимизировать и соединить несколько процессов, используя выходные данные одного шага как входные данные другого.\nПайплайны ClearML реализуются с помощью задачи контроллера, которая содержит логику взаимодействия шагов пайплайна. В зависимости от спецификаций, изложенных в задаче контроллера, параметры шага могут быть переопределены, что позволяет использовать продукты выполнения других шагов, такие как артефакты и параметры.\nПри запуске контроллер последовательно запускает этапы пайплайна. Логика и шаги пайплайна могут выполняться локально или на любом компьютере с помощью Clearml-агента.\nClearML поддерживает несколько режимов выполнения пайлайна:\n\nУдаленный режим (по умолчанию). В этом режиме логика pipeline controller выполняется через назначенную очередь, и все шаги пайплайна запускаются удаленно через соответствующие очереди. Поскольку каждая задача выполняется независимо, она может контролировать свой репозиторий git (при необходимости), необходимые пакеты Python и конкретный контейнер, который будет использоваться.\nЛокальный режим. В этом режиме Пайплайн выполняется локально, а шаги выполняются как подпроцессы. Каждый подпроцесс использует ту же среду Python, что и логика основного пайплайна.\nРежим отладки (для PipelineDecorator). В этом режиме весь пайплайн выполняется локально, при этом контроллер пайплайна и шаги вызываются синхронно, как обычные функции Python, обеспечивая полную возможность отладки каждого вызова функции.\n\nПайплайны ClearML создаются из кода с использованием одного из следующих способов:\n\nКласс PipelineController — Pythonic интерфейс для определения и настройки контроллера пайплайна и его шагов. Контроллер и шаги могут быть функциями в вашем коде Python или существующими задачами ClearML .\nКласс PipelineDecorator — набор декораторов Python, которые преобразуют ваши функции в контроллер пайплайна и шаги.\n\n\nПоскольку контроллер пайплайна сам по себе является задачей-экспериментом ClearML , его можно использовать в качестве шага пайплайна. Это позволяет создавать более сложные рабочие процессы, например пайплайны, выполняющие другие пайплайны, или пайплайны, выполняющие несколько задач одновременно.",
    "crumbs": [
      "Лекции",
      "ClearML"
    ]
  },
  {
    "objectID": "2. clearml_yandex_kube.html",
    "href": "2. clearml_yandex_kube.html",
    "title": "Настройка ClearML Yandex",
    "section": "",
    "text": "Скачайте репозиторий clearml helm charts\n\n\nУпакуйте helm для дальнейшего использования\nhelm package clearml-helm-charts/charts/clearml \n\n\n\nСоздайте Cloud Registry для helm/docker.\nhelm push clearml-7.14.5.tgz oci://registry.yandexcloud.net/&lt;Cloud registry ID&gt;\n\n\n\nЗапустите готовый helm на вашем кластере kubernetes\nhelm install clearml oci://registry.yandexcloud.net/&lt;Cloud registry ID&gt;/clearml:7.14.5",
    "crumbs": [
      "Практика",
      "Настройка ClearML Yandex"
    ]
  },
  {
    "objectID": "2. clearml_yandex_kube.html#package-helm-chart",
    "href": "2. clearml_yandex_kube.html#package-helm-chart",
    "title": "Настройка ClearML Yandex",
    "section": "",
    "text": "Упакуйте helm для дальнейшего использования\nhelm package clearml-helm-charts/charts/clearml",
    "crumbs": [
      "Практика",
      "Настройка ClearML Yandex"
    ]
  },
  {
    "objectID": "2. clearml_yandex_kube.html#push-helm-chart",
    "href": "2. clearml_yandex_kube.html#push-helm-chart",
    "title": "Настройка ClearML Yandex",
    "section": "",
    "text": "Создайте Cloud Registry для helm/docker.\nhelm push clearml-7.14.5.tgz oci://registry.yandexcloud.net/&lt;Cloud registry ID&gt;",
    "crumbs": [
      "Практика",
      "Настройка ClearML Yandex"
    ]
  },
  {
    "objectID": "2. clearml_yandex_kube.html#deploy-helm-chart",
    "href": "2. clearml_yandex_kube.html#deploy-helm-chart",
    "title": "Настройка ClearML Yandex",
    "section": "",
    "text": "Запустите готовый helm на вашем кластере kubernetes\nhelm install clearml oci://registry.yandexcloud.net/&lt;Cloud registry ID&gt;/clearml:7.14.5",
    "crumbs": [
      "Практика",
      "Настройка ClearML Yandex"
    ]
  },
  {
    "objectID": "2. clearml_yandex_kube.html#package-helm-chart-1",
    "href": "2. clearml_yandex_kube.html#package-helm-chart-1",
    "title": "Настройка ClearML Yandex",
    "section": "Package helm chart",
    "text": "Package helm chart\nУпакуйте helm для дальнейшего использования\nhelm package clearml-helm-charts/charts/clearml-agent",
    "crumbs": [
      "Практика",
      "Настройка ClearML Yandex"
    ]
  },
  {
    "objectID": "2. clearml_yandex_kube.html#push-helm-chart-1",
    "href": "2. clearml_yandex_kube.html#push-helm-chart-1",
    "title": "Настройка ClearML Yandex",
    "section": "Push helm chart",
    "text": "Push helm chart\nСоздайте Cloud Registry для helm/docker.\nhelm push clearml-agent-5.3.3.tgz oci://registry.yandexcloud.net/&lt;Cloud registry ID&gt;",
    "crumbs": [
      "Практика",
      "Настройка ClearML Yandex"
    ]
  },
  {
    "objectID": "2. clearml_yandex_kube.html#deploy-helm-chart-1",
    "href": "2. clearml_yandex_kube.html#deploy-helm-chart-1",
    "title": "Настройка ClearML Yandex",
    "section": "Deploy helm chart",
    "text": "Deploy helm chart\nЗапустите готовый helm на вашем кластере kubernetes.\nhelm install clearml-agent oci://registry.yandexcloud.net/&lt;Cloud registry ID&gt;/clearml-agent:5.3.3  --set clearml.agentk8sglueKey=ACCESSKEY --set clearml.agentk8sglueSecret=SECRETKEY --set agentk8sglue.apiServerUrlReference=APISERVERURL --set agentk8sglue.fileServerUrlReference=FILESERVERURL --set agentk8sglue.webServerUrlReference=WEBSERVERURL\nСоздайте доступы в clearml (см. clearml_work.md) и заполните эти поля: * ACCESSKEY значение access_key в новых доступах * SECRETKEY значение secret_key в новых доступах * APISERVERURL значение api_server в новых доступах * FILESSERVERURL значение files_server в новых доступах * WEBSERVERURL значение web_server в новых доступах",
    "crumbs": [
      "Практика",
      "Настройка ClearML Yandex"
    ]
  },
  {
    "objectID": "2. clearml_yandex_kube.html#package-helm-chart-2",
    "href": "2. clearml_yandex_kube.html#package-helm-chart-2",
    "title": "Настройка ClearML Yandex",
    "section": "Package helm chart",
    "text": "Package helm chart\nУпакуйте helm для дальнейшего использования\nhelm package clearml-helm-charts/charts/clearml-serving",
    "crumbs": [
      "Практика",
      "Настройка ClearML Yandex"
    ]
  },
  {
    "objectID": "2. clearml_yandex_kube.html#push-helm-chart-2",
    "href": "2. clearml_yandex_kube.html#push-helm-chart-2",
    "title": "Настройка ClearML Yandex",
    "section": "Push helm chart",
    "text": "Push helm chart\nСоздайте Cloud Registry для helm/docker.\nhelm push clearml-serving-1.6.0.tgz oci://registry.yandexcloud.net/&lt;Cloud registry ID&gt;",
    "crumbs": [
      "Практика",
      "Настройка ClearML Yandex"
    ]
  },
  {
    "objectID": "2. clearml_yandex_kube.html#deploy-helm-chart-2",
    "href": "2. clearml_yandex_kube.html#deploy-helm-chart-2",
    "title": "Настройка ClearML Yandex",
    "section": "Deploy helm chart",
    "text": "Deploy helm chart\nЗапустите готовый helm на вашем кластере kubernetes.\nhelm install clearml-serving oci://registry.yandexcloud.net/&lt;Cloud registry ID&gt;/clearml-serving:1.6.0  --set clearml.apiAccessKey=ACCESSKEY --set clearml.apiSecretKey=SECRETKEY --set clearml.apiHost=APISERVERURL --set clearml.filesHost=FILESERVERURL --set clearml.webHost=WEBSERVERURL --set clearml.servingTaskId=SERVERINGID\nСоздайте доступы в clearml (см. clearml_work.md) и заполните эти поля: * ACCESSKEY значение access_key в новых доступах * SECRETKEY значение secret_key в новых доступах * APISERVERURL значение api_server в новых доступах * FILESSERVERURL значение files_server в новых доступах * WEBSERVERURL значение web_server в новых доступах\nСоздайте с помощью clearml-serving пространство (8. clearml_serving.md), SERVERINGID это его id.",
    "crumbs": [
      "Практика",
      "Настройка ClearML Yandex"
    ]
  },
  {
    "objectID": "4. clearml_data.html",
    "href": "4. clearml_data.html",
    "title": "ClearML Data",
    "section": "",
    "text": "ClearML Data\nВ примере для загрузки начальных данных использовался скрипт mlops-example/1.upload_dataset.ipynb. Для того что бы он работал скачайте датасет Amazon reviews и разархивируйте его в папку mlops-example/data.\nОткройте mlops-example/1.upload_dataset.ipynb и начните его выполнение.\n\nВ самом начале он создает пустой Clearml Dataset (мы рассмотрим работу через SDK, но есть еще и CLI), который мы будем постепенно наполнять данными из данных Amazon reviews. Вы сможете найти ваш датасет в разделе /datasets: http://51.250.106.18:30080/datasets.\n\ndataset = Dataset.create(\n    dataset_name=\"Amazon reviews dataset\",\n    dataset_project=\"Amazon reviews\",\n    dataset_version=\"1.0\",\n    description=\"Data from kagle project\",\n)\ndataset.finalize()\n\nРазбивает обучающую выборки на батчи по 25000 строк в цикле и обрабатывает каждый батч.\n\nfor index, batch in enumerate(\n    pl.read_csv(\n        \"data/train.csv\",\n        has_header=False,\n        new_columns=[\"Polarity\", \"Title\", \"Review\"],\n    )\n    .with_row_index()\n    .with_columns(pl.col(\"index\") // 25000)\n    .partition_by(\"index\")\n):\n\nСначала сохраняет batch локально под уникальным номером.\n\n    batch.write_csv(f\"data/raw/batch_{index}.csv\")\n\nСчитает для него распределение классов\n\n    polaritu_distrib = batch.group_by(\"Polarity\").len()\n\nСоздает новую версию датасета и добавляет в нее новый файл. Заметьте, что у датасета в качестве parent_datasets указана предыдущая версия датасета, это позволяет строить цепочку датасетов.\n\n    dataset = Dataset.create(\n        dataset_name=\"Amazon reviews dataset\",\n        dataset_project=\"Amazon reviews\",\n        parent_datasets=[dataset],\n        dataset_version=f\"1.{index}\",\n        description=\"Data from kagle project\",\n    )\n    dataset.add_files(path=f\"data/raw/batch_{index}.csv\")\n\n\nЗадает мета информацию об изменении датасета в виде гистограммы распределения классов и head добавляемой таблицы.\n\n    dataset.get_logger().report_table(\n        \"Dataset Preview\", \"Dataset Preview\", table_plot=batch.head(5).to_pandas()\n    )\n    dataset.get_logger().report_histogram(\n        title=\"Polarity distribution\",\n        series=\"Polarity distribution\",\n        values=polaritu_distrib[\"len\"].to_list(),\n        xlabels=polaritu_distrib[\"Polarity\"].to_list(),\n        yaxis=\"Number of samples\",\n    )\n\nЗагружает данные в датасет и финализирует новую версию.\n\n    dataset.upload()\n    dataset.finalize()\n\nТеперь вы можете легко получать данные из вашего датасета на любое рабочее место, выполнив такой код: ```python dataset = Dataset.get( dataset_name=“Amazon reviews dataset”, dataset_project=“Amazon reviews”, dataset_version=“1.143”, )",
    "crumbs": [
      "Практика",
      "ClearML Data"
    ]
  },
  {
    "objectID": "6. clearml_research.html",
    "href": "6. clearml_research.html",
    "title": "ClearML Research",
    "section": "",
    "text": "Теперь разберем самое интересное – как можно в ClearML проводить исследования. ClearML предоставляет комплексную платформу для управления ML-экспериментами: - Автоматическое отслеживание кода, параметров, метрик и артефактов - Воспроизводимость экспериментов через фиксацию данных, кода и зависимостей - Масштабирование с помощью удаленных агентов - Сравнение экспериментов через веб-интерфейс\nНиже объясняется как проводить исследования с примерами из 3.tf_idf.py и 4.bert_amazon.ipynb\n\n\n\nИнициализация задачи. Каждый эксперимент начинается с инициализации задачи, вот небольшой пример, но стоит посмотреть на документацию.\n\nfrom clearml import Task\ntask = Task.init(\n    project_name=\"Amazon reviews\",\n    task_name=\"TF-IDF Vectorize BernoulliNB\",  # или \"Bert\"\n    output_uri=True  # Автоматическое логирование артефактов\n)\n\nУправление конфигурацией. ClearML позволяет настроить отслеживание гиперпараметров и настроек:\n\nargs = {\n    \"random_state\": 42,\n    \"max_features\": 1000,\n    \"analyzer\": \"word\"\n}\ntask.connect(args)  # Логирует параметры в ClearML\n\n\nСтоит использовать не локальные данные, а данные которые у нас уже преобразованы в датасет. Это обеспечивает воспроизводимость:\n\nfrom clearml import Dataset\n\n# Получение конкретной версии датасета\ntrain_dataset = Dataset.get(\n    dataset_name=\"Amazon reviews dataset\",\n    dataset_project=\"Amazon reviews\",\n    dataset_version=\"1.2.1\"  # Фиксация версии\n)\nframe_path = train_dataset.get_local_copy()\n\nОбучение моделей и их логирование. Для этого у clearml есть специальный класс который позволяет задавать специальные артефакты–модели, которые в дальнейшем можно будет засерверить.\n\nfrom clearml import OutputModel\n\npipe = Pipeline([\n    (\"tfidf\", TfidfVectorizer()),\n    (\"bernoulli\", BernoulliNB())\n])\npipe.fit(train_x, train_y)\n\n# Сохранение и логирование модели\njoblib.dump(pipe, \"model.pkl\")\noutput_model = OutputModel(task=task, framework=\"scikit-learn\")\noutput_model.update_weights(weights_filename=\"model.pkl\")\n \n\nОтслеживание экспериментов и метрик может производиться как в отношении эксперимента, так и отдельных артефактов моделей/датасетов, ниже приведен пример как можно залогировать classification_report и он будет сохранен и в задании и в описании модели.\n\nimport pandas as pd\nfrom sklearn.metrics import classification_report\nfrom clearml import Logger\n\nlogger: Logger = task.get_logger()\n\npred_y = pipe.predict(test_x[\"corpus\"])\nclassification_report_table = pd.DataFrame(\n    classification_report(test_y, pred_y, output_dict=True)\n).T\nlogger.report_table(\n    \"Classifiacation Report\", \"Metrics\", table_plot=classification_report_table\n)\noutput_model.report_table(\n    \"Classifiacation Report\", \"Metrics\", table_plot=classification_report_table\n)\nclassification_report_table\n\n\nМожно заниматься логированием отдельных артефактов в задания, например эмбендингов полученных от bert’a, что бы использовать их в других экспериментах.\n\n# Загрузка эмбеддингов (пример BERT)\ntask.upload_artifact(\"train_embeddings\", train_embeddings)\n\nClearML автоматически фиксирует:\n\n\nКонсольный вывод\nИсходный код (с созданием Git-снимка)\nУстановленные зависимости\nСистемные метрики (CPU/GPU/память) Для этого не требуется дополнительный код.\n\n\nСравнение экспериментов в ClearML есть инструменты для сравнения экспериментов, вы можете легко сравнивать результаты разных экспериментов и графики и метрики.\n\n\n\n\n\n\nИнициализация задачи: Начните отслеживание перед выполнением кода\nКонфигурация параметров: Используйте task.connect() для воспроизводимости и повторных удаленных запусков на clearml agent с другими параметрами.\nВерсионирование данных: Выбирайте версии датасетов через Dataset.get(), и лучше установить версию как параметр, что бы вы легко могли воспроизвести эксперимент на следующих инкрементах данных.\nВыполнение эксперимента:\n\nАвтоматическое/ручное логирование метрик\nСохранение моделей через OutputModel\nЛогирование артефактов через task.upload_artifact()\n\nФинализация: task.mark_completed() – по завершении пометьте эксперимент выполненным\nВоспроизведение:\n\nКлонирование задачи через веб-интерфейс\nЗапуск на удаленном агенте с новыми параметрами\n\nСравнение экспериментов с различными параметрами в веб интерфейсе",
    "crumbs": [
      "Практика",
      "ClearML Research"
    ]
  },
  {
    "objectID": "6. clearml_research.html#ключевые-шаги-исследований-в-clearml",
    "href": "6. clearml_research.html#ключевые-шаги-исследований-в-clearml",
    "title": "ClearML Research",
    "section": "",
    "text": "Инициализация задачи. Каждый эксперимент начинается с инициализации задачи, вот небольшой пример, но стоит посмотреть на документацию.\n\nfrom clearml import Task\ntask = Task.init(\n    project_name=\"Amazon reviews\",\n    task_name=\"TF-IDF Vectorize BernoulliNB\",  # или \"Bert\"\n    output_uri=True  # Автоматическое логирование артефактов\n)\n\nУправление конфигурацией. ClearML позволяет настроить отслеживание гиперпараметров и настроек:\n\nargs = {\n    \"random_state\": 42,\n    \"max_features\": 1000,\n    \"analyzer\": \"word\"\n}\ntask.connect(args)  # Логирует параметры в ClearML\n\n\nСтоит использовать не локальные данные, а данные которые у нас уже преобразованы в датасет. Это обеспечивает воспроизводимость:\n\nfrom clearml import Dataset\n\n# Получение конкретной версии датасета\ntrain_dataset = Dataset.get(\n    dataset_name=\"Amazon reviews dataset\",\n    dataset_project=\"Amazon reviews\",\n    dataset_version=\"1.2.1\"  # Фиксация версии\n)\nframe_path = train_dataset.get_local_copy()\n\nОбучение моделей и их логирование. Для этого у clearml есть специальный класс который позволяет задавать специальные артефакты–модели, которые в дальнейшем можно будет засерверить.\n\nfrom clearml import OutputModel\n\npipe = Pipeline([\n    (\"tfidf\", TfidfVectorizer()),\n    (\"bernoulli\", BernoulliNB())\n])\npipe.fit(train_x, train_y)\n\n# Сохранение и логирование модели\njoblib.dump(pipe, \"model.pkl\")\noutput_model = OutputModel(task=task, framework=\"scikit-learn\")\noutput_model.update_weights(weights_filename=\"model.pkl\")\n \n\nОтслеживание экспериментов и метрик может производиться как в отношении эксперимента, так и отдельных артефактов моделей/датасетов, ниже приведен пример как можно залогировать classification_report и он будет сохранен и в задании и в описании модели.\n\nimport pandas as pd\nfrom sklearn.metrics import classification_report\nfrom clearml import Logger\n\nlogger: Logger = task.get_logger()\n\npred_y = pipe.predict(test_x[\"corpus\"])\nclassification_report_table = pd.DataFrame(\n    classification_report(test_y, pred_y, output_dict=True)\n).T\nlogger.report_table(\n    \"Classifiacation Report\", \"Metrics\", table_plot=classification_report_table\n)\noutput_model.report_table(\n    \"Classifiacation Report\", \"Metrics\", table_plot=classification_report_table\n)\nclassification_report_table\n\n\nМожно заниматься логированием отдельных артефактов в задания, например эмбендингов полученных от bert’a, что бы использовать их в других экспериментах.\n\n# Загрузка эмбеддингов (пример BERT)\ntask.upload_artifact(\"train_embeddings\", train_embeddings)\n\nClearML автоматически фиксирует:\n\n\nКонсольный вывод\nИсходный код (с созданием Git-снимка)\nУстановленные зависимости\nСистемные метрики (CPU/GPU/память) Для этого не требуется дополнительный код.\n\n\nСравнение экспериментов в ClearML есть инструменты для сравнения экспериментов, вы можете легко сравнивать результаты разных экспериментов и графики и метрики.",
    "crumbs": [
      "Практика",
      "ClearML Research"
    ]
  },
  {
    "objectID": "6. clearml_research.html#шаги-рабочего-процесса",
    "href": "6. clearml_research.html#шаги-рабочего-процесса",
    "title": "ClearML Research",
    "section": "",
    "text": "Инициализация задачи: Начните отслеживание перед выполнением кода\nКонфигурация параметров: Используйте task.connect() для воспроизводимости и повторных удаленных запусков на clearml agent с другими параметрами.\nВерсионирование данных: Выбирайте версии датасетов через Dataset.get(), и лучше установить версию как параметр, что бы вы легко могли воспроизвести эксперимент на следующих инкрементах данных.\nВыполнение эксперимента:\n\nАвтоматическое/ручное логирование метрик\nСохранение моделей через OutputModel\nЛогирование артефактов через task.upload_artifact()\n\nФинализация: task.mark_completed() – по завершении пометьте эксперимент выполненным\nВоспроизведение:\n\nКлонирование задачи через веб-интерфейс\nЗапуск на удаленном агенте с новыми параметрами\n\nСравнение экспериментов с различными параметрами в веб интерфейсе",
    "crumbs": [
      "Практика",
      "ClearML Research"
    ]
  },
  {
    "objectID": "8. clearml_serving.html",
    "href": "8. clearml_serving.html",
    "title": "ClearML Servering",
    "section": "",
    "text": "Установите clearml-serving\n\npixi add --pypi clearml-serving\npixi install -a\n\nСоздайте clearml serving controller:\n\npixi run clearml-serving create --name  \"Amazon Reviews\"\nПолучите его ID для развертки clearml-serving в kubernetess\nNew Serving Service created: id=3e0e2ce884444da694fb774ef94ecc5f\n\nПерейдите к инструкции из 2. clearml_yandex_kube.md. Используйте полученный ID как SERVERINGID. Обратите внимание, что в serving нужно добавить зависимости в values.yaml\n\nclearml_serving_inference:\n  ...\n  extraPythonPackages:\n  - nltk==3.9.1\n  - polars&gt;=1.31.0,&lt;2\n\nДалее работаем с clearml-serving, (Вот тут документация)\n\n\n\n\n\nСтоит опубликовать вашу модель, которую вы хотите использовать, выберете в артефактах вашу модель и нажмите publish в ее меню. \nДалее нужно подготовить prepreprocessing для данных на вход модели, варианты можно найти в примерах. Вам нужно по сути написать класс Preprocessing в виде класса в фалйле, вот пример для подготовки данных в tf-idf\n\nclass Preprocess(object):\n    def __init__(self):\n        # set internal state, this will be called only once. (i.e. not per request)\n        pass\n\n    def preprocess(\n        self, body: dict, state: dict, collect_custom_statistics_fn=None\n    ) -&gt; Any:\n        # we expect to get two valid on the dict x0, and x1\n        text = body.get(\"text\", None)\n        processed_words = text_preprocessing(text).split(\" \")\n        lemmatizer = WordNetLemmatizer()\n        processed_text = \" \".join(\n            [lemmatizer.lemmatize(token) for token in processed_words]\n        )\n        return [processed_text]\n\n    def postprocess(\n        self, data: Any, state: dict, collect_custom_statistics_fn=None\n    ) -&gt; dict:\n        # post process the data returned from the model inference engine\n        # data is the return value from model.predict we will put is inside a return value as Y\n        return dict(y=data.tolist() if isinstance(data, np.ndarray) else data)\n\nДобавьте модель в serving:\n\npixi run clearml-serving --id 3e0e2ce884444da694fb774ef94ecc5f model auto-update --engine sklearn --endpoint \"sentiment_analyze\" --published --project \"Amazon reviews\" --name \"TF-IDF Vectorize BernoulliNB\" --max-versions 5 --preprocess \"mlops-example/mlops_example/preprocessing.py\"\nВот разбор команды: - Указываем --id   3e0e2ce884444da694fb774ef94ecc5f созданного контроллера - Выбираем режим модели model auto-update для автообновления при публикации новых моделей - Указываем фреймворк модели --engine sklearn (см документацию) - Определяем ендпоинт для доступа к модели --endpoint \"sentiment_analyze\" - Указываем параметры модели: опубликованные модели --published определенного проекта --project \"Amazon reviews\" под названием --name \"TF-IDF Vectorize BernoulliNB\" - Максимальное количество версий модели которые могут быть запущены --max-versions 5 - Указываем скрипт препроцессинга --preprocess \"mlops-example/mlops_example/preprocessing.py\"\n\nТеперь перейдите в проект DevOps, там в задаче Amazon Reviews - serve instance будут логи добавления модели.  Так же можете выполнить команду:\n\npixi run clearml-serving --id 3e0e2ce884444da694fb774ef94ecc5f model list\nИ увидеть что модели загружены:\nclearml-serving - CLI for launching ClearML serving engine\nList model serving and endpoints, control task id=3e0e2ce884444da694fb774ef94ecc5f\nInfo: syncing model endpoint configuration, state hash=378b860f5e9c7c07f37320fe4033bdad\nEndpoints:\n{}\nModel Monitoring:\n{\n  \"sentiment_analyze\": {\n    \"base_serving_url\": \"sentiment_analyze\",\n    \"engine_type\": \"sklearn\",\n    \"monitor_project\": \"Amazon reviews\",\n    \"monitor_name\": \"TF-IDF Vectorize BernoulliNB\",\n    \"monitor_tags\": [],\n    \"only_published\": true,\n    \"max_versions\": 5,\n    \"input_size\": null,\n    \"input_type\": null,\n    \"input_name\": null,\n    \"output_size\": null,\n    \"output_type\": null,\n    \"output_name\": null,\n    \"preprocess_artifact\": \"py_code_sentiment_analyze\",\n    \"auxiliary_cfg\": null\n  }\n}\nCanary:\n{}\n\n\n\nПопробуем потестировать модель, сразу оговорюсь нужно делать тесты мз сети yc, так как для моделей не проброшены внешние порты, для этого можно развернуть виртуалку. Попробуем первый запрос, мы будем обращаться к модели с ID=27c2c1bb0af74984a3a22e702f65fdf9, поэтому в url указываем версию 2.\ncurl -X POST \"http://10.112.135.102:8080/serve/sentiment_analyze/2\" -H \"accept: application/json\" -H \"Content-Type: application/json\" -d \"{\\\"text\\\": \\\"Taking this out of my daughter's library, I found this book and thought the illustrtions were absolutey beautiful -- a true work of artistry. However, I didn't read it through before I bought it. I was reading it to my daughter when I discovered how disturbing the story turns with the spanking scenes. I stopped reading the book and I will take it out of my house.\\\"}\"\nОтвет модели: {\"y\":[2]}\nТеперь второй запрос:\ncurl -X POST \"http://10.112.135.102:8080/serve/sentiment_analyze/2\" -H \"accept: application/json\" -H \"Content-Type: application/json\" -d \"{\\\"text\\\": \\\"Scratched the lens with a kleenex,I used these once then used a Kleenex to wipe one lens that was a little smudged. I have microscopic vision and I noticed it was scratched AFTER I used the Kleenex, so to be sure, I used it again and sure enough, it scratched the lens some more. I compared the 2 lenses and the other lens looked pristine, whereas the one I used the kleenex on was scratched all over Very low quality lenses! Unusable after one use\\\"}\"\nОтвет модели: {\"y\":[1]}\nВидим что модель работает и назначает соответствующие лейблы. Отлично у вас есть развернутая модель которую можно использовать и отправлять ей разные запросы.",
    "crumbs": [
      "Практика",
      "ClearML Servering"
    ]
  },
  {
    "objectID": "8. clearml_serving.html#базовая-настройка",
    "href": "8. clearml_serving.html#базовая-настройка",
    "title": "ClearML Servering",
    "section": "",
    "text": "Установите clearml-serving\n\npixi add --pypi clearml-serving\npixi install -a\n\nСоздайте clearml serving controller:\n\npixi run clearml-serving create --name  \"Amazon Reviews\"\nПолучите его ID для развертки clearml-serving в kubernetess\nNew Serving Service created: id=3e0e2ce884444da694fb774ef94ecc5f\n\nПерейдите к инструкции из 2. clearml_yandex_kube.md. Используйте полученный ID как SERVERINGID. Обратите внимание, что в serving нужно добавить зависимости в values.yaml\n\nclearml_serving_inference:\n  ...\n  extraPythonPackages:\n  - nltk==3.9.1\n  - polars&gt;=1.31.0,&lt;2\n\nДалее работаем с clearml-serving, (Вот тут документация)",
    "crumbs": [
      "Практика",
      "ClearML Servering"
    ]
  },
  {
    "objectID": "8. clearml_serving.html#добвавлние-моделей",
    "href": "8. clearml_serving.html#добвавлние-моделей",
    "title": "ClearML Servering",
    "section": "",
    "text": "Стоит опубликовать вашу модель, которую вы хотите использовать, выберете в артефактах вашу модель и нажмите publish в ее меню. \nДалее нужно подготовить prepreprocessing для данных на вход модели, варианты можно найти в примерах. Вам нужно по сути написать класс Preprocessing в виде класса в фалйле, вот пример для подготовки данных в tf-idf\n\nclass Preprocess(object):\n    def __init__(self):\n        # set internal state, this will be called only once. (i.e. not per request)\n        pass\n\n    def preprocess(\n        self, body: dict, state: dict, collect_custom_statistics_fn=None\n    ) -&gt; Any:\n        # we expect to get two valid on the dict x0, and x1\n        text = body.get(\"text\", None)\n        processed_words = text_preprocessing(text).split(\" \")\n        lemmatizer = WordNetLemmatizer()\n        processed_text = \" \".join(\n            [lemmatizer.lemmatize(token) for token in processed_words]\n        )\n        return [processed_text]\n\n    def postprocess(\n        self, data: Any, state: dict, collect_custom_statistics_fn=None\n    ) -&gt; dict:\n        # post process the data returned from the model inference engine\n        # data is the return value from model.predict we will put is inside a return value as Y\n        return dict(y=data.tolist() if isinstance(data, np.ndarray) else data)\n\nДобавьте модель в serving:\n\npixi run clearml-serving --id 3e0e2ce884444da694fb774ef94ecc5f model auto-update --engine sklearn --endpoint \"sentiment_analyze\" --published --project \"Amazon reviews\" --name \"TF-IDF Vectorize BernoulliNB\" --max-versions 5 --preprocess \"mlops-example/mlops_example/preprocessing.py\"\nВот разбор команды: - Указываем --id   3e0e2ce884444da694fb774ef94ecc5f созданного контроллера - Выбираем режим модели model auto-update для автообновления при публикации новых моделей - Указываем фреймворк модели --engine sklearn (см документацию) - Определяем ендпоинт для доступа к модели --endpoint \"sentiment_analyze\" - Указываем параметры модели: опубликованные модели --published определенного проекта --project \"Amazon reviews\" под названием --name \"TF-IDF Vectorize BernoulliNB\" - Максимальное количество версий модели которые могут быть запущены --max-versions 5 - Указываем скрипт препроцессинга --preprocess \"mlops-example/mlops_example/preprocessing.py\"\n\nТеперь перейдите в проект DevOps, там в задаче Amazon Reviews - serve instance будут логи добавления модели.  Так же можете выполнить команду:\n\npixi run clearml-serving --id 3e0e2ce884444da694fb774ef94ecc5f model list\nИ увидеть что модели загружены:\nclearml-serving - CLI for launching ClearML serving engine\nList model serving and endpoints, control task id=3e0e2ce884444da694fb774ef94ecc5f\nInfo: syncing model endpoint configuration, state hash=378b860f5e9c7c07f37320fe4033bdad\nEndpoints:\n{}\nModel Monitoring:\n{\n  \"sentiment_analyze\": {\n    \"base_serving_url\": \"sentiment_analyze\",\n    \"engine_type\": \"sklearn\",\n    \"monitor_project\": \"Amazon reviews\",\n    \"monitor_name\": \"TF-IDF Vectorize BernoulliNB\",\n    \"monitor_tags\": [],\n    \"only_published\": true,\n    \"max_versions\": 5,\n    \"input_size\": null,\n    \"input_type\": null,\n    \"input_name\": null,\n    \"output_size\": null,\n    \"output_type\": null,\n    \"output_name\": null,\n    \"preprocess_artifact\": \"py_code_sentiment_analyze\",\n    \"auxiliary_cfg\": null\n  }\n}\nCanary:\n{}",
    "crumbs": [
      "Практика",
      "ClearML Servering"
    ]
  },
  {
    "objectID": "8. clearml_serving.html#тестирвоание-модели",
    "href": "8. clearml_serving.html#тестирвоание-модели",
    "title": "ClearML Servering",
    "section": "",
    "text": "Попробуем потестировать модель, сразу оговорюсь нужно делать тесты мз сети yc, так как для моделей не проброшены внешние порты, для этого можно развернуть виртуалку. Попробуем первый запрос, мы будем обращаться к модели с ID=27c2c1bb0af74984a3a22e702f65fdf9, поэтому в url указываем версию 2.\ncurl -X POST \"http://10.112.135.102:8080/serve/sentiment_analyze/2\" -H \"accept: application/json\" -H \"Content-Type: application/json\" -d \"{\\\"text\\\": \\\"Taking this out of my daughter's library, I found this book and thought the illustrtions were absolutey beautiful -- a true work of artistry. However, I didn't read it through before I bought it. I was reading it to my daughter when I discovered how disturbing the story turns with the spanking scenes. I stopped reading the book and I will take it out of my house.\\\"}\"\nОтвет модели: {\"y\":[2]}\nТеперь второй запрос:\ncurl -X POST \"http://10.112.135.102:8080/serve/sentiment_analyze/2\" -H \"accept: application/json\" -H \"Content-Type: application/json\" -d \"{\\\"text\\\": \\\"Scratched the lens with a kleenex,I used these once then used a Kleenex to wipe one lens that was a little smudged. I have microscopic vision and I noticed it was scratched AFTER I used the Kleenex, so to be sure, I used it again and sure enough, it scratched the lens some more. I compared the 2 lenses and the other lens looked pristine, whereas the one I used the kleenex on was scratched all over Very low quality lenses! Unusable after one use\\\"}\"\nОтвет модели: {\"y\":[1]}\nВидим что модель работает и назначает соответствующие лейблы. Отлично у вас есть развернутая модель которую можно использовать и отправлять ей разные запросы.",
    "crumbs": [
      "Практика",
      "ClearML Servering"
    ]
  }
]