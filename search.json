[
  {
    "objectID": "9. clearml_extend_pipes.html",
    "href": "9. clearml_extend_pipes.html",
    "title": "Расширение ClearML pipelines",
    "section": "",
    "text": "Расширение ClearML pipelines\nЕще немного вернемся к пайплайнам, кроме пайплайнов из кода, как это было показано в 5. clearml_pipeline.md, можно создавать пайплайны из задач. Давайте разберемся, что для этого надо и рассмотрим файл mlops-example/5.full_pipe.py.\n\nТочно также инициализируем пайплайн, как делали ранее и задаем ему все необходимые параметры:\n\nfrom clearml import PipelineController\n\npipe = PipelineController(\n    name=\"FullPipeline\",\n    project=\"Amazon reviews\",\n    version=\"0.0.1\",\n    packages=[\"./mlops-example\"],\n    docker=\"python:3.11.13-slim-bookworm\",\n    enable_local_imports=True,\n    # working_dir=\"./mlops-example\",\n)\n\npipe.add_parameter(\n    name=\"dataset_name\",\n    description=\"ClearML dataset name\",\n    default=\"Amazon reviews dataset\",\n)\npipe.add_parameter(\n    name=\"dataset_project\",\n    description=\"ClearML project\",\n    default=\"Amazon reviews\",\n)\npipe.add_parameter(\n    name=\"dataset_version\",\n    description=\"ClearML dataset version\",\n    default=\"1.2\",\n)\npipe.add_parameter(\n    name=\"test_size\", description=\"Test ratio size\", default=0.2, param_type=\"float\"\n)\npipe.add_parameter(\n    name=\"random_state\", description=\"Random state\", default=42, param_type=\"int\"\n)\npipe.add_parameter(\n    name=\"max_features\",\n    description=\"Tf-idf features limit\",\n    default=1000,\n    param_type=\"int\",\n)\npipe.add_parameter(\n    name=\"analyzer\",\n    description=\"Tf-idf analyzer\",\n    default=\"word\",\n    param_type=\"str\",\n)\n\nЗададим первый шаг и включим в него весь пайплайн подготовки данных из mlops-example/5.full_pipe.py. В нем указываем base_task_id=\"1ecd1cacb1db4f40a362a67d629fe14f\", которая определит задачу которая должна выполняться на этом шаге, переопределим ее параметры и донастроим. По параметрам, их нужно писать так: Section/Param name, что бы корректно переопределить.\n\npipe.add_step(\n    name=\"data_prepare\",\n    base_task_id=\"1ecd1cacb1db4f40a362a67d629fe14f\",\n    parameter_override={\n        \"Args/dataset_name\": \"${pipeline.dataset_name}\",\n        \"Args/dataset_project\": \"${pipeline.dataset_project}\",\n        \"Args/dataset_version\": \"${pipeline.dataset_version}\",\n        \"Args/random_state\": \"${pipeline.random_state}\",\n        \"Args/test_size\": \"${pipeline.test_size}\",\n    },\n    cache_executed_step=True,\n    execution_queue=\"default\",\n)\nВ результате при выполнении у нас будет запускаться дополнительно этот пайплайн \n\nЗададим шаг на основе mlops-example/3.tf_idf.py, работа с ним описана в 6. clearml_research.md. Точно также указываем base_task_id=\"b5217b5ef85e4e4aa630c672f8177973\" из clearml и переопределяем параметры, а также указываем что следует она после выполнения подпайплайна data_prepare.\n\npipe.add_step(\n    name=\"fit_model\",\n    base_task_id=\"b5217b5ef85e4e4aa630c672f8177973\",\n    parameter_override={\n        \"General/dataset_name\": \"${pipeline.dataset_name}\",\n        \"General/dataset_project\": \"${pipeline.dataset_project}\",\n        \"General/train_dataset_version\": \"${pipeline.dataset_version}.2\",\n        \"General/test_dataset_version\": \"${pipeline.dataset_version}.3\",\n        \"General/dataset_version\": \"${pipeline.dataset_version}.4\",\n        \"General/random_state\": \"${pipeline.random_state}\",\n        \"General/max_features\": \"${pipeline.max_features}\",\n        \"General/analyzer\": \"${pipeline.analyzer}\",\n    },\n    parents=[\"data_prepare\"],\n    cache_executed_step=True,\n    execution_queue=\"default\",\n)\nПосле выполнения подпайплайна data_prepare переходит к выполнению этой задачи. И так у нас есть цельный пайплайн по обработке данных и обучению модели, который мы можем запустить на любой версии данных.",
    "crumbs": [
      "Практика",
      "Расширение ClearML pipelines"
    ]
  },
  {
    "objectID": "7. clearml_reports.html",
    "href": "7. clearml_reports.html",
    "title": "ClearML Reports",
    "section": "",
    "text": "ClearML предоставляет мощные инструменты для создания отчетов о результатах экспериментов. Отчеты позволяют документировать и визуализировать результаты исследований, сравнивать разные эксперименты и делиться выводами с командой.\n\n\n\nCodeLess отчеты на основе залогированных метрик и артефактов\nСравнение экспериментов в табличном или графическом виде\nВстраивание визуализаций (графики, таблицы, изображения)\nВерсионирование отчетов вместе с экспериментами\n\n\n\n\n\n\nСоздание:\n\nВ разделе Reports → Create New Report\nИспользуйте визуальный редактор или Markdown\n\nНаписание отчета\n\nОписывайте постановку задачи/эксперимента/исследования\nПрикладывайте результаты различных экспериментов и описывайте их\nФиксируйте свои наблюдения и предположения\n\nРевью отчета\n\nОбсуждайте результаты с коллегами\nФиксируйте вопросы к отчетам и замечаниям\nПравьте отчет и дополняйте его\nПосле его полной финализации – опубликуйте его",
    "crumbs": [
      "Практика",
      "ClearML Reports"
    ]
  },
  {
    "objectID": "7. clearml_reports.html#основные-возможности-отчетов",
    "href": "7. clearml_reports.html#основные-возможности-отчетов",
    "title": "ClearML Reports",
    "section": "",
    "text": "CodeLess отчеты на основе залогированных метрик и артефактов\nСравнение экспериментов в табличном или графическом виде\nВстраивание визуализаций (графики, таблицы, изображения)\nВерсионирование отчетов вместе с экспериментами",
    "crumbs": [
      "Практика",
      "ClearML Reports"
    ]
  },
  {
    "objectID": "7. clearml_reports.html#работа-с-отчетами-через-веб-интерфейс",
    "href": "7. clearml_reports.html#работа-с-отчетами-через-веб-интерфейс",
    "title": "ClearML Reports",
    "section": "",
    "text": "Создание:\n\nВ разделе Reports → Create New Report\nИспользуйте визуальный редактор или Markdown\n\nНаписание отчета\n\nОписывайте постановку задачи/эксперимента/исследования\nПрикладывайте результаты различных экспериментов и описывайте их\nФиксируйте свои наблюдения и предположения\n\nРевью отчета\n\nОбсуждайте результаты с коллегами\nФиксируйте вопросы к отчетам и замечаниям\nПравьте отчет и дополняйте его\nПосле его полной финализации – опубликуйте его",
    "crumbs": [
      "Практика",
      "ClearML Reports"
    ]
  },
  {
    "objectID": "5. clearml_pipeline.html",
    "href": "5. clearml_pipeline.html",
    "title": "ClearML Pipelines",
    "section": "",
    "text": "Теперь разберем работу с ClearML agent и ClearML pipeline.\n\n\nБыстрый его запуск разобран в 2. clearml_yandex_kube.md, сейчас мы уделим внимание его более детальной настройки и чуть-уть разберем его helm chart.\nВесь перечень параметров представлен в репозитории clearml-helm-charts\n\nСтоит уделить внимание версии самого ClearML-agent, на момент подготовки курса доступна версия 1.9.3, но она не корректно работает с задачами в очереди (см. issue). Поэту ставим специально понижаем версию до последней рабочей.\n\nagentk8sglue:\n  ...\n  extraEnvs:\n  - name: CLEARML_AGENT_UPDATE_VERSION\n    value: \"==1.9.2\"\n\nТакже стоит изменить образ который будет использоваться для запуска задач на нужный вам (возможно кастомный). Опять же советую использовать python не выше 3.11, что бы не возникало проблем с использованием более старых версий библиотек на следующих этапах.\n\nagentk8sglue:\n  ...\n  defaultContainerImage: python:3.11.13-slim-bookworm\n\nВнеся такие изменения вы в целом можете разворачивать его на kubernetes и использовать для выполнения пайплайнов и экспериментов.\n\n\n\n\nClearML позволяет составлять пайплайны, формируя их из существующих задач или прописывая специализированный код используя pipeline SDK. Сейчас мы разберем пример pipeline реализованного с помощью PipelineController, для этого надо посмотреть в файл 2.train_test_split.py, давайте его запустим:\npixi run python mlops-example/2.train_test_split.py\nА пока он исполняется, разберем код пайплайна:\n\nСоздается основной объект пайплайна, ему указывается имя, проект, версия, специальные зависимости, докер образ для исполнения и возможность локального импорта модулей. Далее мы будем работать с этим объектом и его донастраивать.\n\npipe = PipelineController(\n    name=\"DataPrepare\",\n    project=\"Amazon reviews\",\n    version=\"0.0.1\",\n    packages=[\"./mlops-example\", \"numpy==1.26.4\"],\n    docker=\"python:3.11.13-slim-bookworm\",\n    enable_local_imports=True,\n)\n\nПайплайну задаются основные параметры, которые в дальнейшем мы сможем задавать в интерфейсе clearml.\n\npipe.add_parameter(\n    name=\"dataset_name\",\n    description=\"ClearML dataset name\",\n    default=\"Amazon reviews dataset\",\n)\npipe.add_parameter(\n    name=\"dataset_project\",\n    description=\"ClearML project\",\n    default=\"Amazon reviews\",\n)\npipe.add_parameter(\n    name=\"dataset_version\",\n    description=\"ClearML dataset version\",\n    default=\"1.2\",\n)\npipe.add_parameter(\n    name=\"test_size\", description=\"Test ratio size\", default=0.2, param_type=\"float\"\n)\npipe.add_parameter(\n    name=\"random_state\", description=\"Random state\", default=42, param_type=\"int\"\n)\n\n\nДалее описываются функции, которые будут исполняться. Обратит внимание Что основные импорты находятся внутри функции, это позволяет clearml автоматически считать зависимости которые необходимы для работы этого кода, но на практике лучше вручную задавать зависимости для каждого шага, что бы установить корректные версии библиотек. Здесь пример функции которая занимается разделение данные на train и test, и складывает их в новую версию датасета: X.X.1.\n\ndef dataset_train_test_split(\n    dataset_name,\n    dataset_project,\n    dataset_version,\n    test_size,\n    random_state,\n    version_postfix,\n):\n    from pathlib import Path\n\n    import pandas as pd\n    import polars as pl\n    import pyarrow\n    from clearml import Dataset, Logger\n    from sklearn.model_selection import train_test_split\n\n    print(pyarrow.__version__)\n\n    dataset = Dataset.get(\n        dataset_name=dataset_name,\n        dataset_project=dataset_project,\n        dataset_version=dataset_version,\n    )\n    datset_path = Path(dataset.get_local_copy())\n\n    data: pd.DataFrame = pl.concat(\n        [pl.read_csv(data_file) for data_file in datset_path.iterdir()]\n    )\n    train, test = train_test_split(\n        data.to_pandas(), test_size=float(test_size), random_state=int(random_state)\n    )\n    train_distrib = class_distribution(train, \"Polarity\")\n    test_distrib = class_distribution(test, \"Polarity\")\n    result_path = Path(\"data/prepared/split\")\n    result_path.mkdir(exist_ok=True, parents=True)\n    train.to_csv(result_path / \"raw_train.csv\", index=False)\n    test.to_csv(result_path / \"raw_test.csv\", index=False)\n    prepared_dataset = Dataset.create(\n        dataset_name=dataset_name,\n        dataset_project=dataset_project,\n        dataset_version=f\"{dataset_version}.{version_postfix}\",\n        parent_datasets=[dataset],\n    )\n    prepared_dataset.add_files(result_path)\n    prepared_dataset.upload()\n    prepared_dataset.get_logger().report_plotly(\n        \"Class distribution\", \"Train\", train_distrib\n    )\n    prepared_dataset.get_logger().report_plotly(\n        \"Class distribution\", \"Test\", test_distrib\n    )\n    prepared_dataset.finalize()\n\n    pipe_logger = Logger.current_logger()\n    pipe_logger.report_plotly(\"Class distribution\", \"Train\", train_distrib)\n    pipe_logger.report_plotly(\"Class distribution\", \"Test\", test_distrib)\n    return (\n        pl.from_pandas(train, include_index=False),\n        pl.from_pandas(test, include_index=False),\n        prepared_dataset.id,\n    )\n\nДобавляем первый функциональный шаг, указываем его имя, функцию которая его исполняет, ее аргументы, используя параметры pipeline, так же указываем какие артефакты сохранить на этом шаге в качестве возвращаемых значений функции, указываем что этот шаг может быть закеширован, указываем очередь для передачи ее ClearML agent, если вы ее не настраивали, то это default, Так же у нас идут helper fucntions, они нужны что бы код шага корректно сгенерировался, и наконец специфичные зависимости для шага.\n\npipe.add_function_step(\n    name=\"train_test_split\",\n    function=dataset_train_test_split,\n    function_kwargs=dict(\n        dataset_name=\"${pipeline.dataset_name}\",\n        dataset_project=\"${pipeline.dataset_project}\",\n        dataset_version=\"${pipeline.dataset_version}\",\n        test_size=\"${pipeline.test_size}\",\n        random_state=\"${pipeline.random_state}\",\n        version_postfix=\"1\",\n    ),\n    function_return=[\"raw_train_dataframe\", \"raw_test_dataframe\", \"splited_dataset_id\"],\n    cache_executed_step=True,\n    execution_queue=\"default\",\n    helper_functions=[class_distribution],\n    packages=[\n        \"plotly&gt;=6.2.0,&lt;7\",\n        \"plotly-express&gt;=0.4.1,&lt;0.5\",\n        \"clearml-serving&gt;=1.3.5,&lt;2\",\n        \"scikit-learn==1.2.2\",\n        \"numpy==1.26.4\",\n        \"pandas&gt;=2.3.0,&lt;3\",\n        \"polars&gt;=1.31.0,&lt;2\",\n        \"nltk&gt;=3.9.1,&lt;4\",\n        \"pyarrow&gt;=20.0.0,&lt;21\",\n    ],\n)\nЕще стоит сказать про особенность function_step, в нем ваш код будет преобразован в отдельный скрипт который будет исполняться, поэтому есть такие проблемы с import разных библиотек и тд. Вот пример кода для этого шага, который переработал ClearML:\nfrom clearml import Task\nfrom clearml import TaskTypes\nfrom clearml.automation.controller import PipelineDecorator\nimport inspect\n\nfrom clearml.utilities.proxy_object import get_basic_type\n\n\n\n\n\ntry:\n    import pandas as pd\nexcept Exception as e:\n    print('Import error: ' + str(e))\n\ntry:\n    import plotly.express as px\nexcept Exception as e:\n    print('Import error: ' + str(e))\n\ntry:\n    import plotly.graph_objects as go\nexcept Exception as e:\n    print('Import error: ' + str(e))\n\ndef class_distribution(data, target_col):\n    polarity_distribution = data.groupby(target_col, as_index=False).agg(count=pd.NamedAgg(target_col, 'count'))\n    return px.histogram(polarity_distribution, x=target_col, y='count')\n\ntry:\n    from clearml import PipelineController\nexcept Exception as e:\n    print('Import error: ' + str(e))\n\ntry:\n    from mlops_example.preprocessing import dataframe_preprocessing\nexcept Exception as e:\n    print('Import error: ' + str(e))\n\ntry:\n    from mlops_example.preprocessing import lemmatize\nexcept Exception as e:\n    print('Import error: ' + str(e))\n\ntry:\n    from mlops_example.preprocessing import text_preprocessing\nexcept Exception as e:\n    print('Import error: ' + str(e))\n\ntry:\n    from mlops_example.visualisation import class_distribution\nexcept Exception as e:\n    print('Import error: ' + str(e))\n\ndef dataset_train_test_split(dataset_name, dataset_project, dataset_version, test_size, random_state, version_postfix):\n    from pathlib import Path\n    import pandas as pd\n    import polars as pl\n    import pyarrow\n    from clearml import Dataset, Logger\n    from sklearn.model_selection import train_test_split\n    print(pyarrow.__version__)\n    dataset = Dataset.get(dataset_name=dataset_name, dataset_project=dataset_project, dataset_version=dataset_version)\n    datset_path = Path(dataset.get_local_copy())\n    data: pd.DataFrame = pl.concat([pl.read_csv(data_file) for data_file in datset_path.iterdir()])\n    train, test = train_test_split(data.to_pandas(), test_size=float(test_size), random_state=int(random_state))\n    train_distrib = class_distribution(train, 'Polarity')\n    test_distrib = class_distribution(test, 'Polarity')\n    result_path = Path('data/prepared/split')\n    result_path.mkdir(exist_ok=True, parents=True)\n    train.to_csv(result_path / 'raw_train.csv', index=False)\n    test.to_csv(result_path / 'raw_test.csv', index=False)\n    prepared_dataset = Dataset.create(dataset_name=dataset_name, dataset_project=dataset_project, dataset_version=f'{dataset_version}.{version_postfix}', parent_datasets=[dataset])\n    prepared_dataset.add_files(result_path)\n    prepared_dataset.upload()\n    prepared_dataset.get_logger().report_plotly('Class distribution', 'Train', train_distrib)\n    prepared_dataset.get_logger().report_plotly('Class distribution', 'Test', test_distrib)\n    prepared_dataset.finalize()\n    pipe_logger = Logger.current_logger()\n    pipe_logger.report_plotly('Class distribution', 'Train', train_distrib)\n    pipe_logger.report_plotly('Class distribution', 'Test', test_distrib)\n    return (pl.from_pandas(train, include_index=False), pl.from_pandas(test, include_index=False), prepared_dataset.id)\n\nif __name__ == '__main__':\n    task = Task.init(\n        auto_connect_frameworks=True,\n        auto_connect_arg_parser=True,\n    )\n    kwargs = {'dataset_name': '${pipeline.dataset_name}', 'dataset_project': '${pipeline.dataset_project}', 'dataset_version': '${pipeline.dataset_version}', 'test_size': '${pipeline.test_size}', 'random_state': '${pipeline.random_state}', 'version_postfix': '1'}\n    task.connect(kwargs, name='kwargs')\n    function_input_artifacts = {}\n    params = task.get_parameters(cast=True) or dict()\n    argspec = inspect.getfullargspec(dataset_train_test_split)\n    if argspec.varkw is not None or argspec.varargs is not None:\n        for k, v in params.items():\n            if k.startswith('kwargs/'):\n                kwargs[k.replace('kwargs/', '', 1)] = v\n    return_section = 'return'\n    for k, v in params.items():\n        if not v or not k.startswith('kwargs_artifacts/'):\n            continue\n        k = k.replace('kwargs_artifacts/', '', 1)\n        task_id, artifact_name = v.split('.', 1)\n        parent_task = Task.get_task(task_id=task_id)\n        if artifact_name in parent_task.artifacts:\n            kwargs[k] = parent_task.artifacts[artifact_name].get(deserialization_function=None)\n        else:\n            kwargs[k] = parent_task.get_parameters(cast=True).get(return_section + '/' + artifact_name)\n    if '0' in kwargs:  # *args arguments are present\n        pos_args = [kwargs.pop(arg, None) for arg in (argspec.args or [])]\n        other_pos_args_index = 0\n        while str(other_pos_args_index) in kwargs:\n            pos_args.append(kwargs.pop(str(other_pos_args_index)))\n            other_pos_args_index += 1\n        results = dataset_train_test_split(*pos_args, **kwargs)\n    else:\n        results = dataset_train_test_split(**kwargs)\n    result_names = ['raw_train_dataframe', 'raw_test_dataframe', 'splited_dataset_id']\n    if result_names:\n        if not isinstance(results, (tuple, list)) or len(result_names) == 1:\n            results = [results]\n        parameters = dict()\n        parameters_types = dict()\n        for name, artifact in zip(result_names, results):\n            if type(artifact) in (float, int, bool, str):\n                parameters[return_section + '/' + name] = artifact\n                parameters_types[return_section + '/' + name] = get_basic_type(artifact)\n            else:\n                task.upload_artifact(\n                    name=name,\n                    artifact_object=artifact,\n                    extension_name='.pkl' if isinstance(artifact, dict) else None,\n                    serialization_function=None\n                )\n        if parameters:\n            task._set_parameters(parameters, __parameters_types=parameters_types, __update=True)\n\nПрописываем все функцию для препроцессинга данных с помощью nltk.\n\ndef dataset_preprocessing(\n    dataframe,\n    parent_dataset,\n    dataset_name,\n    dataset_project,\n    dataset_version,\n    version_postfix,\n    frame_name,\n):\n    from pathlib import Path\n\n    import nltk\n    import polars as pl\n    import pyarrow\n    from clearml import Dataset\n\n    print(pyarrow.__version__)\n\n    nltk.download(\"stopwords\")\n    nltk.download(\"wordnet\")\n\n    prepared_dataset = Dataset.create(\n        dataset_name=dataset_name,\n        dataset_project=dataset_project,\n        dataset_version=f\"{dataset_version}.{version_postfix}\",\n        parent_datasets=[parent_dataset],\n    )\n    dataframe: pl.DataFrame\n    processed_dataframe = dataframe_preprocessing(dataframe, \"Review\")\n\n    result_path = Path(\"data/prepared/processed\")\n    result_path.mkdir(exist_ok=True, parents=True)\n    processed_dataframe.write_parquet(result_path / f\"processed_{frame_name}.parquet\")\n\n    prepared_dataset.add_files(result_path)\n    prepared_dataset.upload()\n    prepared_dataset.finalize()\n    return processed_dataframe, prepared_dataset.id\n\nИ задаем для нее два шага, для обработки обучающей и тестовой выборок. Можно заметить что в параметризации функции у нас также используются и сохраненные артефакты шагаtrain_test_split, а также появился параметр parents, позволяющий строить пайплайн. Кстати, эти шаги будут выполняться паралельно.\n\npipe.add_function_step(\n    name=\"train_processing\",\n    function=dataset_preprocessing,\n    function_kwargs=dict(\n        dataframe=\"${train_test_split.raw_train_dataframe}\",\n        parent_dataset=\"${train_test_split.splited_dataset_id}\",\n        dataset_name=\"${pipeline.dataset_name}\",\n        dataset_project=\"${pipeline.dataset_project}\",\n        dataset_version=\"${pipeline.dataset_version}\",\n        version_postfix=\"2\",\n        frame_name=\"train\",\n    ),\n    function_return=[\"processed_train_dataframe\", \"dataset_id\"],\n    cache_executed_step=True,\n    execution_queue=\"default\",\n    helper_functions=[lemmatize, dataframe_preprocessing, text_preprocessing],\n    parents=[\"train_test_split\"],\n    packages=[\n        \"plotly&gt;=6.2.0,&lt;7\",\n        \"plotly-express&gt;=0.4.1,&lt;0.5\",\n        \"clearml-serving&gt;=1.3.5,&lt;2\",\n        \"scikit-learn==1.2.2\",\n        \"numpy==1.26.4\",\n        \"pandas&gt;=2.3.0,&lt;3\",\n        \"polars&gt;=1.31.0,&lt;2\",\n        \"nltk&gt;=3.9.1,&lt;4\",\n        \"pyarrow&gt;=20.0.0,&lt;21\",\n    ],\n)\n\npipe.add_function_step(\n    name=\"test_processing\",\n    function=dataset_preprocessing,\n    function_kwargs=dict(\n        dataframe=\"${train_test_split.raw_test_dataframe}\",\n        parent_dataset=\"${train_test_split.splited_dataset_id}\",\n        dataset_name=\"${pipeline.dataset_name}\",\n        dataset_project=\"${pipeline.dataset_project}\",\n        dataset_version=\"${pipeline.dataset_version}\",\n        version_postfix=\"3\",\n        frame_name=\"test\",\n    ),\n    function_return=[\"processed_test_dataframe\", \"dataset_id\"],\n    cache_executed_step=True,\n    execution_queue=\"default\",\n    helper_functions=[lemmatize, dataframe_preprocessing, text_preprocessing],\n    parents=[\"train_test_split\"],\n    packages=[\n        \"plotly&gt;=6.2.0,&lt;7\",\n        \"plotly-express&gt;=0.4.1,&lt;0.5\",\n        \"clearml-serving&gt;=1.3.5,&lt;2\",\n        \"scikit-learn==1.2.2\",\n        \"numpy==1.26.4\",\n        \"pandas&gt;=2.3.0,&lt;3\",\n        \"polars&gt;=1.31.0,&lt;2\",\n        \"nltk&gt;=3.9.1,&lt;4\",\n        \"pyarrow&gt;=20.0.0,&lt;21\",\n    ],\n)\n\nТеперь непосредственно команда запуска. Есть два варианта запуска start и start_locally.Первая (start) запускает сборку и исполнение pipeline на стороне агента, то есть агент установит окружение пайплайна и начнемт подготовку кода для каждого из шагов, затем непосредсвенно начнет выполнение шагов. По сути это не блокирующая команда которая направляет задачу агенту и он ее выполняет. Второй вариант start_locally позволяет сконфигурировать пайплайн локлаьно и только шаги исполнить удаленно, но если указать start_locally(run_pipeline_steps_locally=True), то и шаги пайплайна будут исполнены локально, что может быть удобно для дебага.\n\npipe.start()\nВы можете перейти в clearml и увидеть что ваш pipeline выполняется:  Посмотреть его логи можно в поде clearml-id-xxxxxxx:  Или в консоле пайплайна.\n\nКогда пайплайн завершился, можно посотреть всю инфомрацию о нем: настройки, изменения, заисимости, артефакты и тд.     \nТеперь мы легко можем запускать этот пайплайн для других верси датасета, для этого надо клинкнуть по нему пкм и надать run, тогда появится окно задания настрое, напрмиер поставим версию 1.3.   В процессе вы увидите что у вас динамически создаются worker для обработки шагов пайплайна",
    "crumbs": [
      "Практика",
      "ClearML Pipelines"
    ]
  },
  {
    "objectID": "5. clearml_pipeline.html#настойка-clearml-agent",
    "href": "5. clearml_pipeline.html#настойка-clearml-agent",
    "title": "ClearML Pipelines",
    "section": "",
    "text": "Быстрый его запуск разобран в 2. clearml_yandex_kube.md, сейчас мы уделим внимание его более детальной настройки и чуть-уть разберем его helm chart.\nВесь перечень параметров представлен в репозитории clearml-helm-charts\n\nСтоит уделить внимание версии самого ClearML-agent, на момент подготовки курса доступна версия 1.9.3, но она не корректно работает с задачами в очереди (см. issue). Поэту ставим специально понижаем версию до последней рабочей.\n\nagentk8sglue:\n  ...\n  extraEnvs:\n  - name: CLEARML_AGENT_UPDATE_VERSION\n    value: \"==1.9.2\"\n\nТакже стоит изменить образ который будет использоваться для запуска задач на нужный вам (возможно кастомный). Опять же советую использовать python не выше 3.11, что бы не возникало проблем с использованием более старых версий библиотек на следующих этапах.\n\nagentk8sglue:\n  ...\n  defaultContainerImage: python:3.11.13-slim-bookworm\n\nВнеся такие изменения вы в целом можете разворачивать его на kubernetes и использовать для выполнения пайплайнов и экспериментов.",
    "crumbs": [
      "Практика",
      "ClearML Pipelines"
    ]
  },
  {
    "objectID": "5. clearml_pipeline.html#clearml-pipeline",
    "href": "5. clearml_pipeline.html#clearml-pipeline",
    "title": "ClearML Pipelines",
    "section": "",
    "text": "ClearML позволяет составлять пайплайны, формируя их из существующих задач или прописывая специализированный код используя pipeline SDK. Сейчас мы разберем пример pipeline реализованного с помощью PipelineController, для этого надо посмотреть в файл 2.train_test_split.py, давайте его запустим:\npixi run python mlops-example/2.train_test_split.py\nА пока он исполняется, разберем код пайплайна:\n\nСоздается основной объект пайплайна, ему указывается имя, проект, версия, специальные зависимости, докер образ для исполнения и возможность локального импорта модулей. Далее мы будем работать с этим объектом и его донастраивать.\n\npipe = PipelineController(\n    name=\"DataPrepare\",\n    project=\"Amazon reviews\",\n    version=\"0.0.1\",\n    packages=[\"./mlops-example\", \"numpy==1.26.4\"],\n    docker=\"python:3.11.13-slim-bookworm\",\n    enable_local_imports=True,\n)\n\nПайплайну задаются основные параметры, которые в дальнейшем мы сможем задавать в интерфейсе clearml.\n\npipe.add_parameter(\n    name=\"dataset_name\",\n    description=\"ClearML dataset name\",\n    default=\"Amazon reviews dataset\",\n)\npipe.add_parameter(\n    name=\"dataset_project\",\n    description=\"ClearML project\",\n    default=\"Amazon reviews\",\n)\npipe.add_parameter(\n    name=\"dataset_version\",\n    description=\"ClearML dataset version\",\n    default=\"1.2\",\n)\npipe.add_parameter(\n    name=\"test_size\", description=\"Test ratio size\", default=0.2, param_type=\"float\"\n)\npipe.add_parameter(\n    name=\"random_state\", description=\"Random state\", default=42, param_type=\"int\"\n)\n\n\nДалее описываются функции, которые будут исполняться. Обратит внимание Что основные импорты находятся внутри функции, это позволяет clearml автоматически считать зависимости которые необходимы для работы этого кода, но на практике лучше вручную задавать зависимости для каждого шага, что бы установить корректные версии библиотек. Здесь пример функции которая занимается разделение данные на train и test, и складывает их в новую версию датасета: X.X.1.\n\ndef dataset_train_test_split(\n    dataset_name,\n    dataset_project,\n    dataset_version,\n    test_size,\n    random_state,\n    version_postfix,\n):\n    from pathlib import Path\n\n    import pandas as pd\n    import polars as pl\n    import pyarrow\n    from clearml import Dataset, Logger\n    from sklearn.model_selection import train_test_split\n\n    print(pyarrow.__version__)\n\n    dataset = Dataset.get(\n        dataset_name=dataset_name,\n        dataset_project=dataset_project,\n        dataset_version=dataset_version,\n    )\n    datset_path = Path(dataset.get_local_copy())\n\n    data: pd.DataFrame = pl.concat(\n        [pl.read_csv(data_file) for data_file in datset_path.iterdir()]\n    )\n    train, test = train_test_split(\n        data.to_pandas(), test_size=float(test_size), random_state=int(random_state)\n    )\n    train_distrib = class_distribution(train, \"Polarity\")\n    test_distrib = class_distribution(test, \"Polarity\")\n    result_path = Path(\"data/prepared/split\")\n    result_path.mkdir(exist_ok=True, parents=True)\n    train.to_csv(result_path / \"raw_train.csv\", index=False)\n    test.to_csv(result_path / \"raw_test.csv\", index=False)\n    prepared_dataset = Dataset.create(\n        dataset_name=dataset_name,\n        dataset_project=dataset_project,\n        dataset_version=f\"{dataset_version}.{version_postfix}\",\n        parent_datasets=[dataset],\n    )\n    prepared_dataset.add_files(result_path)\n    prepared_dataset.upload()\n    prepared_dataset.get_logger().report_plotly(\n        \"Class distribution\", \"Train\", train_distrib\n    )\n    prepared_dataset.get_logger().report_plotly(\n        \"Class distribution\", \"Test\", test_distrib\n    )\n    prepared_dataset.finalize()\n\n    pipe_logger = Logger.current_logger()\n    pipe_logger.report_plotly(\"Class distribution\", \"Train\", train_distrib)\n    pipe_logger.report_plotly(\"Class distribution\", \"Test\", test_distrib)\n    return (\n        pl.from_pandas(train, include_index=False),\n        pl.from_pandas(test, include_index=False),\n        prepared_dataset.id,\n    )\n\nДобавляем первый функциональный шаг, указываем его имя, функцию которая его исполняет, ее аргументы, используя параметры pipeline, так же указываем какие артефакты сохранить на этом шаге в качестве возвращаемых значений функции, указываем что этот шаг может быть закеширован, указываем очередь для передачи ее ClearML agent, если вы ее не настраивали, то это default, Так же у нас идут helper fucntions, они нужны что бы код шага корректно сгенерировался, и наконец специфичные зависимости для шага.\n\npipe.add_function_step(\n    name=\"train_test_split\",\n    function=dataset_train_test_split,\n    function_kwargs=dict(\n        dataset_name=\"${pipeline.dataset_name}\",\n        dataset_project=\"${pipeline.dataset_project}\",\n        dataset_version=\"${pipeline.dataset_version}\",\n        test_size=\"${pipeline.test_size}\",\n        random_state=\"${pipeline.random_state}\",\n        version_postfix=\"1\",\n    ),\n    function_return=[\"raw_train_dataframe\", \"raw_test_dataframe\", \"splited_dataset_id\"],\n    cache_executed_step=True,\n    execution_queue=\"default\",\n    helper_functions=[class_distribution],\n    packages=[\n        \"plotly&gt;=6.2.0,&lt;7\",\n        \"plotly-express&gt;=0.4.1,&lt;0.5\",\n        \"clearml-serving&gt;=1.3.5,&lt;2\",\n        \"scikit-learn==1.2.2\",\n        \"numpy==1.26.4\",\n        \"pandas&gt;=2.3.0,&lt;3\",\n        \"polars&gt;=1.31.0,&lt;2\",\n        \"nltk&gt;=3.9.1,&lt;4\",\n        \"pyarrow&gt;=20.0.0,&lt;21\",\n    ],\n)\nЕще стоит сказать про особенность function_step, в нем ваш код будет преобразован в отдельный скрипт который будет исполняться, поэтому есть такие проблемы с import разных библиотек и тд. Вот пример кода для этого шага, который переработал ClearML:\nfrom clearml import Task\nfrom clearml import TaskTypes\nfrom clearml.automation.controller import PipelineDecorator\nimport inspect\n\nfrom clearml.utilities.proxy_object import get_basic_type\n\n\n\n\n\ntry:\n    import pandas as pd\nexcept Exception as e:\n    print('Import error: ' + str(e))\n\ntry:\n    import plotly.express as px\nexcept Exception as e:\n    print('Import error: ' + str(e))\n\ntry:\n    import plotly.graph_objects as go\nexcept Exception as e:\n    print('Import error: ' + str(e))\n\ndef class_distribution(data, target_col):\n    polarity_distribution = data.groupby(target_col, as_index=False).agg(count=pd.NamedAgg(target_col, 'count'))\n    return px.histogram(polarity_distribution, x=target_col, y='count')\n\ntry:\n    from clearml import PipelineController\nexcept Exception as e:\n    print('Import error: ' + str(e))\n\ntry:\n    from mlops_example.preprocessing import dataframe_preprocessing\nexcept Exception as e:\n    print('Import error: ' + str(e))\n\ntry:\n    from mlops_example.preprocessing import lemmatize\nexcept Exception as e:\n    print('Import error: ' + str(e))\n\ntry:\n    from mlops_example.preprocessing import text_preprocessing\nexcept Exception as e:\n    print('Import error: ' + str(e))\n\ntry:\n    from mlops_example.visualisation import class_distribution\nexcept Exception as e:\n    print('Import error: ' + str(e))\n\ndef dataset_train_test_split(dataset_name, dataset_project, dataset_version, test_size, random_state, version_postfix):\n    from pathlib import Path\n    import pandas as pd\n    import polars as pl\n    import pyarrow\n    from clearml import Dataset, Logger\n    from sklearn.model_selection import train_test_split\n    print(pyarrow.__version__)\n    dataset = Dataset.get(dataset_name=dataset_name, dataset_project=dataset_project, dataset_version=dataset_version)\n    datset_path = Path(dataset.get_local_copy())\n    data: pd.DataFrame = pl.concat([pl.read_csv(data_file) for data_file in datset_path.iterdir()])\n    train, test = train_test_split(data.to_pandas(), test_size=float(test_size), random_state=int(random_state))\n    train_distrib = class_distribution(train, 'Polarity')\n    test_distrib = class_distribution(test, 'Polarity')\n    result_path = Path('data/prepared/split')\n    result_path.mkdir(exist_ok=True, parents=True)\n    train.to_csv(result_path / 'raw_train.csv', index=False)\n    test.to_csv(result_path / 'raw_test.csv', index=False)\n    prepared_dataset = Dataset.create(dataset_name=dataset_name, dataset_project=dataset_project, dataset_version=f'{dataset_version}.{version_postfix}', parent_datasets=[dataset])\n    prepared_dataset.add_files(result_path)\n    prepared_dataset.upload()\n    prepared_dataset.get_logger().report_plotly('Class distribution', 'Train', train_distrib)\n    prepared_dataset.get_logger().report_plotly('Class distribution', 'Test', test_distrib)\n    prepared_dataset.finalize()\n    pipe_logger = Logger.current_logger()\n    pipe_logger.report_plotly('Class distribution', 'Train', train_distrib)\n    pipe_logger.report_plotly('Class distribution', 'Test', test_distrib)\n    return (pl.from_pandas(train, include_index=False), pl.from_pandas(test, include_index=False), prepared_dataset.id)\n\nif __name__ == '__main__':\n    task = Task.init(\n        auto_connect_frameworks=True,\n        auto_connect_arg_parser=True,\n    )\n    kwargs = {'dataset_name': '${pipeline.dataset_name}', 'dataset_project': '${pipeline.dataset_project}', 'dataset_version': '${pipeline.dataset_version}', 'test_size': '${pipeline.test_size}', 'random_state': '${pipeline.random_state}', 'version_postfix': '1'}\n    task.connect(kwargs, name='kwargs')\n    function_input_artifacts = {}\n    params = task.get_parameters(cast=True) or dict()\n    argspec = inspect.getfullargspec(dataset_train_test_split)\n    if argspec.varkw is not None or argspec.varargs is not None:\n        for k, v in params.items():\n            if k.startswith('kwargs/'):\n                kwargs[k.replace('kwargs/', '', 1)] = v\n    return_section = 'return'\n    for k, v in params.items():\n        if not v or not k.startswith('kwargs_artifacts/'):\n            continue\n        k = k.replace('kwargs_artifacts/', '', 1)\n        task_id, artifact_name = v.split('.', 1)\n        parent_task = Task.get_task(task_id=task_id)\n        if artifact_name in parent_task.artifacts:\n            kwargs[k] = parent_task.artifacts[artifact_name].get(deserialization_function=None)\n        else:\n            kwargs[k] = parent_task.get_parameters(cast=True).get(return_section + '/' + artifact_name)\n    if '0' in kwargs:  # *args arguments are present\n        pos_args = [kwargs.pop(arg, None) for arg in (argspec.args or [])]\n        other_pos_args_index = 0\n        while str(other_pos_args_index) in kwargs:\n            pos_args.append(kwargs.pop(str(other_pos_args_index)))\n            other_pos_args_index += 1\n        results = dataset_train_test_split(*pos_args, **kwargs)\n    else:\n        results = dataset_train_test_split(**kwargs)\n    result_names = ['raw_train_dataframe', 'raw_test_dataframe', 'splited_dataset_id']\n    if result_names:\n        if not isinstance(results, (tuple, list)) or len(result_names) == 1:\n            results = [results]\n        parameters = dict()\n        parameters_types = dict()\n        for name, artifact in zip(result_names, results):\n            if type(artifact) in (float, int, bool, str):\n                parameters[return_section + '/' + name] = artifact\n                parameters_types[return_section + '/' + name] = get_basic_type(artifact)\n            else:\n                task.upload_artifact(\n                    name=name,\n                    artifact_object=artifact,\n                    extension_name='.pkl' if isinstance(artifact, dict) else None,\n                    serialization_function=None\n                )\n        if parameters:\n            task._set_parameters(parameters, __parameters_types=parameters_types, __update=True)\n\nПрописываем все функцию для препроцессинга данных с помощью nltk.\n\ndef dataset_preprocessing(\n    dataframe,\n    parent_dataset,\n    dataset_name,\n    dataset_project,\n    dataset_version,\n    version_postfix,\n    frame_name,\n):\n    from pathlib import Path\n\n    import nltk\n    import polars as pl\n    import pyarrow\n    from clearml import Dataset\n\n    print(pyarrow.__version__)\n\n    nltk.download(\"stopwords\")\n    nltk.download(\"wordnet\")\n\n    prepared_dataset = Dataset.create(\n        dataset_name=dataset_name,\n        dataset_project=dataset_project,\n        dataset_version=f\"{dataset_version}.{version_postfix}\",\n        parent_datasets=[parent_dataset],\n    )\n    dataframe: pl.DataFrame\n    processed_dataframe = dataframe_preprocessing(dataframe, \"Review\")\n\n    result_path = Path(\"data/prepared/processed\")\n    result_path.mkdir(exist_ok=True, parents=True)\n    processed_dataframe.write_parquet(result_path / f\"processed_{frame_name}.parquet\")\n\n    prepared_dataset.add_files(result_path)\n    prepared_dataset.upload()\n    prepared_dataset.finalize()\n    return processed_dataframe, prepared_dataset.id\n\nИ задаем для нее два шага, для обработки обучающей и тестовой выборок. Можно заметить что в параметризации функции у нас также используются и сохраненные артефакты шагаtrain_test_split, а также появился параметр parents, позволяющий строить пайплайн. Кстати, эти шаги будут выполняться паралельно.\n\npipe.add_function_step(\n    name=\"train_processing\",\n    function=dataset_preprocessing,\n    function_kwargs=dict(\n        dataframe=\"${train_test_split.raw_train_dataframe}\",\n        parent_dataset=\"${train_test_split.splited_dataset_id}\",\n        dataset_name=\"${pipeline.dataset_name}\",\n        dataset_project=\"${pipeline.dataset_project}\",\n        dataset_version=\"${pipeline.dataset_version}\",\n        version_postfix=\"2\",\n        frame_name=\"train\",\n    ),\n    function_return=[\"processed_train_dataframe\", \"dataset_id\"],\n    cache_executed_step=True,\n    execution_queue=\"default\",\n    helper_functions=[lemmatize, dataframe_preprocessing, text_preprocessing],\n    parents=[\"train_test_split\"],\n    packages=[\n        \"plotly&gt;=6.2.0,&lt;7\",\n        \"plotly-express&gt;=0.4.1,&lt;0.5\",\n        \"clearml-serving&gt;=1.3.5,&lt;2\",\n        \"scikit-learn==1.2.2\",\n        \"numpy==1.26.4\",\n        \"pandas&gt;=2.3.0,&lt;3\",\n        \"polars&gt;=1.31.0,&lt;2\",\n        \"nltk&gt;=3.9.1,&lt;4\",\n        \"pyarrow&gt;=20.0.0,&lt;21\",\n    ],\n)\n\npipe.add_function_step(\n    name=\"test_processing\",\n    function=dataset_preprocessing,\n    function_kwargs=dict(\n        dataframe=\"${train_test_split.raw_test_dataframe}\",\n        parent_dataset=\"${train_test_split.splited_dataset_id}\",\n        dataset_name=\"${pipeline.dataset_name}\",\n        dataset_project=\"${pipeline.dataset_project}\",\n        dataset_version=\"${pipeline.dataset_version}\",\n        version_postfix=\"3\",\n        frame_name=\"test\",\n    ),\n    function_return=[\"processed_test_dataframe\", \"dataset_id\"],\n    cache_executed_step=True,\n    execution_queue=\"default\",\n    helper_functions=[lemmatize, dataframe_preprocessing, text_preprocessing],\n    parents=[\"train_test_split\"],\n    packages=[\n        \"plotly&gt;=6.2.0,&lt;7\",\n        \"plotly-express&gt;=0.4.1,&lt;0.5\",\n        \"clearml-serving&gt;=1.3.5,&lt;2\",\n        \"scikit-learn==1.2.2\",\n        \"numpy==1.26.4\",\n        \"pandas&gt;=2.3.0,&lt;3\",\n        \"polars&gt;=1.31.0,&lt;2\",\n        \"nltk&gt;=3.9.1,&lt;4\",\n        \"pyarrow&gt;=20.0.0,&lt;21\",\n    ],\n)\n\nТеперь непосредственно команда запуска. Есть два варианта запуска start и start_locally.Первая (start) запускает сборку и исполнение pipeline на стороне агента, то есть агент установит окружение пайплайна и начнемт подготовку кода для каждого из шагов, затем непосредсвенно начнет выполнение шагов. По сути это не блокирующая команда которая направляет задачу агенту и он ее выполняет. Второй вариант start_locally позволяет сконфигурировать пайплайн локлаьно и только шаги исполнить удаленно, но если указать start_locally(run_pipeline_steps_locally=True), то и шаги пайплайна будут исполнены локально, что может быть удобно для дебага.\n\npipe.start()\nВы можете перейти в clearml и увидеть что ваш pipeline выполняется:  Посмотреть его логи можно в поде clearml-id-xxxxxxx:  Или в консоле пайплайна.\n\nКогда пайплайн завершился, можно посотреть всю инфомрацию о нем: настройки, изменения, заисимости, артефакты и тд.     \nТеперь мы легко можем запускать этот пайплайн для других верси датасета, для этого надо клинкнуть по нему пкм и надать run, тогда появится окно задания настрое, напрмиер поставим версию 1.3.   В процессе вы увидите что у вас динамически создаются worker для обработки шагов пайплайна",
    "crumbs": [
      "Практика",
      "ClearML Pipelines"
    ]
  },
  {
    "objectID": "3. clearml_work.html",
    "href": "3. clearml_work.html",
    "title": "Работа с ClearML",
    "section": "",
    "text": "Для начала зайдите на свой ClearML, в примере он развернут на http://51.250.106.18:30080/. Его адрес можно найти в информации об узле на котором развернут pod: \nЗайдите в Settings -&gt; Workspace и там нажмите Create new credentials: \nВам покажется модельное окно с сгенерированными credentials, выполните инструкцию написанную в нем: скопируйте текст credentials в ~/clearml.conf:\napi {\n    web_server:http://51.250.106.18:30080/\n    api_server:http://51.250.106.18:30008\n    files_server:http://51.250.106.18:30081\n    credentials {\n        \"access_key\"=\"ACCESSKEY\"\n        \"secret_key\"=\"SECRETKEY\"\n    }\n}\nОсталось установить библиотеку clearml для полноценной работы.\n\n\n\nДля примера использовался пакетный менеджер pixi, что бы его установить выполните команду:\necho PIXI_VERSION=0.48.2 && curl -fsSL https://pixi.sh/install.sh | sh\nПоскольку инструмент еще на стадии активной разработки то меду версиями могут быть различия и breaking changes, поэтому обратите внимание на версию 0.48.2.\nПосле успешной установки перейдите в папку mlops-example и выполните команду:\npixi install -a\nСразу обращу внимание, что не стоит гнаться за последними версиями библиотек. Ограничитесь python==3.11, scikit-learn==1.2.2, numpy==1.26.4. Это важно потому что на шагах связанных с разверткой моделей у вас могут появиться не состыковки по версиям поддерживаемых зависимостей и придется или менять версии библиотек в ваших экспериментах (как это было при подготовке примера), или собирать свои кастомные образы для serving’а моделей с обновленными зависимостями.\nДля дальнейшей работы в окружении вы можете выполнить команду pixi shell или каждую команду начинать с pixi run ...",
    "crumbs": [
      "Практика",
      "Работа с ClearML"
    ]
  },
  {
    "objectID": "3. clearml_work.html#настройка-clearml",
    "href": "3. clearml_work.html#настройка-clearml",
    "title": "Работа с ClearML",
    "section": "",
    "text": "Для начала зайдите на свой ClearML, в примере он развернут на http://51.250.106.18:30080/. Его адрес можно найти в информации об узле на котором развернут pod: \nЗайдите в Settings -&gt; Workspace и там нажмите Create new credentials: \nВам покажется модельное окно с сгенерированными credentials, выполните инструкцию написанную в нем: скопируйте текст credentials в ~/clearml.conf:\napi {\n    web_server:http://51.250.106.18:30080/\n    api_server:http://51.250.106.18:30008\n    files_server:http://51.250.106.18:30081\n    credentials {\n        \"access_key\"=\"ACCESSKEY\"\n        \"secret_key\"=\"SECRETKEY\"\n    }\n}\nОсталось установить библиотеку clearml для полноценной работы.",
    "crumbs": [
      "Практика",
      "Работа с ClearML"
    ]
  },
  {
    "objectID": "3. clearml_work.html#настройка-окружения-mlops-example",
    "href": "3. clearml_work.html#настройка-окружения-mlops-example",
    "title": "Работа с ClearML",
    "section": "",
    "text": "Для примера использовался пакетный менеджер pixi, что бы его установить выполните команду:\necho PIXI_VERSION=0.48.2 && curl -fsSL https://pixi.sh/install.sh | sh\nПоскольку инструмент еще на стадии активной разработки то меду версиями могут быть различия и breaking changes, поэтому обратите внимание на версию 0.48.2.\nПосле успешной установки перейдите в папку mlops-example и выполните команду:\npixi install -a\nСразу обращу внимание, что не стоит гнаться за последними версиями библиотек. Ограничитесь python==3.11, scikit-learn==1.2.2, numpy==1.26.4. Это важно потому что на шагах связанных с разверткой моделей у вас могут появиться не состыковки по версиям поддерживаемых зависимостей и придется или менять версии библиотек в ваших экспериментах (как это было при подготовке примера), или собирать свои кастомные образы для serving’а моделей с обновленными зависимостями.\nДля дальнейшей работы в окружении вы можете выполнить команду pixi shell или каждую команду начинать с pixi run ...",
    "crumbs": [
      "Практика",
      "Работа с ClearML"
    ]
  },
  {
    "objectID": "1. yandex_kube.html",
    "href": "1. yandex_kube.html",
    "title": "Настройка Yandex Kubernetes",
    "section": "",
    "text": "Общая инструкция по настройке Yandex Kubernetes\n\n\nСоздайте кластер вот с такой конфигурацией: \nСоздайте В нем группу узлов вот с такой конфигурацией: \n\n\n\nИнструкция по установке от yandex\nСкачайте скрипт установки и запустите:\ncurl -sSL https://storage.yandexcloud.net/yandexcloud-yc/install.sh | bash\nПолучите ваш OauthToken и задайте его yc.\nyc config set token &lt;OAuth-токен&gt;\n\n\n\nИнструкция по установке от Kubernetes\nСкачайте к себе собранный бинарник kubectl\ncurl -LO https://dl.k8s.io/release/v1.33.0/bin/linux/amd64/kubectl\nИзмените права для исполнения kubectl\nchmod +x ./kubectl\nПереместите его в системную папку bin\nsudo mv ./kubectl /usr/local/bin/kubectl\n\n\n\nНастройте доступ к kubectl к кластеру\nyc managed-kubernetes cluster get-credentials --id &lt;Cluster ID&gt; --external\n\nПроверьте что все работает\nkubectl config view\nили\nkubectl get nodes\n\n\n\nСкачайте скрипт установки (см инструкцию helm)\ncurl -fsSL -o get_helm.sh https://raw.githubusercontent.com/helm/helm/main/scripts/get-helm-3\nИзмените права для запуска\nchmod 700 get_helm.sh\nЗапустите установку\n./get_helm.sh\n\n\n\nЧто бы подключить helm к yc выполните команду, воспользуйтесь своим OauthToken\nhelm registry login registry.yandexcloud.net -u oauth\nPassword: &lt;OAuth-токен&gt;",
    "crumbs": [
      "Практика",
      "Настройка Yandex Kubernetes"
    ]
  },
  {
    "objectID": "1. yandex_kube.html#создание-кластера-kubernetes",
    "href": "1. yandex_kube.html#создание-кластера-kubernetes",
    "title": "Настройка Yandex Kubernetes",
    "section": "",
    "text": "Создайте кластер вот с такой конфигурацией: \nСоздайте В нем группу узлов вот с такой конфигурацией:",
    "crumbs": [
      "Практика",
      "Настройка Yandex Kubernetes"
    ]
  },
  {
    "objectID": "1. yandex_kube.html#установка-yc",
    "href": "1. yandex_kube.html#установка-yc",
    "title": "Настройка Yandex Kubernetes",
    "section": "",
    "text": "Инструкция по установке от yandex\nСкачайте скрипт установки и запустите:\ncurl -sSL https://storage.yandexcloud.net/yandexcloud-yc/install.sh | bash\nПолучите ваш OauthToken и задайте его yc.\nyc config set token &lt;OAuth-токен&gt;",
    "crumbs": [
      "Практика",
      "Настройка Yandex Kubernetes"
    ]
  },
  {
    "objectID": "1. yandex_kube.html#установка-kubectl",
    "href": "1. yandex_kube.html#установка-kubectl",
    "title": "Настройка Yandex Kubernetes",
    "section": "",
    "text": "Инструкция по установке от Kubernetes\nСкачайте к себе собранный бинарник kubectl\ncurl -LO https://dl.k8s.io/release/v1.33.0/bin/linux/amd64/kubectl\nИзмените права для исполнения kubectl\nchmod +x ./kubectl\nПереместите его в системную папку bin\nsudo mv ./kubectl /usr/local/bin/kubectl",
    "crumbs": [
      "Практика",
      "Настройка Yandex Kubernetes"
    ]
  },
  {
    "objectID": "1. yandex_kube.html#настройка-доступов-kubectl",
    "href": "1. yandex_kube.html#настройка-доступов-kubectl",
    "title": "Настройка Yandex Kubernetes",
    "section": "",
    "text": "Настройте доступ к kubectl к кластеру\nyc managed-kubernetes cluster get-credentials --id &lt;Cluster ID&gt; --external\n\nПроверьте что все работает\nkubectl config view\nили\nkubectl get nodes",
    "crumbs": [
      "Практика",
      "Настройка Yandex Kubernetes"
    ]
  },
  {
    "objectID": "1. yandex_kube.html#установка-helm",
    "href": "1. yandex_kube.html#установка-helm",
    "title": "Настройка Yandex Kubernetes",
    "section": "",
    "text": "Скачайте скрипт установки (см инструкцию helm)\ncurl -fsSL -o get_helm.sh https://raw.githubusercontent.com/helm/helm/main/scripts/get-helm-3\nИзмените права для запуска\nchmod 700 get_helm.sh\nЗапустите установку\n./get_helm.sh",
    "crumbs": [
      "Практика",
      "Настройка Yandex Kubernetes"
    ]
  },
  {
    "objectID": "1. yandex_kube.html#настройка-доступов-helm",
    "href": "1. yandex_kube.html#настройка-доступов-helm",
    "title": "Настройка Yandex Kubernetes",
    "section": "",
    "text": "Что бы подключить helm к yc выполните команду, воспользуйтесь своим OauthToken\nhelm registry login registry.yandexcloud.net -u oauth\nPassword: &lt;OAuth-токен&gt;",
    "crumbs": [
      "Практика",
      "Настройка Yandex Kubernetes"
    ]
  },
  {
    "objectID": "slides/1.intro.html#чуть-чуть-интерактива",
    "href": "slides/1.intro.html#чуть-чуть-интерактива",
    "title": "Intro",
    "section": "Чуть-чуть интерактива",
    "text": "Чуть-чуть интерактива\nvk.cc/cNpPry",
    "crumbs": [
      "Лекции",
      "Intro"
    ]
  },
  {
    "objectID": "slides/1.intro.html#план-занятий",
    "href": "slides/1.intro.html#план-занятий",
    "title": "Intro",
    "section": "План занятий",
    "text": "План занятий\n\nОпределимся: Что такое MLOps?\nПоговорим о проблемах ML\nПосмотрим подходы к их решению\nПосвятим много времени ClearML",
    "crumbs": [
      "Лекции",
      "Intro"
    ]
  },
  {
    "objectID": "slides/1.intro.html#что-такое-mlops",
    "href": "slides/1.intro.html#что-такое-mlops",
    "title": "Intro",
    "section": "Что такое MLOps?",
    "text": "Что такое MLOps?",
    "crumbs": [
      "Лекции",
      "Intro"
    ]
  },
  {
    "objectID": "slides/1.intro.html#данные",
    "href": "slides/1.intro.html#данные",
    "title": "Intro",
    "section": "Данные",
    "text": "Данные\n\n\n\nЛежат локально\nМеняются произвольно\nНет настроенных потоков данных\nНет версий датасетов",
    "crumbs": [
      "Лекции",
      "Intro"
    ]
  },
  {
    "objectID": "slides/1.intro.html#исследования",
    "href": "slides/1.intro.html#исследования",
    "title": "Intro",
    "section": "Исследования",
    "text": "Исследования\n\n\n\nНет культуры исследований\nРезультаты теряются\nЧасто не воспроизводимы\nСложно разобраться “а что сделано-то?”",
    "crumbs": [
      "Лекции",
      "Intro"
    ]
  },
  {
    "objectID": "slides/1.intro.html#модели",
    "href": "slides/1.intro.html#модели",
    "title": "Intro",
    "section": "Модели",
    "text": "Модели\n\n\n\n“А где модель то?”\n“Как ее запустить?”\n“А она еще работает?”\n“Что-то не так, дай новую модельку”",
    "crumbs": [
      "Лекции",
      "Intro"
    ]
  },
  {
    "objectID": "slides/1.intro.html#командное-взаимодействие",
    "href": "slides/1.intro.html#командное-взаимодействие",
    "title": "Intro",
    "section": "Командное взаимодействие",
    "text": "Командное взаимодействие\n\n\n\nКаждый кодит как он хочет\nИсследования независимы\nНет обмена знаниями\n“А что мы вообще делаем?”",
    "crumbs": [
      "Лекции",
      "Intro"
    ]
  },
  {
    "objectID": "slides/1.intro.html#как-же-все-это-решать",
    "href": "slides/1.intro.html#как-же-все-это-решать",
    "title": "Intro",
    "section": "Как же все это решать?",
    "text": "Как же все это решать?\nматрица зрелости инженерных практик\n\nПостепенно менять процессы работы\nВнедрять инструменты автоматизации\nПовышать культуру и компетенции команды\nДелать сразу как надо",
    "crumbs": [
      "Лекции",
      "Intro"
    ]
  },
  {
    "objectID": "README.html",
    "href": "README.html",
    "title": "MLOps/DataOps YA.CAMP 2025",
    "section": "",
    "text": "В репозитории представлены материалы для занятий MLOps/DataOps YA.CAMP 2025.\n\n\nИсточники для подготовленных материалов:\n\nДокументация ClearML\nКурс MLOps и production в DS исследованиях 3.0\nКурс Инженерные практики в ML\n\n\n\n\n\nВведение в MLOps, что это и зачем нужно?\nИнструменты MLOps (краткий перечень)\nClearML как единая платформа для ML исследований\n\n\n\n\n\nclearml-helm-charts – подготовленные helm charts для запуска на YC clearml и выполнения примера. В них заранее заменены образы которые попали под блокировку, поэтому развертка должна пройти без проблем.\nmlops-example – подготовленный демо пример того, как и что можно делать c clearml, показаны основные возможности и способы работы.\nИнстуркции к работе с примером также приложены в репозиторий, надеюсь они помогут разобраться с ним:\n\n1. yandex_kube.md – настрйока kuber в yc, куда нужно посмотреть и как настроить локальные инструменты.\n2. clearml_yandex_kube.md – как развернуть на yc kuber нужные для практики сервисы clearml.\n3. clearml_work.md – как настроить окружение демо примера у себя и настроить работу с clearml\n4. clearml_data.md – информация по работе с clearml data, как с ней взаимодействовать и как подготовить данные для демо примера и загрузить в clearml.\n5. clearml_pipeline.md – базовое создание пайплайнов и способы их запуска: локально и удаленно, пример пайплайна по подготовке данных\n6. clearml_research.md – как проводить исследваония в clearml, что для этого нужно, как логировать метрики, артефакты и модели, а так же сравнвивать экперименты между собой.\n7. clearml_reports.md – Немного про отчеты, как их легко делать и хранить в clearml\n8. clearml_serving.md – как развернуть модели с помощью clearml, описание демо примера.\n9. clearml_extend_pipes.md – чуть больше возможностей пайплайнов, как составить пайплайн из готовых задач.\n\n\n\nСначала ознакомьтесь со всеми материалами, а уже потом пробуйте запустить\n\n\n\n\nНа практике необходимо выполнить задание, его подробности вам опишет практик, но основная часть такая:\nПервая практика\n\nРазвернуть инфру на YC1\nЗагрузить несколько версий датасета в clearml\nРеализовать пайплайн обработки версий датасета для подготовки данных для обучения моделей.\n\nВторая практика\n\nРеализовать обучение модели на подготовленном датасет\nНастроить логирования метрик, семплов и моделей в clearml\nЗапустить удаленные эксперименты на агенте clearml\nСформировать отчёт с сравнением моделей в clearml reports\n\nТретья практика\n\nНастроить model servering в YC 2\nЗадеплоить туда одну из моделей\nРеализовать простой интерфейс для взаимодействия с API модели на streamlit/dash"
  },
  {
    "objectID": "README.html#источники",
    "href": "README.html#источники",
    "title": "MLOps/DataOps YA.CAMP 2025",
    "section": "",
    "text": "Источники для подготовленных материалов:\n\nДокументация ClearML\nКурс MLOps и production в DS исследованиях 3.0\nКурс Инженерные практики в ML"
  },
  {
    "objectID": "README.html#теория",
    "href": "README.html#теория",
    "title": "MLOps/DataOps YA.CAMP 2025",
    "section": "",
    "text": "Введение в MLOps, что это и зачем нужно?\nИнструменты MLOps (краткий перечень)\nClearML как единая платформа для ML исследований"
  },
  {
    "objectID": "README.html#практика",
    "href": "README.html#практика",
    "title": "MLOps/DataOps YA.CAMP 2025",
    "section": "",
    "text": "clearml-helm-charts – подготовленные helm charts для запуска на YC clearml и выполнения примера. В них заранее заменены образы которые попали под блокировку, поэтому развертка должна пройти без проблем.\nmlops-example – подготовленный демо пример того, как и что можно делать c clearml, показаны основные возможности и способы работы.\nИнстуркции к работе с примером также приложены в репозиторий, надеюсь они помогут разобраться с ним:\n\n1. yandex_kube.md – настрйока kuber в yc, куда нужно посмотреть и как настроить локальные инструменты.\n2. clearml_yandex_kube.md – как развернуть на yc kuber нужные для практики сервисы clearml.\n3. clearml_work.md – как настроить окружение демо примера у себя и настроить работу с clearml\n4. clearml_data.md – информация по работе с clearml data, как с ней взаимодействовать и как подготовить данные для демо примера и загрузить в clearml.\n5. clearml_pipeline.md – базовое создание пайплайнов и способы их запуска: локально и удаленно, пример пайплайна по подготовке данных\n6. clearml_research.md – как проводить исследваония в clearml, что для этого нужно, как логировать метрики, артефакты и модели, а так же сравнвивать экперименты между собой.\n7. clearml_reports.md – Немного про отчеты, как их легко делать и хранить в clearml\n8. clearml_serving.md – как развернуть модели с помощью clearml, описание демо примера.\n9. clearml_extend_pipes.md – чуть больше возможностей пайплайнов, как составить пайплайн из готовых задач.\n\n\n\nСначала ознакомьтесь со всеми материалами, а уже потом пробуйте запустить"
  },
  {
    "objectID": "README.html#задание",
    "href": "README.html#задание",
    "title": "MLOps/DataOps YA.CAMP 2025",
    "section": "",
    "text": "На практике необходимо выполнить задание, его подробности вам опишет практик, но основная часть такая:\nПервая практика\n\nРазвернуть инфру на YC1\nЗагрузить несколько версий датасета в clearml\nРеализовать пайплайн обработки версий датасета для подготовки данных для обучения моделей.\n\nВторая практика\n\nРеализовать обучение модели на подготовленном датасет\nНастроить логирования метрик, семплов и моделей в clearml\nЗапустить удаленные эксперименты на агенте clearml\nСформировать отчёт с сравнением моделей в clearml reports\n\nТретья практика\n\nНастроить model servering в YC 2\nЗадеплоить туда одну из моделей\nРеализовать простой интерфейс для взаимодействия с API модели на streamlit/dash"
  },
  {
    "objectID": "README.html#footnotes",
    "href": "README.html#footnotes",
    "title": "MLOps/DataOps YA.CAMP 2025",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nЕсли не получается то локлаьно через docker-compose↩︎\nЕсли неполчается, то реализовать приложение fastpai, которое при запуске забирает определенную версию модели из clearml↩︎"
  },
  {
    "objectID": "slides/2.tools.html#tools-types",
    "href": "slides/2.tools.html#tools-types",
    "title": "MLOps Tools",
    "section": "Tools types",
    "text": "Tools types\n\n\n\nData Management\nData Validation\nWorkflow Managment\nModel Lifecycle\n\n\n\nKnowledge Sharing\nModel Serving\nMonitoring & Dashboards\nMLOps Platforms\n\n\nИ это еще не всё…1\nСмотрите в awesome-mlops и mlops-references",
    "crumbs": [
      "Лекции",
      "MLOps Tools"
    ]
  },
  {
    "objectID": "slides/2.tools.html#data-management",
    "href": "slides/2.tools.html#data-management",
    "title": "MLOps Tools",
    "section": "Data Management",
    "text": "Data Management\n\nGit LFS – расширение git для больших файлов\nDVC – система версионирования данных и моделей в ml проектах\nHugging Face – платформа для публикации открытых моделей и датасетов\nLakeFS – git like система версионирования данных в объектных хранилищах",
    "crumbs": [
      "Лекции",
      "MLOps Tools"
    ]
  },
  {
    "objectID": "slides/2.tools.html#data-validation",
    "href": "slides/2.tools.html#data-validation",
    "title": "MLOps Tools",
    "section": "Data Validation",
    "text": "Data Validation\n\nGreat Expectations – фреймворк для валидации данных\nPandera – задание модели данных pandas и polars\nData contract – валидация как хранилищ данных, так и отдельных файлов",
    "crumbs": [
      "Лекции",
      "MLOps Tools"
    ]
  },
  {
    "objectID": "slides/2.tools.html#workflow-managment",
    "href": "slides/2.tools.html#workflow-managment",
    "title": "MLOps Tools",
    "section": "Workflow Managment",
    "text": "Workflow Managment\n\nGNU Make – олдовый workflow manager на основе файлов\nSnakeMake – аналог для управления workflow в DS проектах\nLuigi – python оркестратор workflow\nMetaflow – оркестратор для ML workflow\nMage AI – фреймворк для управления ml workflow\nAirFlow –мощный и популярный оркестратор workflow",
    "crumbs": [
      "Лекции",
      "MLOps Tools"
    ]
  },
  {
    "objectID": "slides/2.tools.html#model-lifecycle",
    "href": "slides/2.tools.html#model-lifecycle",
    "title": "MLOps Tools",
    "section": "Model Lifecycle",
    "text": "Model Lifecycle\n\nMLflow – платформа для трекинга артефактов экспериментов\nNeptune AI – колобаративный инструмент трекинга артефактов и датасетов\nWeights and Biases – инструмент визуализации и отслеживания обучения ваших моделей\nTensorBoard – инструмент визуализации обучения ваших нейронных сетей",
    "crumbs": [
      "Лекции",
      "MLOps Tools"
    ]
  },
  {
    "objectID": "slides/2.tools.html#knowledge-sharing",
    "href": "slides/2.tools.html#knowledge-sharing",
    "title": "MLOps Tools",
    "section": "Knowledge Sharing",
    "text": "Knowledge Sharing\n\nKnowledge Repo – платформа обмена знаниями для исследователей\nKyso – инструмент публикации и ревью отчетов",
    "crumbs": [
      "Лекции",
      "MLOps Tools"
    ]
  },
  {
    "objectID": "slides/2.tools.html#model-serving",
    "href": "slides/2.tools.html#model-serving",
    "title": "MLOps Tools",
    "section": "Model Serving",
    "text": "Model Serving\n\nTriton Inference Server – python сервис для деплоя различных моделей и оптимизацией их исполнения\nTensorFlow Serving – гибкий, мощный инструмент деплоя tensorflow в продакшен\nTorchServe – аналог для моделей pytorch\nOpyrator – простой способ получить API/интерфейс модели\nGradio – инструмент построения простых ML web-приложений",
    "crumbs": [
      "Лекции",
      "MLOps Tools"
    ]
  },
  {
    "objectID": "slides/2.tools.html#monitoring-dashboards",
    "href": "slides/2.tools.html#monitoring-dashboards",
    "title": "MLOps Tools",
    "section": "Monitoring & Dashboards",
    "text": "Monitoring & Dashboards\n\nStreamlit – простой инструмент построения dashboards чего либо на питоне\nDash – аналог от команды plotly\nGrafana – простой сервис для построения dashboards\nPrometheus – инструмент сбора метрик и ошибок\nGrayLog – сборщик и анализатор логов",
    "crumbs": [
      "Лекции",
      "MLOps Tools"
    ]
  },
  {
    "objectID": "slides/2.tools.html#mlops-platforms",
    "href": "slides/2.tools.html#mlops-platforms",
    "title": "MLOps Tools",
    "section": "MLOps Platforms",
    "text": "MLOps Platforms\n\nClearML – платформа все в одном\nKubeflow – платформа для ML на основе kubernetes\nИ много много других",
    "crumbs": [
      "Лекции",
      "MLOps Tools"
    ]
  },
  {
    "objectID": "2. clearml_yandex_kube.html",
    "href": "2. clearml_yandex_kube.html",
    "title": "Настройка ClearML Yandex",
    "section": "",
    "text": "Скачайте репозиторий clearml helm charts\n\n\nУпакуйте helm для дальнейшего использования\nhelm package clearml-helm-charts/charts/clearml \n\n\n\nСоздайте Cloud Registry для helm/docker.\nhelm push clearml-7.14.5.tgz oci://registry.yandexcloud.net/&lt;Cloud registry ID&gt;\n\n\n\nЗапустите готовый helm на вашем кластере kubernetes\nhelm install clearml oci://registry.yandexcloud.net/&lt;Cloud registry ID&gt;/clearml:7.14.5",
    "crumbs": [
      "Практика",
      "Настройка ClearML Yandex"
    ]
  },
  {
    "objectID": "2. clearml_yandex_kube.html#package-helm-chart",
    "href": "2. clearml_yandex_kube.html#package-helm-chart",
    "title": "Настройка ClearML Yandex",
    "section": "",
    "text": "Упакуйте helm для дальнейшего использования\nhelm package clearml-helm-charts/charts/clearml",
    "crumbs": [
      "Практика",
      "Настройка ClearML Yandex"
    ]
  },
  {
    "objectID": "2. clearml_yandex_kube.html#push-helm-chart",
    "href": "2. clearml_yandex_kube.html#push-helm-chart",
    "title": "Настройка ClearML Yandex",
    "section": "",
    "text": "Создайте Cloud Registry для helm/docker.\nhelm push clearml-7.14.5.tgz oci://registry.yandexcloud.net/&lt;Cloud registry ID&gt;",
    "crumbs": [
      "Практика",
      "Настройка ClearML Yandex"
    ]
  },
  {
    "objectID": "2. clearml_yandex_kube.html#deploy-helm-chart",
    "href": "2. clearml_yandex_kube.html#deploy-helm-chart",
    "title": "Настройка ClearML Yandex",
    "section": "",
    "text": "Запустите готовый helm на вашем кластере kubernetes\nhelm install clearml oci://registry.yandexcloud.net/&lt;Cloud registry ID&gt;/clearml:7.14.5",
    "crumbs": [
      "Практика",
      "Настройка ClearML Yandex"
    ]
  },
  {
    "objectID": "2. clearml_yandex_kube.html#package-helm-chart-1",
    "href": "2. clearml_yandex_kube.html#package-helm-chart-1",
    "title": "Настройка ClearML Yandex",
    "section": "Package helm chart",
    "text": "Package helm chart\nУпакуйте helm для дальнейшего использования\nhelm package clearml-helm-charts/charts/clearml-agent",
    "crumbs": [
      "Практика",
      "Настройка ClearML Yandex"
    ]
  },
  {
    "objectID": "2. clearml_yandex_kube.html#push-helm-chart-1",
    "href": "2. clearml_yandex_kube.html#push-helm-chart-1",
    "title": "Настройка ClearML Yandex",
    "section": "Push helm chart",
    "text": "Push helm chart\nСоздайте Cloud Registry для helm/docker.\nhelm push clearml-agent-5.3.3.tgz oci://registry.yandexcloud.net/&lt;Cloud registry ID&gt;",
    "crumbs": [
      "Практика",
      "Настройка ClearML Yandex"
    ]
  },
  {
    "objectID": "2. clearml_yandex_kube.html#deploy-helm-chart-1",
    "href": "2. clearml_yandex_kube.html#deploy-helm-chart-1",
    "title": "Настройка ClearML Yandex",
    "section": "Deploy helm chart",
    "text": "Deploy helm chart\nЗапустите готовый helm на вашем кластере kubernetes.\nhelm install clearml-agent oci://registry.yandexcloud.net/&lt;Cloud registry ID&gt;/clearml-agent:5.3.3  --set clearml.agentk8sglueKey=ACCESSKEY --set clearml.agentk8sglueSecret=SECRETKEY --set agentk8sglue.apiServerUrlReference=APISERVERURL --set agentk8sglue.fileServerUrlReference=FILESERVERURL --set agentk8sglue.webServerUrlReference=WEBSERVERURL\nСоздайте доступы в clearml (см. clearml_work.md) и заполните эти поля: * ACCESSKEY значение access_key в новых доступах * SECRETKEY значение secret_key в новых доступах * APISERVERURL значение api_server в новых доступах * FILESSERVERURL значение files_server в новых доступах * WEBSERVERURL значение web_server в новых доступах",
    "crumbs": [
      "Практика",
      "Настройка ClearML Yandex"
    ]
  },
  {
    "objectID": "2. clearml_yandex_kube.html#package-helm-chart-2",
    "href": "2. clearml_yandex_kube.html#package-helm-chart-2",
    "title": "Настройка ClearML Yandex",
    "section": "Package helm chart",
    "text": "Package helm chart\nУпакуйте helm для дальнейшего использования\nhelm package clearml-helm-charts/charts/clearml-serving",
    "crumbs": [
      "Практика",
      "Настройка ClearML Yandex"
    ]
  },
  {
    "objectID": "2. clearml_yandex_kube.html#push-helm-chart-2",
    "href": "2. clearml_yandex_kube.html#push-helm-chart-2",
    "title": "Настройка ClearML Yandex",
    "section": "Push helm chart",
    "text": "Push helm chart\nСоздайте Cloud Registry для helm/docker.\nhelm push clearml-serving-1.6.0.tgz oci://registry.yandexcloud.net/&lt;Cloud registry ID&gt;",
    "crumbs": [
      "Практика",
      "Настройка ClearML Yandex"
    ]
  },
  {
    "objectID": "2. clearml_yandex_kube.html#deploy-helm-chart-2",
    "href": "2. clearml_yandex_kube.html#deploy-helm-chart-2",
    "title": "Настройка ClearML Yandex",
    "section": "Deploy helm chart",
    "text": "Deploy helm chart\nЗапустите готовый helm на вашем кластере kubernetes.\nhelm install clearml-serving oci://registry.yandexcloud.net/&lt;Cloud registry ID&gt;/clearml-serving:1.6.0  --set clearml.apiAccessKey=ACCESSKEY --set clearml.apiSecretKey=SECRETKEY --set clearml.apiHost=APISERVERURL --set clearml.filesHost=FILESERVERURL --set clearml.webHost=WEBSERVERURL --set clearml.servingTaskId=SERVERINGID\nСоздайте доступы в clearml (см. clearml_work.md) и заполните эти поля: * ACCESSKEY значение access_key в новых доступах * SECRETKEY значение secret_key в новых доступах * APISERVERURL значение api_server в новых доступах * FILESSERVERURL значение files_server в новых доступах * WEBSERVERURL значение web_server в новых доступах\nСоздайте с помощью clearml-serving пространство (8. clearml_serving.md), SERVERINGID это его id.",
    "crumbs": [
      "Практика",
      "Настройка ClearML Yandex"
    ]
  },
  {
    "objectID": "4. clearml_data.html",
    "href": "4. clearml_data.html",
    "title": "ClearML Data",
    "section": "",
    "text": "ClearML Data\nВ примере для загрузки начальных данных использовался скрипт mlops-example/1.upload_dataset.ipynb. Для того что бы он работал скачайте датасет Amazon reviews и разархивируйте его в папку mlops-example/data.\nОткройте mlops-example/1.upload_dataset.ipynb и начните его выполнение.\n\nВ самом начале он создает пустой Clearml Dataset (мы рассмотрим работу через SDK, но есть еще и CLI), который мы будем постепенно наполнять данными из данных Amazon reviews. Вы сможете найти ваш датасет в разделе /datasets: http://51.250.106.18:30080/datasets.\n\ndataset = Dataset.create(\n    dataset_name=\"Amazon reviews dataset\",\n    dataset_project=\"Amazon reviews\",\n    dataset_version=\"1.0\",\n    description=\"Data from kagle project\",\n)\ndataset.finalize()\n\nРазбивает обучающую выборки на батчи по 25000 строк в цикле и обрабатывает каждый батч.\n\nfor index, batch in enumerate(\n    pl.read_csv(\n        \"data/train.csv\",\n        has_header=False,\n        new_columns=[\"Polarity\", \"Title\", \"Review\"],\n    )\n    .with_row_index()\n    .with_columns(pl.col(\"index\") // 25000)\n    .partition_by(\"index\")\n):\n\nСначала сохраняет batch локально под уникальным номером.\n\n    batch.write_csv(f\"data/raw/batch_{index}.csv\")\n\nСчитает для него распределение классов\n\n    polaritu_distrib = batch.group_by(\"Polarity\").len()\n\nСоздает новую версию датасета и добавляет в нее новый файл. Заметьте, что у датасета в качестве parent_datasets указана предыдущая версия датасета, это позволяет строить цепочку датасетов.\n\n    dataset = Dataset.create(\n        dataset_name=\"Amazon reviews dataset\",\n        dataset_project=\"Amazon reviews\",\n        parent_datasets=[dataset],\n        dataset_version=f\"1.{index}\",\n        description=\"Data from kagle project\",\n    )\n    dataset.add_files(path=f\"data/raw/batch_{index}.csv\")\n\n\nЗадает мета информацию об изменении датасета в виде гистограммы распределения классов и head добавляемой таблицы.\n\n    dataset.get_logger().report_table(\n        \"Dataset Preview\", \"Dataset Preview\", table_plot=batch.head(5).to_pandas()\n    )\n    dataset.get_logger().report_histogram(\n        title=\"Polarity distribution\",\n        series=\"Polarity distribution\",\n        values=polaritu_distrib[\"len\"].to_list(),\n        xlabels=polaritu_distrib[\"Polarity\"].to_list(),\n        yaxis=\"Number of samples\",\n    )\n\nЗагружает данные в датасет и финализирует новую версию.\n\n    dataset.upload()\n    dataset.finalize()\n\nТеперь вы можете легко получать данные из вашего датасета на любое рабочее место, выполнив такой код: ```python dataset = Dataset.get( dataset_name=“Amazon reviews dataset”, dataset_project=“Amazon reviews”, dataset_version=“1.143”, )",
    "crumbs": [
      "Практика",
      "ClearML Data"
    ]
  },
  {
    "objectID": "6. clearml_research.html",
    "href": "6. clearml_research.html",
    "title": "ClearML Research",
    "section": "",
    "text": "Теперь разберем самое интересное – как можно в ClearML проводить исследования. ClearML предоставляет комплексную платформу для управления ML-экспериментами: - Автоматическое отслеживание кода, параметров, метрик и артефактов - Воспроизводимость экспериментов через фиксацию данных, кода и зависимостей - Масштабирование с помощью удаленных агентов - Сравнение экспериментов через веб-интерфейс\nНиже объясняется как проводить исследования с примерами из 3.tf_idf.py и 4.bert_amazon.ipynb\n\n\n\nИнициализация задачи. Каждый эксперимент начинается с инициализации задачи, вот небольшой пример, но стоит посмотреть на документацию.\n\nfrom clearml import Task\ntask = Task.init(\n    project_name=\"Amazon reviews\",\n    task_name=\"TF-IDF Vectorize BernoulliNB\",  # или \"Bert\"\n    output_uri=True  # Автоматическое логирование артефактов\n)\n\nУправление конфигурацией. ClearML позволяет настроить отслеживание гиперпараметров и настроек:\n\nargs = {\n    \"random_state\": 42,\n    \"max_features\": 1000,\n    \"analyzer\": \"word\"\n}\ntask.connect(args)  # Логирует параметры в ClearML\n\n\nСтоит использовать не локальные данные, а данные которые у нас уже преобразованы в датасет. Это обеспечивает воспроизводимость:\n\nfrom clearml import Dataset\n\n# Получение конкретной версии датасета\ntrain_dataset = Dataset.get(\n    dataset_name=\"Amazon reviews dataset\",\n    dataset_project=\"Amazon reviews\",\n    dataset_version=\"1.2.1\"  # Фиксация версии\n)\nframe_path = train_dataset.get_local_copy()\n\nОбучение моделей и их логирование. Для этого у clearml есть специальный класс который позволяет задавать специальные артефакты–модели, которые в дальнейшем можно будет засерверить.\n\nfrom clearml import OutputModel\n\npipe = Pipeline([\n    (\"tfidf\", TfidfVectorizer()),\n    (\"bernoulli\", BernoulliNB())\n])\npipe.fit(train_x, train_y)\n\n# Сохранение и логирование модели\njoblib.dump(pipe, \"model.pkl\")\noutput_model = OutputModel(task=task, framework=\"scikit-learn\")\noutput_model.update_weights(weights_filename=\"model.pkl\")\n \n\nОтслеживание экспериментов и метрик может производиться как в отношении эксперимента, так и отдельных артефактов моделей/датасетов, ниже приведен пример как можно залогировать classification_report и он будет сохранен и в задании и в описании модели.\n\nimport pandas as pd\nfrom sklearn.metrics import classification_report\nfrom clearml import Logger\n\nlogger: Logger = task.get_logger()\n\npred_y = pipe.predict(test_x[\"corpus\"])\nclassification_report_table = pd.DataFrame(\n    classification_report(test_y, pred_y, output_dict=True)\n).T\nlogger.report_table(\n    \"Classifiacation Report\", \"Metrics\", table_plot=classification_report_table\n)\noutput_model.report_table(\n    \"Classifiacation Report\", \"Metrics\", table_plot=classification_report_table\n)\nclassification_report_table\n\n\nМожно заниматься логированием отдельных артефактов в задания, например эмбендингов полученных от bert’a, что бы использовать их в других экспериментах.\n\n# Загрузка эмбеддингов (пример BERT)\ntask.upload_artifact(\"train_embeddings\", train_embeddings)\n\nClearML автоматически фиксирует:\n\n\nКонсольный вывод\nИсходный код (с созданием Git-снимка)\nУстановленные зависимости\nСистемные метрики (CPU/GPU/память) Для этого не требуется дополнительный код.\n\n\nСравнение экспериментов в ClearML есть инструменты для сравнения экспериментов, вы можете легко сравнивать результаты разных экспериментов и графики и метрики.\n\n\n\n\n\n\nИнициализация задачи: Начните отслеживание перед выполнением кода\nКонфигурация параметров: Используйте task.connect() для воспроизводимости и повторных удаленных запусков на clearml agent с другими параметрами.\nВерсионирование данных: Выбирайте версии датасетов через Dataset.get(), и лучше установить версию как параметр, что бы вы легко могли воспроизвести эксперимент на следующих инкрементах данных.\nВыполнение эксперимента:\n\nАвтоматическое/ручное логирование метрик\nСохранение моделей через OutputModel\nЛогирование артефактов через task.upload_artifact()\n\nФинализация: task.mark_completed() – по завершении пометьте эксперимент выполненным\nВоспроизведение:\n\nКлонирование задачи через веб-интерфейс\nЗапуск на удаленном агенте с новыми параметрами\n\nСравнение экспериментов с различными параметрами в веб интерфейсе",
    "crumbs": [
      "Практика",
      "ClearML Research"
    ]
  },
  {
    "objectID": "6. clearml_research.html#ключевые-шаги-исследований-в-clearml",
    "href": "6. clearml_research.html#ключевые-шаги-исследований-в-clearml",
    "title": "ClearML Research",
    "section": "",
    "text": "Инициализация задачи. Каждый эксперимент начинается с инициализации задачи, вот небольшой пример, но стоит посмотреть на документацию.\n\nfrom clearml import Task\ntask = Task.init(\n    project_name=\"Amazon reviews\",\n    task_name=\"TF-IDF Vectorize BernoulliNB\",  # или \"Bert\"\n    output_uri=True  # Автоматическое логирование артефактов\n)\n\nУправление конфигурацией. ClearML позволяет настроить отслеживание гиперпараметров и настроек:\n\nargs = {\n    \"random_state\": 42,\n    \"max_features\": 1000,\n    \"analyzer\": \"word\"\n}\ntask.connect(args)  # Логирует параметры в ClearML\n\n\nСтоит использовать не локальные данные, а данные которые у нас уже преобразованы в датасет. Это обеспечивает воспроизводимость:\n\nfrom clearml import Dataset\n\n# Получение конкретной версии датасета\ntrain_dataset = Dataset.get(\n    dataset_name=\"Amazon reviews dataset\",\n    dataset_project=\"Amazon reviews\",\n    dataset_version=\"1.2.1\"  # Фиксация версии\n)\nframe_path = train_dataset.get_local_copy()\n\nОбучение моделей и их логирование. Для этого у clearml есть специальный класс который позволяет задавать специальные артефакты–модели, которые в дальнейшем можно будет засерверить.\n\nfrom clearml import OutputModel\n\npipe = Pipeline([\n    (\"tfidf\", TfidfVectorizer()),\n    (\"bernoulli\", BernoulliNB())\n])\npipe.fit(train_x, train_y)\n\n# Сохранение и логирование модели\njoblib.dump(pipe, \"model.pkl\")\noutput_model = OutputModel(task=task, framework=\"scikit-learn\")\noutput_model.update_weights(weights_filename=\"model.pkl\")\n \n\nОтслеживание экспериментов и метрик может производиться как в отношении эксперимента, так и отдельных артефактов моделей/датасетов, ниже приведен пример как можно залогировать classification_report и он будет сохранен и в задании и в описании модели.\n\nimport pandas as pd\nfrom sklearn.metrics import classification_report\nfrom clearml import Logger\n\nlogger: Logger = task.get_logger()\n\npred_y = pipe.predict(test_x[\"corpus\"])\nclassification_report_table = pd.DataFrame(\n    classification_report(test_y, pred_y, output_dict=True)\n).T\nlogger.report_table(\n    \"Classifiacation Report\", \"Metrics\", table_plot=classification_report_table\n)\noutput_model.report_table(\n    \"Classifiacation Report\", \"Metrics\", table_plot=classification_report_table\n)\nclassification_report_table\n\n\nМожно заниматься логированием отдельных артефактов в задания, например эмбендингов полученных от bert’a, что бы использовать их в других экспериментах.\n\n# Загрузка эмбеддингов (пример BERT)\ntask.upload_artifact(\"train_embeddings\", train_embeddings)\n\nClearML автоматически фиксирует:\n\n\nКонсольный вывод\nИсходный код (с созданием Git-снимка)\nУстановленные зависимости\nСистемные метрики (CPU/GPU/память) Для этого не требуется дополнительный код.\n\n\nСравнение экспериментов в ClearML есть инструменты для сравнения экспериментов, вы можете легко сравнивать результаты разных экспериментов и графики и метрики.",
    "crumbs": [
      "Практика",
      "ClearML Research"
    ]
  },
  {
    "objectID": "6. clearml_research.html#шаги-рабочего-процесса",
    "href": "6. clearml_research.html#шаги-рабочего-процесса",
    "title": "ClearML Research",
    "section": "",
    "text": "Инициализация задачи: Начните отслеживание перед выполнением кода\nКонфигурация параметров: Используйте task.connect() для воспроизводимости и повторных удаленных запусков на clearml agent с другими параметрами.\nВерсионирование данных: Выбирайте версии датасетов через Dataset.get(), и лучше установить версию как параметр, что бы вы легко могли воспроизвести эксперимент на следующих инкрементах данных.\nВыполнение эксперимента:\n\nАвтоматическое/ручное логирование метрик\nСохранение моделей через OutputModel\nЛогирование артефактов через task.upload_artifact()\n\nФинализация: task.mark_completed() – по завершении пометьте эксперимент выполненным\nВоспроизведение:\n\nКлонирование задачи через веб-интерфейс\nЗапуск на удаленном агенте с новыми параметрами\n\nСравнение экспериментов с различными параметрами в веб интерфейсе",
    "crumbs": [
      "Практика",
      "ClearML Research"
    ]
  },
  {
    "objectID": "8. clearml_serving.html",
    "href": "8. clearml_serving.html",
    "title": "ClearML Servering",
    "section": "",
    "text": "Установите clearml-serving\n\npixi add --pypi clearml-serving\npixi install -a\n\nСоздайте clearml serving controller:\n\npixi run clearml-serving create --name  \"Amazon Reviews\"\nПолучите его ID для развертки clearml-serving в kubernetess\nNew Serving Service created: id=3e0e2ce884444da694fb774ef94ecc5f\n\nПерейдите к инструкции из 2. clearml_yandex_kube.md. Используйте полученный ID как SERVERINGID. Обратите внимание, что в serving нужно добавить зависимости в values.yaml\n\nclearml_serving_inference:\n  ...\n  extraPythonPackages:\n  - nltk==3.9.1\n  - polars&gt;=1.31.0,&lt;2\n\nДалее работаем с clearml-serving, (Вот тут документация)\n\n\n\n\n\nСтоит опубликовать вашу модель, которую вы хотите использовать, выберете в артефактах вашу модель и нажмите publish в ее меню. \nДалее нужно подготовить prepreprocessing для данных на вход модели, варианты можно найти в примерах. Вам нужно по сути написать класс Preprocessing в виде класса в фалйле, вот пример для подготовки данных в tf-idf\n\nclass Preprocess(object):\n    def __init__(self):\n        # set internal state, this will be called only once. (i.e. not per request)\n        pass\n\n    def preprocess(\n        self, body: dict, state: dict, collect_custom_statistics_fn=None\n    ) -&gt; Any:\n        # we expect to get two valid on the dict x0, and x1\n        text = body.get(\"text\", None)\n        processed_words = text_preprocessing(text).split(\" \")\n        lemmatizer = WordNetLemmatizer()\n        processed_text = \" \".join(\n            [lemmatizer.lemmatize(token) for token in processed_words]\n        )\n        return [processed_text]\n\n    def postprocess(\n        self, data: Any, state: dict, collect_custom_statistics_fn=None\n    ) -&gt; dict:\n        # post process the data returned from the model inference engine\n        # data is the return value from model.predict we will put is inside a return value as Y\n        return dict(y=data.tolist() if isinstance(data, np.ndarray) else data)\n\nДобавьте модель в serving:\n\npixi run clearml-serving --id 3e0e2ce884444da694fb774ef94ecc5f model auto-update --engine sklearn --endpoint \"sentiment_analyze\" --published --project \"Amazon reviews\" --name \"TF-IDF Vectorize BernoulliNB\" --max-versions 5 --preprocess \"mlops-example/mlops_example/preprocessing.py\"\nВот разбор команды: - Указываем --id   3e0e2ce884444da694fb774ef94ecc5f созданного контроллера - Выбираем режим модели model auto-update для автообновления при публикации новых моделей - Указываем фреймворк модели --engine sklearn (см документацию) - Определяем ендпоинт для доступа к модели --endpoint \"sentiment_analyze\" - Указываем параметры модели: опубликованные модели --published определенного проекта --project \"Amazon reviews\" под названием --name \"TF-IDF Vectorize BernoulliNB\" - Максимальное количество версий модели которые могут быть запущены --max-versions 5 - Указываем скрипт препроцессинга --preprocess \"mlops-example/mlops_example/preprocessing.py\"\n\nТеперь перейдите в проект DevOps, там в задаче Amazon Reviews - serve instance будут логи добавления модели.  Так же можете выполнить команду:\n\npixi run clearml-serving --id 3e0e2ce884444da694fb774ef94ecc5f model list\nИ увидеть что модели загружены:\nclearml-serving - CLI for launching ClearML serving engine\nList model serving and endpoints, control task id=3e0e2ce884444da694fb774ef94ecc5f\nInfo: syncing model endpoint configuration, state hash=378b860f5e9c7c07f37320fe4033bdad\nEndpoints:\n{}\nModel Monitoring:\n{\n  \"sentiment_analyze\": {\n    \"base_serving_url\": \"sentiment_analyze\",\n    \"engine_type\": \"sklearn\",\n    \"monitor_project\": \"Amazon reviews\",\n    \"monitor_name\": \"TF-IDF Vectorize BernoulliNB\",\n    \"monitor_tags\": [],\n    \"only_published\": true,\n    \"max_versions\": 5,\n    \"input_size\": null,\n    \"input_type\": null,\n    \"input_name\": null,\n    \"output_size\": null,\n    \"output_type\": null,\n    \"output_name\": null,\n    \"preprocess_artifact\": \"py_code_sentiment_analyze\",\n    \"auxiliary_cfg\": null\n  }\n}\nCanary:\n{}\n\n\n\nПопробуем потестировать модель, сразу оговорюсь нужно делать тесты мз сети yc, так как для моделей не проброшены внешние порты, для этого можно развернуть виртуалку. Попробуем первый запрос, мы будем обращаться к модели с ID=27c2c1bb0af74984a3a22e702f65fdf9, поэтому в url указываем версию 2.\ncurl -X POST \"http://10.112.135.102:8080/serve/sentiment_analyze/2\" -H \"accept: application/json\" -H \"Content-Type: application/json\" -d \"{\\\"text\\\": \\\"Taking this out of my daughter's library, I found this book and thought the illustrtions were absolutey beautiful -- a true work of artistry. However, I didn't read it through before I bought it. I was reading it to my daughter when I discovered how disturbing the story turns with the spanking scenes. I stopped reading the book and I will take it out of my house.\\\"}\"\nОтвет модели: {\"y\":[2]}\nТеперь второй запрос:\ncurl -X POST \"http://10.112.135.102:8080/serve/sentiment_analyze/2\" -H \"accept: application/json\" -H \"Content-Type: application/json\" -d \"{\\\"text\\\": \\\"Scratched the lens with a kleenex,I used these once then used a Kleenex to wipe one lens that was a little smudged. I have microscopic vision and I noticed it was scratched AFTER I used the Kleenex, so to be sure, I used it again and sure enough, it scratched the lens some more. I compared the 2 lenses and the other lens looked pristine, whereas the one I used the kleenex on was scratched all over Very low quality lenses! Unusable after one use\\\"}\"\nОтвет модели: {\"y\":[1]}\nВидим что модель работает и назначает соответствующие лейблы. Отлично у вас есть развернутая модель которую можно использовать и отправлять ей разные запросы.",
    "crumbs": [
      "Практика",
      "ClearML Servering"
    ]
  },
  {
    "objectID": "8. clearml_serving.html#базовая-настройка",
    "href": "8. clearml_serving.html#базовая-настройка",
    "title": "ClearML Servering",
    "section": "",
    "text": "Установите clearml-serving\n\npixi add --pypi clearml-serving\npixi install -a\n\nСоздайте clearml serving controller:\n\npixi run clearml-serving create --name  \"Amazon Reviews\"\nПолучите его ID для развертки clearml-serving в kubernetess\nNew Serving Service created: id=3e0e2ce884444da694fb774ef94ecc5f\n\nПерейдите к инструкции из 2. clearml_yandex_kube.md. Используйте полученный ID как SERVERINGID. Обратите внимание, что в serving нужно добавить зависимости в values.yaml\n\nclearml_serving_inference:\n  ...\n  extraPythonPackages:\n  - nltk==3.9.1\n  - polars&gt;=1.31.0,&lt;2\n\nДалее работаем с clearml-serving, (Вот тут документация)",
    "crumbs": [
      "Практика",
      "ClearML Servering"
    ]
  },
  {
    "objectID": "8. clearml_serving.html#добвавлние-моделей",
    "href": "8. clearml_serving.html#добвавлние-моделей",
    "title": "ClearML Servering",
    "section": "",
    "text": "Стоит опубликовать вашу модель, которую вы хотите использовать, выберете в артефактах вашу модель и нажмите publish в ее меню. \nДалее нужно подготовить prepreprocessing для данных на вход модели, варианты можно найти в примерах. Вам нужно по сути написать класс Preprocessing в виде класса в фалйле, вот пример для подготовки данных в tf-idf\n\nclass Preprocess(object):\n    def __init__(self):\n        # set internal state, this will be called only once. (i.e. not per request)\n        pass\n\n    def preprocess(\n        self, body: dict, state: dict, collect_custom_statistics_fn=None\n    ) -&gt; Any:\n        # we expect to get two valid on the dict x0, and x1\n        text = body.get(\"text\", None)\n        processed_words = text_preprocessing(text).split(\" \")\n        lemmatizer = WordNetLemmatizer()\n        processed_text = \" \".join(\n            [lemmatizer.lemmatize(token) for token in processed_words]\n        )\n        return [processed_text]\n\n    def postprocess(\n        self, data: Any, state: dict, collect_custom_statistics_fn=None\n    ) -&gt; dict:\n        # post process the data returned from the model inference engine\n        # data is the return value from model.predict we will put is inside a return value as Y\n        return dict(y=data.tolist() if isinstance(data, np.ndarray) else data)\n\nДобавьте модель в serving:\n\npixi run clearml-serving --id 3e0e2ce884444da694fb774ef94ecc5f model auto-update --engine sklearn --endpoint \"sentiment_analyze\" --published --project \"Amazon reviews\" --name \"TF-IDF Vectorize BernoulliNB\" --max-versions 5 --preprocess \"mlops-example/mlops_example/preprocessing.py\"\nВот разбор команды: - Указываем --id   3e0e2ce884444da694fb774ef94ecc5f созданного контроллера - Выбираем режим модели model auto-update для автообновления при публикации новых моделей - Указываем фреймворк модели --engine sklearn (см документацию) - Определяем ендпоинт для доступа к модели --endpoint \"sentiment_analyze\" - Указываем параметры модели: опубликованные модели --published определенного проекта --project \"Amazon reviews\" под названием --name \"TF-IDF Vectorize BernoulliNB\" - Максимальное количество версий модели которые могут быть запущены --max-versions 5 - Указываем скрипт препроцессинга --preprocess \"mlops-example/mlops_example/preprocessing.py\"\n\nТеперь перейдите в проект DevOps, там в задаче Amazon Reviews - serve instance будут логи добавления модели.  Так же можете выполнить команду:\n\npixi run clearml-serving --id 3e0e2ce884444da694fb774ef94ecc5f model list\nИ увидеть что модели загружены:\nclearml-serving - CLI for launching ClearML serving engine\nList model serving and endpoints, control task id=3e0e2ce884444da694fb774ef94ecc5f\nInfo: syncing model endpoint configuration, state hash=378b860f5e9c7c07f37320fe4033bdad\nEndpoints:\n{}\nModel Monitoring:\n{\n  \"sentiment_analyze\": {\n    \"base_serving_url\": \"sentiment_analyze\",\n    \"engine_type\": \"sklearn\",\n    \"monitor_project\": \"Amazon reviews\",\n    \"monitor_name\": \"TF-IDF Vectorize BernoulliNB\",\n    \"monitor_tags\": [],\n    \"only_published\": true,\n    \"max_versions\": 5,\n    \"input_size\": null,\n    \"input_type\": null,\n    \"input_name\": null,\n    \"output_size\": null,\n    \"output_type\": null,\n    \"output_name\": null,\n    \"preprocess_artifact\": \"py_code_sentiment_analyze\",\n    \"auxiliary_cfg\": null\n  }\n}\nCanary:\n{}",
    "crumbs": [
      "Практика",
      "ClearML Servering"
    ]
  },
  {
    "objectID": "8. clearml_serving.html#тестирвоание-модели",
    "href": "8. clearml_serving.html#тестирвоание-модели",
    "title": "ClearML Servering",
    "section": "",
    "text": "Попробуем потестировать модель, сразу оговорюсь нужно делать тесты мз сети yc, так как для моделей не проброшены внешние порты, для этого можно развернуть виртуалку. Попробуем первый запрос, мы будем обращаться к модели с ID=27c2c1bb0af74984a3a22e702f65fdf9, поэтому в url указываем версию 2.\ncurl -X POST \"http://10.112.135.102:8080/serve/sentiment_analyze/2\" -H \"accept: application/json\" -H \"Content-Type: application/json\" -d \"{\\\"text\\\": \\\"Taking this out of my daughter's library, I found this book and thought the illustrtions were absolutey beautiful -- a true work of artistry. However, I didn't read it through before I bought it. I was reading it to my daughter when I discovered how disturbing the story turns with the spanking scenes. I stopped reading the book and I will take it out of my house.\\\"}\"\nОтвет модели: {\"y\":[2]}\nТеперь второй запрос:\ncurl -X POST \"http://10.112.135.102:8080/serve/sentiment_analyze/2\" -H \"accept: application/json\" -H \"Content-Type: application/json\" -d \"{\\\"text\\\": \\\"Scratched the lens with a kleenex,I used these once then used a Kleenex to wipe one lens that was a little smudged. I have microscopic vision and I noticed it was scratched AFTER I used the Kleenex, so to be sure, I used it again and sure enough, it scratched the lens some more. I compared the 2 lenses and the other lens looked pristine, whereas the one I used the kleenex on was scratched all over Very low quality lenses! Unusable after one use\\\"}\"\nОтвет модели: {\"y\":[1]}\nВидим что модель работает и назначает соответствующие лейблы. Отлично у вас есть развернутая модель которую можно использовать и отправлять ей разные запросы.",
    "crumbs": [
      "Практика",
      "ClearML Servering"
    ]
  }
]